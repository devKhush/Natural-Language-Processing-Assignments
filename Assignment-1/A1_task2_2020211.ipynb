{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "input_dir = os.path.join(os.getcwd(), 'data')\n",
    "input_text_file = os.path.join(input_dir, 'corpus.txt')\n",
    "label_file = os.path.join(input_dir, 'labels.txt')\n",
    "\n",
    "with open(input_text_file, 'r') as f:\n",
    "    corpus = f.readlines()\n",
    "    for i in range(len(corpus)):\n",
    "        corpus[i] = corpus[i][:-1]\n",
    "\n",
    "with open(label_file, 'r') as f:\n",
    "    labels = f.readlines()\n",
    "    for i in range(len(labels)):\n",
    "        labels[i] = labels[i][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 2400)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus), len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\khush\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "{'label': 'sadness', 'score': 0.00029859962523914874}\n",
      "{'label': 'joy', 'score': 0.9987986087799072}\n",
      "{'label': 'love', 'score': 0.0004451328422874212}\n",
      "{'label': 'anger', 'score': 0.0001878843759186566}\n",
      "{'label': 'fear', 'score': 0.00012197871546959504}\n",
      "{'label': 'surprise', 'score': 0.00014771465794183314}\n",
      "<class 'list'>\n",
      "Time taken for emotion_scores:  0.7797598838806152\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import time\n",
    "\n",
    "classifier = pipeline(\"text-classification\",model='bhadresh-savani/distilbert-base-uncased-emotion', return_all_scores=True,)\n",
    "\n",
    "def emotion_scores(sample): \n",
    "    emotion=classifier(sample)\n",
    "    return emotion[0]\n",
    "\n",
    "start_time = time.time()\n",
    "sample = \"I am so happy to see you!\"\n",
    "all_classes = emotion_scores(sample)\n",
    "for info in all_classes:\n",
    "    print(info)\n",
    "end_time = time.time()\n",
    "print(type(all_classes))\n",
    "print(\"Time taken for emotion_scores: \", end_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigram Model for Sentence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple\n",
    "import random\n",
    "\n",
    "\n",
    "class BigramLanguageModel:\n",
    "    def __init__(self, corpus, labels):\n",
    "        self.corpus = corpus\n",
    "        self.labels = labels\n",
    "        self.bigram_counts = {}\n",
    "        self.unigram_counts = {}\n",
    "        self.vocabulary = set()\n",
    "        self.total_bigram_pairs = None\n",
    "        self.bigram_prob = {}\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        '''\n",
    "        Train the Bigram language model on the corpus and labels.\n",
    "        '''\n",
    "        self.count_unigrams()\n",
    "        self.count_bigrams()\n",
    "    \n",
    "    \n",
    "    def count_unigrams(self):\n",
    "        '''\n",
    "        Count the unigrams in the corpus and store counts in the unigram_counts dictionary\n",
    "        '''\n",
    "        for i in range(len(self.corpus)):\n",
    "            sentence = self.corpus[i]\n",
    "            tokens = ['</start>'] + sentence.split() + ['</end>']\n",
    "            label = self.labels[i]\n",
    "            for token in tokens:\n",
    "                self.unigram_counts[token] = self.unigram_counts.get(token, 0) + 1\n",
    "                self.vocabulary.add(token)\n",
    "        self.vocabulary.remove('</start>')\n",
    "        self.vocabulary.remove('</end>')\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def count_bigrams(self):\n",
    "        '''\n",
    "        Count the bigrams in the corpus and store counts in the bigram_counts dictionary\n",
    "        '''\n",
    "        for i in range(len(self.corpus)):\n",
    "            sentence = self.corpus[i]\n",
    "            tokens = ['</start>'] + sentence.split() + ['</end>']\n",
    "            label = self.labels[i]\n",
    "            bi_grams = self.get_bigrams(tokens)            \n",
    "            \n",
    "            for bi_gram in bi_grams:\n",
    "                context = bi_gram[0]\n",
    "                token = bi_gram[1]\n",
    "                if context not in self.bigram_counts:\n",
    "                    self.bigram_counts[context] = {}\n",
    "                self.bigram_counts[context][token] = self.bigram_counts[context].get(token, 0) + 1\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def get_bigrams(self, tokens: List[str]):\n",
    "        '''\n",
    "        Given a list of tokens, return a list of possible bigrams\n",
    "        '''\n",
    "        bigrams = []\n",
    "        for i in range(len(tokens) - 1):\n",
    "            bigrams.append((tokens[i], tokens[i+1]))\n",
    "        return bigrams\n",
    "    \n",
    "    \n",
    "    def get_bigram_prob(self, context: str, token: str, smoothing: str = 'none'):\n",
    "        '''\n",
    "        Get the probability of the token given the context\n",
    "        '''\n",
    "        smoothing = smoothing.lower()\n",
    "        if smoothing == 'none':\n",
    "            return self.__get_bigram_prob_normal(context, token)\n",
    "        elif smoothing == 'laplace':\n",
    "            return self.__get_bigram_prob_laplace(context, token)\n",
    "        elif smoothing == 'kneser-ney':\n",
    "            return self.__get_bigram_prob_kneser_ney(context, token)\n",
    "        else:\n",
    "            raise ValueError('Smoothing method not supported')\n",
    "    \n",
    "    \n",
    "    def __get_bigram_prob_normal(self, context, token):\n",
    "        context_token_cnt = self.bigram_counts[context].get(token, 0)\n",
    "        return context_token_cnt / self.unigram_counts[context]\n",
    "\n",
    "\n",
    "    def __get_bigram_prob_laplace(self, context, token):\n",
    "        context_token_cnt = self.bigram_counts[context].get(token, 0)\n",
    "        return (context_token_cnt + 1) / (self.unigram_counts[context] + len(self.vocabulary))\n",
    "    \n",
    "    \n",
    "    def __get_bigram_prob_kneser_ney(self, context, token, avg_discount=0.7):\n",
    "        d = avg_discount\n",
    "        context_token_cnt = self.bigram_counts[context].get(token, 0)\n",
    "        \n",
    "        # Calculate alpha, which depends on the context\n",
    "        alpha = d * len(self.bigram_counts[context]) / self.unigram_counts[context]\n",
    "        # Calculate Continuation Probability, which depends on the token\n",
    "        bigram_with_token_cnt = 0\n",
    "        for _context_ in self.bigram_counts:\n",
    "            bigram_with_token_cnt += 1 if token in self.bigram_counts[_context_] else 0\n",
    "        total_bigram_pairs = self.__count_total_bigram_pairs()\n",
    "        P_continuation = bigram_with_token_cnt / total_bigram_pairs\n",
    "    \n",
    "        return (max(context_token_cnt - d, 0) / self.unigram_counts[context]) + (alpha * P_continuation)\n",
    "    \n",
    "    \n",
    "    def __count_total_bigram_pairs(self):\n",
    "        '''\n",
    "        Count the total number of unaiue bigram pairs in the corpus\n",
    "        '''\n",
    "        if self.total_bigram_pairs == None:\n",
    "            self.total_bigram_pairs = 0\n",
    "            for context in self.bigram_counts:\n",
    "                self.total_bigram_pairs += len(self.bigram_counts[context])\n",
    "        return self.total_bigram_pairs\n",
    "    \n",
    "    \n",
    "    def __generate_bigram_prob_for_context(self, context, smoothing:str = 'none'):\n",
    "        '''\n",
    "        Generate bigram probabilities for all tokens for a given context\n",
    "        '''\n",
    "        if context not in self.bigram_prob:\n",
    "            self.bigram_prob[context] = {}\n",
    "            for token in self.bigram_counts[context]:\n",
    "                self.bigram_prob[context][token] = self.get_bigram_prob(context, token, smoothing)\n",
    "        return self.bigram_prob[context]\n",
    "    \n",
    "    \n",
    "    def __generate_token(self, context:str, smoothing:str = 'none'):\n",
    "        '''\n",
    "        Generate a token given the context\n",
    "        '''\n",
    "        all_possible_tokens = self.__generate_bigram_prob_for_context(context, smoothing)\n",
    "        generated_token = random.choices(list(all_possible_tokens.keys()), weights=list(all_possible_tokens.values()), k=1)[0]\n",
    "        return generated_token\n",
    "    \n",
    "    \n",
    "    def generate_sentence(self, max_length: int = 10, smoothing: str = 'none'):\n",
    "        '''\n",
    "        Generate a sentence of the given max_length\n",
    "        '''\n",
    "        sentence = []\n",
    "        context = '</start>'\n",
    "        length = 0\n",
    "        for _ in range(max_length):\n",
    "            token = self.__generate_token(context, smoothing)\n",
    "            if token == '</end>':\n",
    "                if length < 10:\n",
    "                    sentence[-1] = sentence[-1] + '.'\n",
    "                    context = '</start>'\n",
    "                    continue\n",
    "                else:\n",
    "                    break \n",
    "            sentence.append(token)\n",
    "            context = token\n",
    "            length += 1\n",
    "        return ' '.join(sentence)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5862443846717553e-05"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_lm = BigramLanguageModel(corpus, labels)\n",
    "bigram_lm.train()\n",
    "\n",
    "prob = bigram_lm.get_bigram_prob('i', 'fine', smoothing='kneser-ney')\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i dont even if i feel have been clubbed upside'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_lm.generate_sentence(max_length=10, smoothing='kneser-ney')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating top 5 Bigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 bigrams with smoothing method: none\n",
      "Total bigrams: 25681\n",
      "('href', 'http'): 1.0\n",
      "('mooshilu', '</end>'): 1.0\n",
      "('tychelle', 'to'): 1.0\n",
      "('hang', 'out'): 1.0\n",
      "('nonexistent', 'social'): 1.0\n",
      "('alex', 'and'): 1.0\n",
      "('marriage', 'and'): 1.0\n",
      "('personifying', 'an'): 1.0\n",
      "('progeny', 'who'): 1.0\n",
      "('genuflecting', 'at'): 1.0\n",
      "\n",
      "Top 10 bigrams with smoothing method: laplace\n",
      "Total bigrams: 25681\n",
      "('</start>', 'i'): 0.2693830629710052\n",
      "('i', 'feel'): 0.11043610327619874\n",
      "('feel', 'like'): 0.0350976507217662\n",
      "('i', 'am'): 0.03189412019960946\n",
      "('</start>', 'im'): 0.02720653978796781\n",
      "('that', 'i'): 0.02650602409638554\n",
      "('and', 'i'): 0.023103748910200523\n",
      "('im', 'feeling'): 0.022454576619814877\n",
      "('i', 'was'): 0.021913647211976566\n",
      "('to', 'be'): 0.01861427094105481\n",
      "\n",
      "Top 10 bigrams with smoothing method: kneser-ney\n",
      "Total bigrams: 25681\n",
      "('href', 'http'): 0.9720021806004439\n",
      "('don', 't'): 0.9712049203427449\n",
      "('didn', 't'): 0.9611413972283877\n",
      "('sort', 'of'): 0.9594087640897253\n",
      "('supposed', 'to'): 0.9238243578261491\n",
      "('doesn', 't'): 0.9222827944567753\n",
      "('www', '</end>'): 0.9166874342899419\n",
      "('amount', 'of'): 0.9137436236906662\n",
      "('wasn', 't'): 0.9125681437638721\n",
      "('able', 'to'): 0.9071576911594824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smoothing_methods = ['none', 'laplace', 'kneser-ney']\n",
    "\n",
    "for smoothing in smoothing_methods:\n",
    "    all_bigram = {}\n",
    "    for context in bigram_lm.bigram_counts:\n",
    "        for token in bigram_lm.bigram_counts[context]:\n",
    "            all_bigram[(context, token)] = bigram_lm.get_bigram_prob(context, token, smoothing)\n",
    "    \n",
    "    top_count = 10\n",
    "    top_bigrams = sorted(all_bigram, key=all_bigram.get, reverse=True)[:top_count]\n",
    "    print(f\"Top {top_count} bigrams with smoothing method: {smoothing}\")\n",
    "    print(f\"Total bigrams: {len(all_bigram)}\")\n",
    "    for bigram in top_bigrams:\n",
    "        print(f\"{bigram}: {all_bigram[bigram]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigram Model for Emotion Sentence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class BigramLM_Emotion:\n",
    "    def __init__(self, corpus, labels):\n",
    "        self.corpus = corpus\n",
    "        self.labels = labels\n",
    "        self.bigram_counts = {}\n",
    "        self.unigram_counts = {}\n",
    "        self.vocabulary = set()\n",
    "        self.total_bigram_pairs = None\n",
    "        self.bigram_emotion_vector = {}\n",
    "        self.bigram_prob = {}\n",
    "        self.class_to_idx = {'sadness': 0, 'joy': 1, 'love': 2, 'anger': 3, 'fear': 4, 'surprise': 5}\n",
    "        self.num_labels = len(self.class_to_idx)\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        '''\n",
    "        Train the Bigram language model on the corpus and labels.\n",
    "        '''\n",
    "        self.count_unigrams()\n",
    "        self.count_bigrams()\n",
    "            \n",
    "    \n",
    "    def count_unigrams(self):\n",
    "        '''\n",
    "        Count the unigrams in the corpus and store counts in the unigram_counts dictionary\n",
    "        '''\n",
    "        for i in range(len(self.corpus)):\n",
    "            sentence = self.corpus[i]\n",
    "            tokens = ['</start>'] + sentence.split() + ['</end>']\n",
    "            label = self.labels[i]\n",
    "            for token in tokens:\n",
    "                self.unigram_counts[token] = self.unigram_counts.get(token, 0) + 1\n",
    "                self.vocabulary.add(token)\n",
    "        self.vocabulary.remove('</start>')\n",
    "        self.vocabulary.remove('</end>')\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def count_bigrams(self):\n",
    "        '''\n",
    "        Count the bigrams in the corpus and store counts in the bigram_counts dictionary\n",
    "        '''\n",
    "        for i in range(len(self.corpus)):\n",
    "            if i % 100 == 0:\n",
    "                print(i, end=' ')\n",
    "            sentence = self.corpus[i]\n",
    "            emotion = emotion_scores(sentence)\n",
    "            label = self.labels[i]\n",
    "            tokens = ['</start>'] + sentence.split() + ['</end>']\n",
    "            bi_grams = self.get_bigrams(tokens)            \n",
    "            \n",
    "            for bi_gram in bi_grams:\n",
    "                context = bi_gram[0]\n",
    "                token = bi_gram[1]\n",
    "                if context not in self.bigram_counts:\n",
    "                    self.bigram_counts[context] = {}\n",
    "                self.bigram_counts[context][token] = self.bigram_counts[context].get(token, 0) + 1\n",
    "                if context not in self.bigram_emotion_vector:\n",
    "                    self.bigram_emotion_vector[context] = {}\n",
    "                # self.bigram_emotion_vector[context][token] = self.bigram_emotion_vector[context].get(token, [])\n",
    "                emotion_vector = [0] * self.num_labels\n",
    "                for i in range(len(emotion)):\n",
    "                    emotion_vector[self.class_to_idx[emotion[i]['label']]] = emotion[i]['score']\n",
    "                self.bigram_emotion_vector[context][token] = self.bigram_emotion_vector[context].get(token, np.array([0]*self.num_labels)) + np.array(emotion_vector)\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def get_bigrams(self, tokens:List[str]):\n",
    "        '''\n",
    "        Given a list of tokens, return a list of possible bigrams\n",
    "        '''\n",
    "        bigrams = []\n",
    "        for i in range(len(tokens) - 1):\n",
    "            bigrams.append((tokens[i], tokens[i+1]))\n",
    "        return bigrams\n",
    "    \n",
    "    \n",
    "    def get_bigram_prob(self, context:str, token:str, beta_score:float, smoothing:str='kneser-ney'):\n",
    "        '''\n",
    "        Get the probability of the token given the context\n",
    "        '''\n",
    "        smoothing = smoothing.lower()\n",
    "        if smoothing == 'none':\n",
    "            return self.__get_bigram_prob_normal(context, token, beta_score)\n",
    "        elif smoothing == 'laplace':\n",
    "            return self.__get_bigram_prob_laplace(context, token, beta_score)\n",
    "        elif smoothing == 'kneser-ney':\n",
    "            return self.__get_bigram_prob_kneser_ney(context, token, beta_score)\n",
    "        else:\n",
    "            raise ValueError('Smoothing method not supported')\n",
    "    \n",
    "    \n",
    "    def __get_bigram_prob_normal(self, context, token, beta_score):\n",
    "        context_token_cnt = self.bigram_counts[context].get(token, 0)\n",
    "        return beta_score**2 + 2*beta_score*context_token_cnt/(self.unigram_counts[context]*np.log(beta_score) + 1)\n",
    "\n",
    "\n",
    "    def __get_bigram_prob_laplace(self, context, token, beta_score):\n",
    "        context_token_cnt = self.bigram_counts[context].get(token, 0)\n",
    "        return beta_score + beta_score*(context_token_cnt+1)/(self.unigram_counts[context]+len(self.vocabulary))\n",
    "    \n",
    "    \n",
    "    def __get_bigram_prob_kneser_ney(self, context, token, beta_score, avg_discount=0.7):\n",
    "        d = avg_discount\n",
    "        context_token_cnt = self.bigram_counts[context].get(token, 0)\n",
    "        \n",
    "        # Calculate alpha, which depends on the context\n",
    "        alpha = d * len(self.bigram_counts[context]) / self.unigram_counts[context]\n",
    "        # Calculate Continuation Probability, which depends on the token\n",
    "        bigram_with_token_cnt = 0\n",
    "        for _context_ in self.bigram_counts:\n",
    "            bigram_with_token_cnt += 1 if token in self.bigram_counts[_context_] else 0\n",
    "        total_bigram_pairs = self.__count_total_bigram_pairs()\n",
    "        P_continuation = bigram_with_token_cnt / total_bigram_pairs\n",
    "    \n",
    "        return (beta_score + beta_score*max(context_token_cnt-d,0)/self.unigram_counts[context]) + (alpha * P_continuation)\n",
    "    \n",
    "    \n",
    "    def __count_total_bigram_pairs(self):\n",
    "        '''\n",
    "        Count the total number of unique bigram pairs in the corpus\n",
    "        '''\n",
    "        if self.total_bigram_pairs == None:\n",
    "            self.total_bigram_pairs = 0\n",
    "            for context in self.bigram_counts:\n",
    "                self.total_bigram_pairs += len(self.bigram_counts[context])\n",
    "        return self.total_bigram_pairs\n",
    "    \n",
    "    \n",
    "    def __generate_bigram_prob_for_context(self, context, emotion:str, smoothing:str='kneser-ney'):\n",
    "        '''\n",
    "        Generate bigram probabilities for all tokens for a given context\n",
    "        '''\n",
    "        if context not in self.bigram_prob:\n",
    "            self.bigram_prob[context] = {}\n",
    "        if emotion not in self.bigram_prob[context]:\n",
    "            self.bigram_prob[context][emotion] = {}\n",
    "            emotion_vector = np.array([0] * self.num_labels)\n",
    "            emotion_vector[self.class_to_idx[emotion]] = 1\n",
    "\n",
    "            # calculate beta scores and normalize them\n",
    "            beta_scores = {}\n",
    "            total_score = 0\n",
    "            for token in self.bigram_counts[context]:\n",
    "                score = np.sum(emotion_vector * self.bigram_emotion_vector[context][token])\n",
    "                # Best score combinations\n",
    "                # score * np.log(score), score * (1 + np.log(score)), score * (np.e + np.log(score)) \n",
    "                beta_scores[token] =  score # * np.log(score)\n",
    "                total_score += beta_scores[token]\n",
    "            for token in beta_scores:\n",
    "                beta_scores[token] = beta_scores[token] / total_score\n",
    "                \n",
    "            # calculate bigram probabilities\n",
    "            for token in self.bigram_counts[context]:\n",
    "                self.bigram_prob[context][emotion][token] = self.get_bigram_prob(context, token, beta_scores[token], smoothing)\n",
    "            \n",
    "            # normalize bigram probabilities\n",
    "            total_prob = sum(self.bigram_prob[context][emotion].values())\n",
    "            for token in self.bigram_prob[context][emotion]:\n",
    "                self.bigram_prob[context][emotion][token] = self.bigram_prob[context][emotion][token] / total_prob\n",
    "\n",
    "        return self.bigram_prob[context][emotion]\n",
    "    \n",
    "    \n",
    "    def __generate_token(self, context:str, emotion:str, smoothing:str='kneser-ney'):\n",
    "        '''\n",
    "        Generate a token given the context\n",
    "        '''\n",
    "        all_possible_tokens = self.__generate_bigram_prob_for_context(context, emotion, smoothing)\n",
    "        generated_token = random.choices(list(all_possible_tokens.keys()), weights=list(all_possible_tokens.values()))[0]\n",
    "        return generated_token\n",
    "    \n",
    "    \n",
    "    def generate_sentence(self, emotion:str, max_length:int=10, smoothing:str='kneser-ney'):\n",
    "        '''\n",
    "        Generate a sentence of the given max_length\n",
    "        '''\n",
    "        sentence = []\n",
    "        context = '</start>'\n",
    "        length = 0\n",
    "        for _ in range(max_length):\n",
    "            token = self.__generate_token(context, emotion, smoothing)\n",
    "            if  token == '</end>':\n",
    "                if length < 7:\n",
    "                    sentence[-1] = sentence[-1] + '.'\n",
    "                    # sentence.append('.')\n",
    "                    context = '</start>'\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "            length += 1\n",
    "            sentence.append(token)\n",
    "            context = token\n",
    "        return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 "
     ]
    }
   ],
   "source": [
    "lm = BigramLM_Emotion(corpus, labels)\n",
    "lm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sadness': 0, 'joy': 1, 'love': 2, 'anger': 3, 'fear': 4, 'surprise': 5}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i feel special gifts. i feel the fact that what i feel good person in the homes that if i feel so feel relieved that core of the drive'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.generate_sentence('joy', max_length=30, smoothing='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model_file = os.path.join(os.getcwd(), 'bigram_lm_emotion.pkl')\n",
    "pickle.dump(lm, open(model_file, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "model_file = os.path.join(os.getcwd(), 'bigram_lm_emotion.pkl')\n",
    "lm_saved = pickle.load(open(model_file, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate different emotion sentences using the LM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sentences for sadness\n",
      "Generated 50 sentences for sadness in 51 trails\n",
      "Accuracy for sadness: 98.0392156862745\n",
      "\n",
      "Generating sentences for joy\n",
      "Generated 50 sentences for joy in 54 trails\n",
      "Accuracy for joy: 92.5925925925926\n",
      "\n",
      "Generating sentences for love\n",
      "Generated 50 sentences for love in 55 trails\n",
      "Accuracy for love: 90.9090909090909\n",
      "\n",
      "Generating sentences for anger\n",
      "Generated 50 sentences for anger in 60 trails\n",
      "Accuracy for anger: 83.33333333333334\n",
      "\n",
      "Generating sentences for fear\n",
      "Generated 50 sentences for fear in 50 trails\n",
      "Accuracy for fear: 100.0\n",
      "\n",
      "Generating sentences for surprise\n",
      "Generated 50 sentences for surprise in 50 trails\n",
      "Accuracy for surprise: 100.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_emotions = ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n",
    "output_dir = os.path.join(os.getcwd(), 'output')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "for emotion in all_emotions:\n",
    "    print(f'Generating sentences for {emotion}')\n",
    "    output_file = os.path.join(output_dir, f'gen_{emotion}.txt')\n",
    "    label_file = os.path.join(output_dir, f'gen_label_{emotion}.txt')\n",
    "    \n",
    "    with open(label_file, 'w') as f:\n",
    "        f.write(f'Labels for {emotion}\\n\\n')\n",
    "        \n",
    "    with open(output_file, 'w') as f:\n",
    "        sentences = []\n",
    "        outputs = []\n",
    "        samples = 50\n",
    "        generated = 0\n",
    "        trails = 0\n",
    "        while generated < samples:\n",
    "            sentence = lm.generate_sentence(emotion, max_length=30, smoothing='none')\n",
    "            emotions = emotion_scores(sentence)\n",
    "            trails += 1\n",
    "            \n",
    "            max_score = 0\n",
    "            max_label = ''\n",
    "            for info in emotions:\n",
    "                if info['score'] > max_score:\n",
    "                    max_score = info['score']\n",
    "                    max_label = info['label']\n",
    "            if max_label != emotion:\n",
    "                continue\n",
    "            \n",
    "            f.write(sentence + '\\n')\n",
    "            with open(label_file, 'a') as f_label:\n",
    "                f_label.write(max_label + ' ' + str(max_score) + '\\n')\n",
    "            sentences.append(sentence)\n",
    "            outputs.append(emotions)\n",
    "            generated += 1\n",
    "        \n",
    "    print(f'Generated {generated} sentences for {emotion} in {trails} trails')\n",
    "    print(f'Accuracy for {emotion}: {generated/trails*100}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the Best SVC Classifier using GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer # define vectorizer\n",
    "import numpy as np\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "sparse_X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x5410 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 11 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_X[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {\"sadness\":0, \"love\":1, \"anger\":2, \"joy\":3, \"fear\":4, \"surprise\":5} # true label to its index\n",
    "X = sparse_X.todense()\n",
    "X = np.array(X)\n",
    "Y = [labels_dict[label] for label in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 300\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dir = os.path.join(os.getcwd(), 'output')\n",
    "\n",
    "sentence_files = ['gen_sadness.txt', 'gen_love.txt', 'gen_anger.txt', 'gen_joy.txt', 'gen_fear.txt', 'gen_surprise.txt']\n",
    "label_files = ['gen_label_sadness.txt', 'gen_label_love.txt', 'gen_label_anger.txt', 'gen_label_joy.txt', 'gen_label_fear.txt', 'gen_label_surprise.txt']\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "for i in range(len(sentence_files)):\n",
    "    with open(os.path.join(dir, sentence_files[i]), 'r') as f:\n",
    "        sentences = f.readlines()\n",
    "    with open(os.path.join(dir, label_files[i]), 'r') as f:\n",
    "        labels = f.readlines()\n",
    "    \n",
    "    for i in range(len(sentences)):\n",
    "        sentences[i] = sentences[i][:-1]\n",
    "    for i in range(2, len(labels)):\n",
    "        labels[i] = labels[i].split()[0]\n",
    "    X_test.extend(sentences)\n",
    "    Y_test.extend(labels[2:])\n",
    "    \n",
    "print(len(X_test), len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_X_test = vectorizer.transform(X_test)\n",
    "Y_test = [labels_dict[label] for label in Y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'kernel':('linear', 'rbf', 'poly'), 'C':[1, 10, 100]}\n",
    "svc = svm.SVC(gamma='scale', random_state=32)\n",
    "clf = GridSearchCV(svc, parameters, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(random_state=32),\n",
       "             param_grid={&#x27;C&#x27;: [1, 10, 100],\n",
       "                         &#x27;kernel&#x27;: (&#x27;linear&#x27;, &#x27;rbf&#x27;, &#x27;poly&#x27;)},\n",
       "             return_train_score=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(estimator=SVC(random_state=32),\n",
       "             param_grid={&#x27;C&#x27;: [1, 10, 100],\n",
       "                         &#x27;kernel&#x27;: (&#x27;linear&#x27;, &#x27;rbf&#x27;, &#x27;poly&#x27;)},\n",
       "             return_train_score=True)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: SVC</label><div class=\"sk-toggleable__content fitted\"><pre>SVC(random_state=32)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(random_state=32)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(random_state=32),\n",
       "             param_grid={'C': [1, 10, 100],\n",
       "                         'kernel': ('linear', 'rbf', 'poly')},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([26.94461274, 25.1282506 , 23.86464734, 26.97547231, 26.74716873,\n",
       "        28.79105825, 28.14219875, 28.04665427, 28.71511173]),\n",
       " 'std_fit_time': array([2.95685828, 2.71396016, 0.82983448, 3.11018003, 2.33478695,\n",
       "        0.21903727, 0.11040663, 0.25434177, 0.14740535]),\n",
       " 'mean_score_time': array([4.15251136, 5.44599781, 3.64564052, 3.95802684, 7.07484355,\n",
       "        4.37392488, 4.10864515, 7.6225163 , 4.36852808]),\n",
       " 'std_score_time': array([0.52845696, 1.52498603, 0.14484277, 0.52546064, 1.46445381,\n",
       "        0.07239296, 0.03956218, 0.08770424, 0.06181305]),\n",
       " 'param_C': masked_array(data=[1, 1, 1, 10, 10, 10, 100, 100, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['linear', 'rbf', 'poly', 'linear', 'rbf', 'poly',\n",
       "                    'linear', 'rbf', 'poly'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'kernel': 'poly'},\n",
       "  {'C': 10, 'kernel': 'linear'},\n",
       "  {'C': 10, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'kernel': 'poly'},\n",
       "  {'C': 100, 'kernel': 'linear'},\n",
       "  {'C': 100, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'kernel': 'poly'}],\n",
       " 'split0_test_score': array([0.75      , 0.69166667, 0.61458333, 0.73541667, 0.7       ,\n",
       "        0.62291667, 0.72083333, 0.7       , 0.62291667]),\n",
       " 'split1_test_score': array([0.75      , 0.67708333, 0.60625   , 0.73541667, 0.71666667,\n",
       "        0.60625   , 0.72291667, 0.71666667, 0.60625   ]),\n",
       " 'split2_test_score': array([0.72708333, 0.69166667, 0.66458333, 0.72291667, 0.70208333,\n",
       "        0.67083333, 0.71875   , 0.70208333, 0.67083333]),\n",
       " 'split3_test_score': array([0.725     , 0.66875   , 0.625     , 0.74375   , 0.69791667,\n",
       "        0.62916667, 0.7375    , 0.69791667, 0.62916667]),\n",
       " 'split4_test_score': array([0.75      , 0.7       , 0.67291667, 0.75416667, 0.725     ,\n",
       "        0.67083333, 0.75208333, 0.725     , 0.67083333]),\n",
       " 'mean_test_score': array([0.74041667, 0.68583333, 0.63666667, 0.73833333, 0.70833333,\n",
       "        0.64      , 0.73041667, 0.70833333, 0.64      ]),\n",
       " 'std_test_score': array([0.01175561, 0.01128851, 0.02699022, 0.01034139, 0.01062296,\n",
       "        0.02626653, 0.01267927, 0.01062296, 0.02626653]),\n",
       " 'rank_test_score': array([1, 6, 9, 2, 4, 7, 3, 4, 7]),\n",
       " 'split0_train_score': array([0.98333333, 0.9984375 , 0.99947917, 0.99947917, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split1_train_score': array([0.98645833, 0.99739583, 0.99947917, 0.99895833, 0.99947917,\n",
       "        0.99947917, 0.99947917, 0.99947917, 0.99947917]),\n",
       " 'split2_train_score': array([0.984375  , 0.99947917, 0.99947917, 0.99947917, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split3_train_score': array([0.9859375 , 0.99895833, 0.99895833, 0.99895833, 0.99947917,\n",
       "        0.99947917, 0.99947917, 0.99947917, 0.99947917]),\n",
       " 'split4_train_score': array([0.98385417, 0.99791667, 0.99947917, 0.99947917, 0.99947917,\n",
       "        0.99947917, 0.99947917, 0.99947917, 0.99947917]),\n",
       " 'mean_train_score': array([0.98479167, 0.9984375 , 0.999375  , 0.99927083, 0.9996875 ,\n",
       "        0.9996875 , 0.9996875 , 0.9996875 , 0.9996875 ]),\n",
       " 'std_train_score': array([0.00120582, 0.00073657, 0.00020833, 0.00025516, 0.00025516,\n",
       "        0.00025516, 0.00025516, 0.00025516, 0.00025516])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, kernel=&#x27;linear&#x27;, random_state=32)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(C=1, kernel=&#x27;linear&#x27;, random_state=32)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1, kernel='linear', random_state=32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7404166666666667"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.98125\n",
      "Train F1:  0.9812124418156302\n"
     ]
    }
   ],
   "source": [
    "Y_predict_train = clf.predict(X)\n",
    "acc_train = accuracy_score(Y, Y_predict_train)\n",
    "f1_train = f1_score(Y, Y_predict_train, average = \"macro\")\n",
    "\n",
    "print(\"Train Accuracy: \", acc_train)\n",
    "print(\"Train F1: \", f1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on Testing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.98\n",
      "Test F1:  0.9799277398635087\n"
     ]
    }
   ],
   "source": [
    "Y_predict_test = clf.predict(np.asarray(sparse_X_test.todense()))\n",
    "\n",
    "acc_test = accuracy_score(Y_test, Y_predict_test)\n",
    "f1_test = f1_score(Y_test, Y_predict_test, average = \"macro\")\n",
    "print(\"Test Accuracy: \", acc_test)\n",
    "print(\"Test F1: \", f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.98\n",
      "Test F1:  0.9799277398635087\n"
     ]
    }
   ],
   "source": [
    "best_svc = svm.SVC(gamma='scale', random_state=32, C=1.0, kernel=\"linear\")\n",
    "best_svc.fit(X, Y)\n",
    "Y_predict_test = best_svc.predict(np.asarray(sparse_X_test.todense()))\n",
    "\n",
    "acc_test = accuracy_score(Y_test, Y_predict_test)\n",
    "f1_test = f1_score(Y_test, Y_predict_test, average = \"macro\")\n",
    "print(\"Test Accuracy: \", acc_test)\n",
    "print(\"Test F1: \", f1_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
