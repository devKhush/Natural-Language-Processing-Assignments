{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/sumdev/CourseWork/a3_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset and Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training dataset, only the first 50,000 examples\n",
    "train_dataset = load_dataset(\"wmt16\", \"de-en\", split=\"train[:50000]\")\n",
    "\n",
    "# Load validation and test datasets\n",
    "validation_dataset = load_dataset(\"wmt16\", \"de-en\", split=\"validation\")\n",
    "test_dataset = load_dataset(\"wmt16\", \"de-en\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2169, 2999)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(validation_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup- 2A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import Multi30k\n",
    "from typing import Iterable, List\n",
    "\n",
    "# Define the PositionalEncoding module\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, emb_size: int, dropout: float, maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "\n",
    "# Define the Transformer model\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, emb_dim=234, nhead=6, num_encoder_layers=5, num_decoder_layers=5, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding_dim = emb_dim\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=emb_dim, nhead=nhead, num_encoder_layers=num_encoder_layers, \n",
    "            num_decoder_layers=num_decoder_layers, dropout=dropout, batch_first=True)\n",
    "        self.src_token_emb = nn.Embedding(src_vocab_size, emb_dim)\n",
    "        self.tgt_token_emb = nn.Embedding(tgt_vocab_size, emb_dim)\n",
    "        self.linear = nn.Linear(emb_dim, tgt_vocab_size)\n",
    "        self.positional_encoding = PositionalEncoding(emb_dim, dropout=dropout)\n",
    "\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, memory_padding_mask):\n",
    "        src_emb = self.positional_encoding(self.src_token_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_token_emb(tgt))\n",
    "        output = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None, src_padding_mask, tgt_padding_mask, memory_padding_mask)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        return self.transformer.encoder(self.positional_encoding(self.src_token_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask):\n",
    "        return self.transformer.decoder(self.positional_encoding(self.tgt_token_emb(tgt)), memory, tgt_mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocabulary of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "# Define function to yield tokens from the dataset\n",
    "def yield_tokens(data_iter: Iterable, language: str):\n",
    "    for data_sample in data_iter:\n",
    "        yield token_transform[language](data_sample['translation'][language])\n",
    "\n",
    "# Set up tokenizers\n",
    "token_transform = {}\n",
    "SRC_LANGUAGE = 'de'\n",
    "TGT_LANGUAGE = 'en'\n",
    "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "\n",
    "# Build vocabulary\n",
    "vocab_transform = {}\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "vocab_transform[SRC_LANGUAGE] = build_vocab_from_iterator(yield_tokens(train_dataset, 'de'), specials=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"])\n",
    "vocab_transform[TGT_LANGUAGE] = build_vocab_from_iterator(yield_tokens(train_dataset, 'en'), specials=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"])\n",
    "vocab_transform[SRC_LANGUAGE].set_default_index(UNK_IDX)\n",
    "vocab_transform[TGT_LANGUAGE].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 1, 1, 2, 2, 3, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transform[SRC_LANGUAGE]['<unk>'], vocab_transform[TGT_LANGUAGE]['<unk>'], vocab_transform[SRC_LANGUAGE]['<pad>'], vocab_transform[TGT_LANGUAGE]['<pad>'], vocab_transform[SRC_LANGUAGE]['<bos>'], vocab_transform[TGT_LANGUAGE]['<bos>'], vocab_transform[SRC_LANGUAGE]['<eos>'], vocab_transform[TGT_LANGUAGE]['<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52604, 23774)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_transform[SRC_LANGUAGE]), len(vocab_transform[TGT_LANGUAGE])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataSet and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m     tgt_len \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(tgt_len, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m src_batch, tgt_batch, src_len, tgt_len, idx\n\u001b[0;32m---> 31\u001b[0m train_data \u001b[38;5;241m=\u001b[39m TextDataset(\u001b[43mtrain_dataset\u001b[49m)\n\u001b[1;32m     32\u001b[0m val_data \u001b[38;5;241m=\u001b[39m TextDataset(validation_dataset)\n\u001b[1;32m     33\u001b[0m test_data \u001b[38;5;241m=\u001b[39m TextDataset(test_dataset)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        german = self.dataset[idx]['translation']['de']\n",
    "        english = self.dataset[idx]['translation']['en']\n",
    "        german_token = token_transform[SRC_LANGUAGE](german)\n",
    "        english_token = token_transform[TGT_LANGUAGE](english)\n",
    "        german_vocab = torch.tensor([vocab_transform[SRC_LANGUAGE][token] for token in german_token], dtype=torch.long)\n",
    "        english_vocab = torch.tensor([vocab_transform[TGT_LANGUAGE][token] for token in english_token], dtype=torch.long)\n",
    "        germen_sentence_length = len(german_vocab)\n",
    "        english_sentence_length = len(english_vocab)\n",
    "        return german_vocab, english_vocab, germen_sentence_length, english_sentence_length, idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch, src_len, tgt_len, idx = zip(*batch)\n",
    "    src_batch = nn.utils.rnn.pad_sequence(src_batch, padding_value=PAD_IDX, batch_first=True)\n",
    "    tgt_batch = nn.utils.rnn.pad_sequence(tgt_batch, padding_value=PAD_IDX, batch_first=True)\n",
    "    src_len = torch.tensor(src_len, dtype=torch.long)\n",
    "    tgt_len = torch.tensor(tgt_len, dtype=torch.long)\n",
    "    return src_batch, tgt_batch, src_len, tgt_len, idx\n",
    "\n",
    "\n",
    "train_data = TextDataset(train_dataset)\n",
    "val_data = TextDataset(validation_dataset)\n",
    "test_data = TextDataset(test_dataset)\n",
    "print(len(train_data), len(val_data), len(test_data))\n",
    "\n",
    "# Define data loaders\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "print(len(train_loader), len(val_loader), len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[1]\n",
    "    tgt_seq_len = tgt.shape[1]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=device).type(torch.bool)\n",
    "    src_padding_mask = (src == PAD_IDX)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 91]) torch.Size([64, 76]) torch.Size([64]) torch.Size([64])\n",
      "torch.Size([91, 91]) torch.Size([76, 76]) torch.Size([64, 91]) torch.Size([64, 76])\n"
     ]
    }
   ],
   "source": [
    "for src, tgt, src_len, tgt_len, idx in train_loader:\n",
    "    print(src.shape, tgt.shape, src_len.shape, tgt_len.shape)\n",
    "    src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt)\n",
    "    print(src_mask.shape, tgt_mask.shape, src_padding_mask.shape, tgt_padding_mask.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize model\n",
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "EMB_DIM = 256\n",
    "N_HEAD = 8\n",
    "NUM_ENCODER_LAYERS = 8\n",
    "NUM_DECODER_LAYERS = 8\n",
    "DROPOUT = 0.05\n",
    "model = TransformerModel(src_vocab_size=SRC_VOCAB_SIZE, tgt_vocab_size=TGT_VOCAB_SIZE, \n",
    "            emb_dim=EMB_DIM, nhead=N_HEAD, num_encoder_layers=NUM_ENCODER_LAYERS, \n",
    "            num_decoder_layers=NUM_DECODER_LAYERS, dropout=DROPOUT)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    model.train()\n",
    "    model = model.to(device)\n",
    "    epoch_loss = 0\n",
    "    for index, (src, tgt, _, _, _) in enumerate(iterator):\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        tgt_input = tgt[:, :-1]\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "        memory_padding_mask = src_padding_mask.clone()\n",
    "        tgt_out = tgt[:, 1:]\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, memory_padding_mask)\n",
    "        loss = criterion(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        if index % 100 == 0:\n",
    "            print(f\"Batch {index} Loss: {loss.item()}\")\n",
    "    model = model.to('cpu')\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "# Evaluation loop\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt, _, _, _ in iterator:\n",
    "            src = src.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "            tgt_input = tgt[:, :-1]\n",
    "            src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "            memory_padding_mask = src_padding_mask.clone()\n",
    "            tgt_out = tgt[:, 1:]\n",
    "            logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, memory_padding_mask)\n",
    "            loss = criterion(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "            epoch_loss += loss.item()\n",
    "    model = model.to('cpu')\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/sumdev/CourseWork/a3_env/lib/python3.12/site-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 Loss: 10.220878601074219\n",
      "Batch 100 Loss: 6.968963146209717\n",
      "Batch 200 Loss: 6.4077558517456055\n",
      "Batch 300 Loss: 5.975808143615723\n",
      "Batch 400 Loss: 5.9370245933532715\n",
      "Batch 500 Loss: 5.778221130371094\n",
      "Batch 600 Loss: 5.525778293609619\n",
      "Batch 700 Loss: 5.508260726928711\n",
      "Epoch: 1 | Train Loss: 6.22467139370911 | Val Loss: 7.2703906087314385\n",
      "Batch 0 Loss: 5.538148403167725\n",
      "Batch 100 Loss: 5.275978088378906\n",
      "Batch 200 Loss: 5.278611660003662\n",
      "Batch 300 Loss: 5.162457466125488\n",
      "Batch 400 Loss: 5.114497184753418\n",
      "Batch 500 Loss: 5.181527614593506\n",
      "Batch 600 Loss: 5.241818428039551\n",
      "Batch 700 Loss: 4.939311504364014\n",
      "Epoch: 2 | Train Loss: 5.205466532036471 | Val Loss: 7.145123650045956\n",
      "Batch 0 Loss: 4.958529472351074\n",
      "Batch 100 Loss: 4.9718828201293945\n",
      "Batch 200 Loss: 4.929483413696289\n",
      "Batch 300 Loss: 4.895610809326172\n",
      "Batch 400 Loss: 4.971885681152344\n",
      "Batch 500 Loss: 4.903313159942627\n",
      "Batch 600 Loss: 4.8681206703186035\n",
      "Batch 700 Loss: 4.6816725730896\n",
      "Epoch: 3 | Train Loss: 4.8974092903039645 | Val Loss: 6.879389861050774\n",
      "Batch 0 Loss: 4.716778755187988\n",
      "Batch 100 Loss: 4.649244785308838\n",
      "Batch 200 Loss: 4.726291179656982\n",
      "Batch 300 Loss: 4.7597479820251465\n",
      "Batch 400 Loss: 4.715301036834717\n",
      "Batch 500 Loss: 4.714985370635986\n",
      "Batch 600 Loss: 4.526054859161377\n",
      "Batch 700 Loss: 4.506436347961426\n",
      "Epoch: 4 | Train Loss: 4.695641972524736 | Val Loss: 6.901529059690588\n",
      "Batch 0 Loss: 4.60966682434082\n",
      "Batch 100 Loss: 4.644985198974609\n",
      "Batch 200 Loss: 4.524564266204834\n",
      "Batch 300 Loss: 4.5900750160217285\n",
      "Batch 400 Loss: 4.524502754211426\n",
      "Batch 500 Loss: 4.56439733505249\n",
      "Batch 600 Loss: 4.672557353973389\n",
      "Batch 700 Loss: 4.405167579650879\n",
      "Epoch: 5 | Train Loss: 4.533606273743808 | Val Loss: 6.72000838728512\n",
      "Batch 0 Loss: 4.438945293426514\n",
      "Batch 100 Loss: 4.515316009521484\n",
      "Batch 200 Loss: 4.405940532684326\n",
      "Batch 300 Loss: 4.347811222076416\n",
      "Batch 400 Loss: 4.2705397605896\n",
      "Batch 500 Loss: 4.362485885620117\n",
      "Batch 600 Loss: 4.271872520446777\n",
      "Batch 700 Loss: 4.29947566986084\n",
      "Epoch: 6 | Train Loss: 4.396932644002578 | Val Loss: 6.677600215463078\n",
      "Batch 0 Loss: 4.248816967010498\n",
      "Batch 100 Loss: 4.294404029846191\n",
      "Batch 200 Loss: 4.286946773529053\n",
      "Batch 300 Loss: 4.364271640777588\n",
      "Batch 400 Loss: 4.472418785095215\n",
      "Batch 500 Loss: 4.073663234710693\n",
      "Batch 600 Loss: 4.129185199737549\n",
      "Batch 700 Loss: 4.423928737640381\n",
      "Epoch: 7 | Train Loss: 4.276219233832396 | Val Loss: 6.676111782298369\n",
      "Batch 0 Loss: 4.253754615783691\n",
      "Batch 100 Loss: 4.129093170166016\n",
      "Batch 200 Loss: 4.196895599365234\n",
      "Batch 300 Loss: 4.2680559158325195\n",
      "Batch 400 Loss: 4.212950706481934\n",
      "Batch 500 Loss: 4.244508743286133\n",
      "Batch 600 Loss: 4.2540283203125\n",
      "Batch 700 Loss: 4.147491455078125\n",
      "Epoch: 8 | Train Loss: 4.167600463113517 | Val Loss: 6.646944158217487\n",
      "Batch 0 Loss: 4.183809757232666\n",
      "Batch 100 Loss: 4.131309509277344\n",
      "Batch 200 Loss: 4.05911111831665\n",
      "Batch 300 Loss: 4.062179088592529\n",
      "Batch 400 Loss: 4.1194329261779785\n",
      "Batch 500 Loss: 4.046625137329102\n",
      "Batch 600 Loss: 4.037542343139648\n",
      "Batch 700 Loss: 3.8820273876190186\n",
      "Epoch: 9 | Train Loss: 4.069945000016781 | Val Loss: 6.571708342608283\n",
      "Batch 0 Loss: 4.001835823059082\n",
      "Batch 100 Loss: 3.9790971279144287\n",
      "Batch 200 Loss: 4.122492790222168\n",
      "Batch 300 Loss: 4.045344829559326\n",
      "Batch 400 Loss: 3.9597952365875244\n",
      "Batch 500 Loss: 4.127245903015137\n",
      "Batch 600 Loss: 4.00120210647583\n",
      "Batch 700 Loss: 3.827488899230957\n",
      "Epoch: 10 | Train Loss: 3.976901699210067 | Val Loss: 6.578901571386001\n",
      "| Test Loss: 6.708190045458205\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "N_EPOCHS = 10\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion)\n",
    "    val_loss = evaluate(model, val_loader, criterion)\n",
    "    training_loss.append(train_loss)\n",
    "    validation_loss.append(val_loss)\n",
    "    print(f'Epoch: {epoch+1} | Train Loss: {train_loss} | Val Loss: {val_loss}')\n",
    "\n",
    "# Test the model\n",
    "test_loss = evaluate(model, test_loader, criterion)\n",
    "print(f'| Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABXQElEQVR4nO3dd3xUVf7/8ddMem+kQgihhxB6Z2mKArqsIDZEQUVdFRDbrvJzXbGiq7isoiiuwrqK2FbkKyICIiC9C9JbAiQhlBQSSJvM748JAwNhCCHJTSbv5+NxH2TOnDvzGQLkzbnnnmOyWq1WRERERFyE2egCRERERCqTwo2IiIi4FIUbERERcSkKNyIiIuJSFG5ERETEpSjciIiIiEtRuBERERGX4m50AdWtpKSE1NRUAgICMJlMRpcjIiIi5WC1Wjl16hQxMTGYzc7HZupcuElNTSU2NtboMkRERKQCDh06RIMGDZz2qXPhJiAgALD95gQGBhpcjYiIiJRHTk4OsbGx9p/jztS5cHP2UlRgYKDCjYiISC1TniklmlAsIiIiLkXhRkRERFyKwo2IiIi4lDo350ZERK6exWKhqKjI6DLExXh6el72Nu/yULgREZFys1qtpKenk5WVZXQp4oLMZjPx8fF4enpe1eso3IiISLmdDTYRERH4+vpqMVSpNGcX2U1LS6Nhw4ZX9WdL4UZERMrFYrHYg01YWJjR5YgLCg8PJzU1leLiYjw8PCr8OppQLCIi5XJ2jo2vr6/BlYirOns5ymKxXNXrKNyIiMgV0aUoqSqV9WdL4UZERERcisKNiIiIuBSFGxERkSvUqFEjpkyZUu7+v/zyCyaTSbfQVxOFm8pitULKGiguNLoSEREpZTKZnB4TJ06s0OuuW7eOBx98sNz9e/ToQVpaGkFBQRV6v/JSiLLRreCV5cQ++Ph68PCF2K4Q3wvi+0B0O3DTb7OIiBHS0tLsX3/xxRf8/e9/Z9euXfY2f39/+9dWqxWLxYK7++X/zQ4PD7+iOjw9PYmKirqic6TiNHJTWbJTwLceFJ2G/Utg8Yvw72vh9Ubw2a2w4m1I3QwlV3d7m4hITWG1WjldWGzIYbVay1VjVFSU/QgKCsJkMtkf79y5k4CAAObPn0/Hjh3x8vLi119/Zd++fdx0001ERkbi7+9P586dWbRokcPrXnhZymQy8e9//5uhQ4fi6+tLs2bNmDt3rv35C0dUZs6cSXBwMAsWLCAhIQF/f38GDhzoEMaKi4t59NFHCQ4OJiwsjKeffppRo0YxZMiQCn/PMjMzGTlyJCEhIfj6+jJo0CD27Nljfz45OZnBgwcTEhKCn58fiYmJ/PDDD/ZzR4wYQXh4OD4+PjRr1owZM2ZUuJaqpCGFytLkGvjLXsjYAQeXw4FlcPBXyM+CPT/ZDgDvIIj7Q+nITm8IT4BK2EdDRKS6nSmy0OrvCwx57+0vDsDXs3J+hD3zzDO8+eabNG7cmJCQEA4dOsQNN9zAK6+8gpeXF5988gmDBw9m165dNGzY8JKv88ILL/CPf/yDN954g3feeYcRI0aQnJxMaGhomf1Pnz7Nm2++yX//+1/MZjN33XUXTz31FJ999hkAr7/+Op999hkzZswgISGBf/3rX8yZM4d+/fpV+LPec8897Nmzh7lz5xIYGMjTTz/NDTfcwPbt2/Hw8GDMmDEUFhaybNky/Pz82L59u31067nnnmP79u3Mnz+fevXqsXfvXs6cOVPhWqqSwk1lMpkgspXt6Ppn2yjN0W1woDTsJK+E/GzYNc92APiGQaM/2IJOo95Qr5ntdUREpFq8+OKLXHfddfbHoaGhtG3b1v74pZde4ttvv2Xu3LmMHTv2kq9zzz33MHz4cABeffVV3n77bdauXcvAgQPL7F9UVMT7779PkyZNABg7diwvvvii/fl33nmHCRMmMHToUACmTp1qH0WpiLOhZsWKFfTo0QOAzz77jNjYWObMmcOtt95KSkoKw4YNIykpCYDGjRvbz09JSaF9+/Z06tQJsI1e1VQKN1XJ7AbRbW1Hj7FgKYa0LXBgqW10J2U1nD4B27+zHQD+UefCTnwvCIlX2BGRGsnHw43tLw4w7L0ry9kf1mfl5uYyceJE5s2bR1paGsXFxZw5c4aUlBSnr9OmTRv7135+fgQGBpKRkXHJ/r6+vvZgAxAdHW3vn52dzdGjR+nSpYv9eTc3Nzp27EhJSckVfb6zduzYgbu7O127drW3hYWF0aJFC3bs2AHAo48+ysMPP8xPP/1E//79GTZsmP1zPfzwwwwbNoyNGzdy/fXXM2TIEHtIqmkUbqqTmzs06Gg7ej1hu7PqyIZzl7EOrYXcdNj2te0ACGxwLug06gXBscZ+BhGRUiaTqdIuDRnJz8/P4fFTTz3FwoULefPNN2natCk+Pj7ccsstFBY6vxv2wr2QTCaT0yBSVv/yziWqKvfffz8DBgxg3rx5/PTTT0yaNInJkyczbtw4Bg0aRHJyMj/88AMLFy7k2muvZcyYMbz55puG1lwWTfYwkrsnxHWHPn+Fe76HZ1Jg1P9B779Cw+5g9oCcw7BlFsx5GKa0hn+1hbnj4Lev4FS60Z9ARMTlrFixgnvuuYehQ4eSlJREVFQUBw8erNYagoKCiIyMZN26dfY2i8XCxo0bK/yaCQkJFBcXs2bNGnvbiRMn2LVrF61atbK3xcbG8tBDD/G///2PJ598kg8//ND+XHh4OKNGjeLTTz9lypQpTJ8+vcL1VKXaH7ldiYd36ShNb9vjwjzbpauDy23zdlI3QeZB27HxE1ufes1tIzpnR3b86hlVvYiIS2jWrBn/+9//GDx4MCaTieeee67Cl4Kuxrhx45g0aRJNmzalZcuWvPPOO2RmZpZr/6WtW7cSEBBgf2wymWjbti033XQTDzzwAB988AEBAQE888wz1K9fn5tuugmAxx57jEGDBtG8eXMyMzNZsmQJCQkJAPz973+nY8eOJCYmUlBQwPfff29/rqZRuKnJPP2g6bW2AyA/B1JW2S5hHVgG6Vvh+G7bsf4jW5+IxHNBp1FP8Akxrn4RkVrorbfe4r777qNHjx7Uq1ePp59+mpycnGqv4+mnnyY9PZ2RI0fi5ubGgw8+yIABA3Bzu/x8o969ezs8dnNzo7i4mBkzZjB+/Hj++Mc/UlhYSO/evfnhhx/sl8gsFgtjxozh8OHDBAYGMnDgQP75z38CtrV6JkyYwMGDB/Hx8aFXr17Mnj278j94JTBZjb7AV81ycnIICgoiOzubwMBAo8u5OqdP2u7AOjtnJ2P7BR1MEN2mdGSnt+1Sl3ct/8wiYpj8/HwOHDhAfHw83t7eRpdT55SUlJCQkMBtt93GSy+9ZHQ5VcLZn7Er+fmtkZvazDcUEv5oOwByj0Hyr6UjO8vhxB7b3VlpW2DVVDC5QUz7c2vsxHYDT19jP4OIiJQpOTmZn376iT59+lBQUMDUqVM5cOAAd955p9Gl1XgKN67EPxwSh9oOgJw020KCZ289zzwIR9bbjl//aZuw3KBT6Ro7vaBBZ9u8HxERMZzZbGbmzJk89dRTWK1WWrduzaJFi2rsPJeaRJel6pKsFNuIztkJyjmHHZ9397YFnPg+ttGgCP0FEpFzdFlKqpouS8mVC24I7UfYDqsVTu4/F3QOLofco7ZfDy6HJa9Am9vhmmdt54mIiNQSCjd1lckEYU1sR8d7bGHn+G7bfJ29i2D3j/DbbPj9f9DlQej1pG2Oj4iISA2nRfzExmSC8BbQ5QG48wt44GfbPBxLoW0y8r/awfK3oKhmbpImIiJylsKNlK1+R9tqySO+gcjWUJANi1+AtzvYFhC0FBtdoYiISJkUbuTSTCZo1h/+vByGfgBBsXAq1bb9w/s9YecPtstZIiIiNYjCjVye2Qxt74Cx6+H6V2yrHh/bCbOHw4xBkLLm8q8hIlKL9e3bl8cee8z+uFGjRkyZMsXpOSaTiTlz5lz1e1fW69QlCjdSfh7e0GMsPLoZ/vC47dbxlFXw8fUwewQc2210hSIiDgYPHszAgQPLfG758uWYTCZ+++23K37ddevW8eCDD15teQ4mTpxIu3btLmpPS0tj0KBBlfpeF5o5cybBwcFV+h7VSeFGrpxPMPSfCI9ugvZ3g8kMO7+H97rB/423LR4oIlIDjB49moULF3L48OGLnpsxYwadOnWiTZs2V/y64eHh+PpWzwrvUVFReHl5Vct7uQqFG6m4wBi4aSo8vApa3ABWC2yYCW+3h8UvQX620RWKSB33xz/+kfDwcGbOnOnQnpuby1dffcXo0aM5ceIEw4cPp379+vj6+pKUlMTnn3/u9HUvvCy1Z88eevfujbe3N61atWLhwoUXnfP000/TvHlzfH19ady4Mc899xxFRUWAbeTkhRdeYMuWLZhMJkwmk73mCy9Lbd26lWuuuQYfHx/CwsJ48MEHyc3NtT9/zz33MGTIEN58802io6MJCwtjzJgx9veqiJSUFG666Sb8/f0JDAzktttu4+jRo/bnt2zZQr9+/QgICCAwMJCOHTuyfv16wLaNxODBgwkJCcHPz4/ExER++OGHCtdSHlrnRq5eREsY/jkkr4KFf4fDa2H5m7D+Y+jzV+h0H7jrfx0iLsdqhaLTxry3h6/tpofLcHd3Z+TIkcycOZNnn30WU+k5X331FRaLheHDh5Obm0vHjh15+umnCQwMZN68edx99900adKELl26XPY9SkpKuPnmm4mMjGTNmjVkZ2c7zM85KyAggJkzZxITE8PWrVt54IEHCAgI4K9//Su3334727Zt48cff2TRokUABAUFXfQaeXl5DBgwgO7du7Nu3ToyMjK4//77GTt2rEOAW7JkCdHR0SxZsoS9e/dy++23065dOx544IHLfp6yPt/ZYLN06VKKi4sZM2YMt99+O7/88gsAI0aMoH379kybNg03Nzc2b95s32l8zJgxFBYWsmzZMvz8/Ni+fTv+/v5XXMeVULiRyhPXHUb/BDvnwaKJto07f3wGVk+Da56D1sNsk5NFxDUUnYZXY4x57/+XCp5+5ep633338cYbb7B06VL69u0L2C5JDRs2jKCgIIKCgnjqqafs/ceNG8eCBQv48ssvyxVuFi1axM6dO1mwYAExMbbfj1dfffWieTJ/+9vf7F83atSIp556itmzZ/PXv/4VHx8f/P39cXd3Jyoq6pLvNWvWLPLz8/nkk0/w87N9/qlTpzJ48GBef/11IiMjAQgJCWHq1Km4ubnRsmVLbrzxRhYvXlyhcLN48WK2bt3KgQMHiI2NBeCTTz4hMTGRdevW0blzZ1JSUvjLX/5Cy5YtAWjWrJn9/JSUFIYNG0ZSUhIAjRs3vuIarpR+0kjlMpls+1I9shr+OAX8oyArGf53P0zvA/t+NrpCEaljWrZsSY8ePfj4448B2Lt3L8uXL2f06NEAWCwWXnrpJZKSkggNDcXf358FCxaQkpJSrtffsWMHsbGx9mAD0L1794v6ffHFF/Ts2ZOoqCj8/f3529/+Vu73OP+92rZtaw82AD179qSkpIRdu3bZ2xITE3Fzc7M/jo6OJiMj44re6/z3jI2NtQcbgFatWhEcHMyOHTsAeOKJJ7j//vvp378/r732Gvv27bP3ffTRR3n55Zfp2bMnzz//fIUmcF8pQ0duGjVqRHJy8kXtjzzyCO+++26Z53z11Vc899xzHDx4kGbNmvH6669zww03VHWpcqXc3KHTvdDmNtvIzYp/Qfpv8N+h0LifbUJyTDujqxSRq+HhaxtBMeq9r8Do0aMZN24c7777LjNmzKBJkyb06dMHgDfeeIN//etfTJkyhaSkJPz8/HjssccoLCystHJXrVrFiBEjeOGFFxgwYABBQUHMnj2byZMnV9p7nO/sJaGzTCYTJSUlVfJeYLvT684772TevHnMnz+f559/ntmzZzN06FDuv/9+BgwYwLx58/jpp5+YNGkSkydPZty4cVVWj6EjN+vWrSMtLc1+nJ2Adeutt5bZf+XKlQwfPpzRo0ezadMmhgwZwpAhQ9i2bVt1li1XwtMPej9lu3282yNg9oD9S2yjON/cD5kHja5QRCrKZLL9HTfiKMd8m/PddtttmM1mZs2axSeffMJ9991nn3+zYsUKbrrpJu666y7atm1L48aN2b27/EtbJCQkcOjQIdLSzt0punr1aoc+K1euJC4ujmeffZZOnTrRrFmzi/5z7+npicViuex7bdmyhby8PHvbihUrMJvNtGjRotw1X4mzn+/QoUP2tu3bt5OVlUWrVq3sbc2bN+fxxx/np59+4uabb2bGjBn252JjY3nooYf43//+x5NPPsmHH35YJbWeZWi4CQ8PJyoqyn58//33Dmn6Qv/6178YOHAgf/nLX0hISOCll16iQ4cOTJ06tZorlyvmFwYDJ8G49ZB0m61t61fwTieY/wzkHTe2PhFxaf7+/tx+++1MmDCBtLQ07rnnHvtzzZo1Y+HChaxcuZIdO3bw5z//2eFOoMvp378/zZs3Z9SoUWzZsoXly5fz7LPPOvRp1qwZKSkpzJ49m3379vH222/z7bffOvRp1KgRBw4cYPPmzRw/fpyCgoKL3mvEiBF4e3szatQotm3bxpIlSxg3bhx33323fb5NRVksFjZv3uxw7Nixg/79+5OUlMSIESPYuHEja9euZeTIkfTp04dOnTpx5swZxo4dyy+//EJycjIrVqxg3bp1JCQkAPDYY4+xYMECDhw4wMaNG1myZIn9uapSY+bcFBYW8umnnzqk6QutWrWK/v37O7QNGDCAVatWXfJ1CwoKyMnJcTjEQCGNYNiH8Odl0OQaKCmCNdNsG3MuewMK8y73CiIiFTJ69GgyMzMZMGCAw/yYv/3tb3To0IEBAwbQt29foqKiGDJkSLlf12w28+2333LmzBm6dOnC/fffzyuvvOLQ509/+hOPP/44Y8eOpV27dqxcuZLnnnvOoc+wYcMYOHAg/fr1Izw8vMzb0X19fVmwYAEnT56kc+fO3HLLLVx77bWV8p/83Nxc2rdv73AMHjwYk8nEd999R0hICL1796Z///40btyYL774AgA3NzdOnDjByJEjad68ObfddhuDBg3ihRdeAGyhacyYMSQkJDBw4ECaN2/Oe++9d9X1OmOyWmvG5kBffvkld955JykpKQ5/6M7n6enJf/7zH4YPH25ve++993jhhRcumbInTpxo/w0+X3Z2NoGBgZVTvFTcviW228fTSyeY+UdB32dsiwO66WY+kZokPz+fAwcOEB8fj7e3t9HliAty9mcsJyeHoKCgcv38rjEjNx999BGDBg26ZLCpqAkTJpCdnW0/zr9mKDVAk37w4FIY9hEEx0FuOnz/mG214x3/p405RUTkitWI/xonJyezaNEi/ve//zntFxUVddEIzdGjR52uCeDl5aVlq2s6sxmSboGEwbB+Biz7h22NnC/uggZd4LoXbWvoiIiIlEONGLmZMWMGERER3HjjjU77de/encWLFzu0LVy4sMz1BKQWcveCbg/Z7qzq/RfbrZ6H18KMgfD5cMjYaXSFIiJSCxgebkpKSpgxYwajRo3C3d1xIGnkyJFMmDDB/nj8+PH8+OOPTJ48mZ07dzJx4kTWr1/P2LFjq7tsqUregXDN32wbc3a8F0xusOsHmNYdvhsD2UeMrlBERGoww8PNokWLSElJ4b777rvouZSUFId1A3r06MGsWbOYPn06bdu25euvv2bOnDm0bt26OkuW6hIQBYOnwJg1tktW1hLY9Cm80wEWPg9nsoyuUKROqiH3oYgLqqw/WzXmbqnqciWzraWGObTWdmdVSumt/z4h0Osp6Hw/eOjODZGqZrFY2L17NxEREYSFhRldjrig7OxsUlNTadq06UWrLF/Jz2+FG6ldrFbY/aNtY85jpXNwgmJtl7GSbgWzm9PTReTqpKWlkZWVRUREBL6+vpdcl0zkSpWUlJCamoqHhwcNGza86M+Wwo0TCjcuosQCm2fBklfhVOneNpGtof8L0PTaK16a3RCWYijKsy1cWHgaCnNtuywX5jkeRXm2UaqEP4FvqNFVSx1ntVpJT08nKyvL6FLEBZnNZuLj4/H09LzoOYUbJxRuXEzRGVjzPiz/JxRk29oa9bLdPl6/Q+W8R3Fh+UOIsz72x7m2PpaLl1Z3yuwBzQdA2+HQ7Hpwv/gvv0h1sVgsFBUVGV2GuBhPT0/M5rKnAyvcOKFw46JOn4Tlk2HtdLCU7uSbOBTa3wWWIichpIxQYg8ipSGkpIr/ATe5gad/6YaAvrZfPfzOPfbwg4zfIW3LuXN8w6D1LdD2DohpXztGqkREroLCjRMKNy4uK8V2qWrLbKCS/2i7edrW3vH0LzuEePrZnvPwddy9+JLnlB5unuULJ0e3w5bP4bcvbSs5nxXe0hZy2twOgZW7wreISE2hcOOEwk0dkb4Nlr4Gx/eUHTAqFEI8Lv++1cFSDPt/sQWdnd9Dcb6t3WSGxn1tl61a/tH2OUREXITCjRMKN+JS8rPh9zm2kaqUlefaPQMg8SZb0GnYw7bFhYhILaZw44TCjbiskwfgty9sIzqZB8+1BzeENnfYLl2FNTGsPBGRq6Fw44TCjbg8q9W20OGWz22jOgU5556L7WYLOYlDwSfYqApFRK6Ywo0TCjdSpxSdgZ3zbEFn38+2LSwA3Lyg5Y22y1ZNrgE3d+evIyJiMIUbJxRupM7KSYOtX8Lmz+HYjnPtfhHQ5jZb0InSPm0iUjMp3DihcCN1ntVqWzNny+ew9Ss4feLcc1FJtpCTdCv4RxhXo4jIBRRunFC4ETmPpQj2LLQFnd0/nlsA0eQGTftDu+HQfJA2JhURwyncOKFwI3IJp0/Ctm9st5UfWX+u3TsIEm+GdndCg85aDVlEDKFw44TCjUg5HNtduhryF5Bz5Fx7aBPbZau2t9tuMRcRqSYKN04o3IhcgZISOLjMNgl5x1zbnltnNeplCzqt/gReAcbVKCJ1gsKNEwo3IhVUkGsLOFs+hwPLse/d5eELCYNtQSe+N5jdDC1TRFyTwo0TCjcilSDrEPw22zaic3LfufbA+qW3ld8J4c2Nq09EXI7CjRMKNyKVyGqFw+thyyzbZOT87HPPxXSwTUJuPQx8Q42rUURcgsKNEwo3IlWkuAB2zbddttqzEKwWW7vZA5oPsAWdpteBu6exdYpIraRw44TCjUg1yD1mWyBwy+eQ/tu5dncfCIgEv/DSo955X1/w2DdM83dExE7hxgmFG5FqdvR32DzLFnZyj17BiSZbwLlcCPKrZ1tN2dNfa/CIuDCFGycUbkQMYimGrGTIOw55x0qP878+7zh9EvvdWOXl7l128HH4OuLcqJAuj4nUKlfy81tbAYtI9XBzh7AmtuNyLMVw5mTZISg34+KAVJQHxfmQfch2lId3sPORoPMfewdrVEikFlG4EZGax83dFjDKu3lnYV5p4DkOeRmXGBk6fu5XqwXys2zHiT2Xf32zu2MI8gkBkxkwnRd6zn5d+vjs1ybKaCvjnMu+zoVtXP3rmN1sCzB6BYJ3YOmvQaVfl/7q5nH53x+RGkbhRkRqP08/2xESd/m+JSVwJvOCS2GXuDyWdxwKcqCkGE6l2Y66xsP3gvBTGoDsbUFltF3QTxPDpZop3IhI3WI2g1+Y7aDl5fsX5cPp444h6EymbY2fs/OCzn59yTZKv6aMtoq8zoVtVOx1Soqh4BTk59hCnP3X7HNbbRSdth256Zf/vboUT/9LBKML24LK7ucZYPu+iZSTwo2IiDMe3hDUwHbUJZai0uCTfS7wlBWC7M/nXNyvON/2WoW5tuNUagWLMZ13+SzIMRh5BYJPMITEQ71mUK+5Fo0UhRsRESmDm4ctJFxNUCgudBKCci5oyy6jLQcshYDV9nVBDuQcvvz7+oTagk5YM6jX1BZ4wppBaLzmENURCjciIlI13D3BvZ5tInZFFeVfPgSdOQkn9sGJvba75c6chENrbMf5TG4Q0sgWduo1LQ0/pSHIr57uiHMhCjciIlJzeXjbjoDI8vUvzCsNOnvg+F44vvvc10V5to1eT+6D3Rec5x186dEed6/K/lRSxRRuRETEdXj6QXQb23E+q9V2t9vxPaWBZ6/t6xN7bLvc52fB4XW243wmMwTHlY72NIOwpudCkH+ERntqKK1QLCIidVvRGcfRnhOlAej4Xig8denzvILOu7x1/mhPY9tok1QqrVAsIiJSXh4+ENXadpzParXth1bmaE+Kbf7PkQ22w4EJghueu3vr/NGegCiN9lQDjdyIiIhcqaJ8OLm/dJRnT2nwKR3tKci+9HmeAY6Tmc+GnrAmtpBVXlYrlFhsaxWVFNtW3T7/sf1ry3nPn//cBY8dni+2LXbp8LgYrBe2XfD4/BqCG0KPcVf/+3wejdyIiIhUJQ9viGxlO85ntdoWejw7wnN8z7mvMw/aLnOlbrIdDkwQWN92h9mF4aOs4GK1VNcnrZgGXSo93FwJhRsREZHKYjKd2xetUU/H54oL4OSBC0Z7Si955WeVbw2f8jC7n3e42W6Bd2gzOz42mS8+x3zeOaYLHpf5Ghf0MXjRS4UbERGR6uDuBREtbcf5rFY4fcIWfKwl5QgXbo6/OoQXbVMBCjciIiLGMplKd5y/isUOxYEinoiIiLgUw8PNkSNHuOuuuwgLC8PHx4ekpCTWr19/yf6//PILJpPpoiM9/Sp2rBURERGXYehlqczMTHr27Em/fv2YP38+4eHh7Nmzh5CQkMueu2vXLodbwSIiIqqyVBEREaklDA03r7/+OrGxscyYMcPeFh8fX65zIyIiCA4OrqLKREREpLYy9LLU3Llz6dSpE7feeisRERG0b9+eDz/8sFzntmvXjujoaK677jpWrFhxyX4FBQXk5OQ4HCIiIuK6DA03+/fvZ9q0aTRr1owFCxbw8MMP8+ijj/Kf//znkudER0fz/vvv88033/DNN98QGxtL37592bhxY5n9J02aRFBQkP2IjY2tqo8jIiIiNYCh2y94enrSqVMnVq5caW979NFHWbduHatWrSr36/Tp04eGDRvy3//+96LnCgoKKCgosD/OyckhNjZW2y+IiIjUIley/YKhIzfR0dG0auW4dHVCQgIpKSlX9DpdunRh7969ZT7n5eVFYGCgwyEiIiKuy9Bw07NnT3bt2uXQtnv3buLi4q7odTZv3kx0dHRlliYiIiK1lKF3Sz3++OP06NGDV199ldtuu421a9cyffp0pk+fbu8zYcIEjhw5wieffALAlClTiI+PJzExkfz8fP7973/z888/89NPPxn1MURERKQGMTTcdO7cmW+//ZYJEybw4osvEh8fz5QpUxgxYoS9T1pamsNlqsLCQp588kmOHDmCr68vbdq0YdGiRfTr18+IjyAiIiI1jKETio1wJROSREREpGaoNROKRURERCqbwo2IiIi4FIUbERERcSkKNyIiIuJSFG5ERETEpSjciIiIiEtRuBERERGXonAjIiIiLkXhRkRERFyKwo2IiIi4FIUbERERcSkKNyIiIuJSFG5ERETEpSjciIiIiEtRuBERERGXonAjIiIiLkXhRkRERFyKwo2IiIi4FIUbERERcSnuRhfgKgqKLXyz4Qhe7maGdWxgdDkiIiJ1lsJNJfl+Sxr/79utRAR4cWObaLw93IwuSUREpE7SZalKMrhtDDFB3mScKuCrDYeNLkdERKTOUripJJ7uZv7cpwkA7/+yjyJLicEViYiI1E0KN5Xo9s6x1PP34kjWGb7bnGp0OSIiInWSwk0l8vZw4/5e8QC8t2QvlhKrwRWJiIjUPQo3leyubnEE+Xiw/3ge87elGV2OiIhInaNwU8n8vdy5t2cjAKb+vBerVaM3IiIi1Unhpgrc06MRfp5u7Ew/xeIdGUaXIyIiUqco3FSBYF9P7u7eCICpSzR6IyIiUp0UbqrI6D/E4+VuZvOhLFbuO2F0OSIiInWGwk0VCQ/wYniXhgC88/Meg6sRERGpOxRuqtCDvRvj4WZi9f6TrD940uhyRERE6gSFmyoUE+zDsA62TTSnLtlrcDUiIiJ1g8JNFXuoTxPMJvhl1zG2Hck2uhwRERGXp3BTxRrV8+NPbWMAeFejNyIiIlVO4aYaPNKvKQDzt6Wz5+gpg6sRERFxbQo31aB5ZAADEiMBeO+XfQZXIyIi4toUbqrJ2H7NAJi7JZXkE3kGVyMiIuK6FG6qSVKDIPo0D8dSYuX9pRq9ERERqSoKN9Vo3DW2uTdfbzhMWvYZg6sRERFxTYaHmyNHjnDXXXcRFhaGj48PSUlJrF+/3uk5v/zyCx06dMDLy4umTZsyc+bM6in2KnVqFErX+FCKLFamL9tvdDkiIiIuydBwk5mZSc+ePfHw8GD+/Pls376dyZMnExIScslzDhw4wI033ki/fv3YvHkzjz32GPfffz8LFiyoxsorbmzp6M3na1M4nltgcDUiIiKux2Q1cMvqZ555hhUrVrB8+fJyn/P0008zb948tm3bZm+74447yMrK4scff7zs+Tk5OQQFBZGdnU1gYGCF6r4aVquVIe+tZMuhLB7u24SnB7as9hpERERqmyv5+W3oyM3cuXPp1KkTt956KxEREbRv354PP/zQ6TmrVq2if//+Dm0DBgxg1apVZfYvKCggJyfH4TCSyWRibOm6N/9dlUz26SJD6xEREXE1hoab/fv3M23aNJo1a8aCBQt4+OGHefTRR/nPf/5zyXPS09OJjIx0aIuMjCQnJ4czZy6epDtp0iSCgoLsR2xsbKV/jit1bcsIWkYFkFtQzMyVB40uR0RExKUYGm5KSkro0KEDr776Ku3bt+fBBx/kgQce4P3336+095gwYQLZ2dn249ChQ5X22hVlNpsYUzp6M2PlAfIKig2uSERExHUYGm6io6Np1aqVQ1tCQgIpKSmXPCcqKoqjR486tB09epTAwEB8fHwu6u/l5UVgYKDDURPckBRN43p+ZJ0u4rM1yUaXIyIi4jIMDTc9e/Zk165dDm27d+8mLi7ukud0796dxYsXO7QtXLiQ7t27V0mNVcXNbOKhvk0AmL7sAPlFFoMrEhERcQ2GhpvHH3+c1atX8+qrr7J3715mzZrF9OnTGTNmjL3PhAkTGDlypP3xQw89xP79+/nrX//Kzp07ee+99/jyyy95/PHHjfgIV2Vo+/rUD/bheG4BX643/nKZiIiIKzA03HTu3Jlvv/2Wzz//nNatW/PSSy8xZcoURowYYe+TlpbmcJkqPj6eefPmsXDhQtq2bcvkyZP597//zYABA4z4CFfFw83MQ30aA/DB0v0UFpcYXJGIiEjtZ+g6N0Ywep2bC+UXWej1jyUcO1XAP4a14bbOxt/NJSIiUtPUmnVuBLw93Hiwl230ZtrSfVhK6lTWFBERqXQKNzXAnV0bEuzrwYHjeczbmmZ0OSIiIrWawk0N4Oflzn094wF49+e9lGj0RkREpMIUbmqIUT0aEeDlzq6jp1i04+jlTxAREZEyKdzUEEE+Htzd3ba+z7tL9lLH5nmLiIhUGoWbGmT0H+Lx9jCz5XA2y/ccN7ocERGRWknhpgYJ8/fizi620ZupS/YaXI2IiEjtpHBTwzzYuzGebmbWHjjJ2gMnjS5HRESk1lG4qWGigry5pVMDQKM3IiIiFaFwUwM93KcJbmYTy3Yf47fDWUaXIyIiUqso3NRAsaG+3NQ2BoCpP2v0RkRE5Eoo3NRQj/RrgskEP20/yq70U0aXIyIiUmso3NRQTSMCGNQ6CoD3ftHojYiISHkp3NRgj/RtCsD/bUnl4PE8g6sRERGpHRRuarDW9YO4pmUEJVaY9ss+o8sRERGpFRRuargx/WyjN//bdJgjWWcMrkZERKTmU7ip4TrGhdC9cRhFFivTl2r0RkRE5HIUbmqBcdfYRm9mrzvEsVMFBlcjIiJSsync1ALdm4TRvmEwBcUl/PvX/UaXIyIiUqMp3NQCJpOJsaVzbz5dlUzW6UKDKxIREam5KhRuDh06xOHDh+2P165dy2OPPcb06dMrrTBxdE3LCBKiA8krtDBjxUGjyxEREamxKhRu7rzzTpYsWQJAeno61113HWvXruXZZ5/lxRdfrNQCxeb80ZuZKw9yKr/I4IpERERqpgqFm23bttGlSxcAvvzyS1q3bs3KlSv57LPPmDlzZmXWJ+cZ2DqKxuF+ZJ8p4tPVKUaXIyIiUiNVKNwUFRXh5eUFwKJFi/jTn/4EQMuWLUlLS6u86sSBm9nEmNJViz/6dT/5RRaDKxIREal5KhRuEhMTef/991m+fDkLFy5k4MCBAKSmphIWFlapBYqjP7WLoUGID8dzC5m9VqM3IiIiF6pQuHn99df54IMP6Nu3L8OHD6dt27YAzJ071365SqqGh5uZh/o0AeCDZfspLC4xuCIREZGaxWS1Wq0VOdFisZCTk0NISIi97eDBg/j6+hIREVFpBVa2nJwcgoKCyM7OJjAw0OhyKiS/yEKfN5ZwNKeA125O4o4uDY0uSUREpEpdyc/vCo3cnDlzhoKCAnuwSU5OZsqUKezatatGBxtX4e3hxgO9GgMwbek+ii0avRERETmrQuHmpptu4pNPPgEgKyuLrl27MnnyZIYMGcK0adMqtUAp251dGxLq50nyidN8/5smcYuIiJxVoXCzceNGevXqBcDXX39NZGQkycnJfPLJJ7z99tuVWqCUzdfTndF/iAfg3SV7KSmp0NVFERERl1OhcHP69GkCAgIA+Omnn7j55psxm81069aN5OTkSi1QLu3u7nEEeLuzJyOXn7YfNbocERGRGqFC4aZp06bMmTOHQ4cOsWDBAq6//noAMjIyau0k3doo0NuDe3o0AmDqkj1UcG64iIiIS6lQuPn73//OU089RaNGjejSpQvdu3cHbKM47du3r9QCxbl7e8bj4+HGtiM5LN19zOhyREREDFehcHPLLbeQkpLC+vXrWbBggb392muv5Z///GelFSeXF+rnyYiutlvBp/68V6M3IiJS51Uo3ABERUXRvn17UlNT7TuEd+nShZYtW1ZacVI+D/RujKe7mfXJmaw5cNLockRERAxVoXBTUlLCiy++SFBQEHFxccTFxREcHMxLL71ESYnWXKlukYHe3NapAWC7c0pERKQuq1C4efbZZ5k6dSqvvfYamzZtYtOmTbz66qu88847PPfcc5Vdo5TDn3s3wc1sYvme42w+lGV0OSIiIoap0PYLMTExvP/++/bdwM/67rvveOSRRzhy5EilFVjZXGH7hUt56qstfL3hMP0TIvn3qE5GlyMiIlJpqnz7hZMnT5Y5t6Zly5acPKk5H0Z5uG8TTCZYtOMoO9JyjC5HRETEEBUKN23btmXq1KkXtU+dOpU2bdpcdVFSMU3C/bkhKRrQ3BsREam7KhRu/vGPf/Dxxx/TqlUrRo8ezejRo2nVqhUzZ87kzTffLPfrTJw4EZPJ5HA4u9tq5syZF/X39vauyEdwWWP7NQVg3tY09h/LNbgaERGR6lehcNOnTx92797N0KFDycrKIisri5tvvpnff/+d//73v1f0WomJiaSlpdmPX3/91Wn/wMBAh/7a7sFRQnQg/RMisFph2i/7jC5HRESk2rlX9MSYmBheeeUVh7YtW7bw0UcfMX369PIX4O5OVFRUufubTKYr6l8XjenXlEU7Mvh20xHG929GgxBfo0sSERGpNhVexK+y7Nmzh5iYGBo3bsyIESNISUlx2j83N5e4uDhiY2O56aab+P333532LygoICcnx+Fwde0bhvCHpvUoLrHywdL9RpcjIiJSrQwNN127dmXmzJn8+OOPTJs2jQMHDtCrVy9OnTpVZv8WLVrw8ccf89133/Hpp59SUlJCjx497Cskl2XSpEkEBQXZj9jY2Kr6ODXKmNK5N1+sP0RGTr7B1YiIiFSfCq1zcylbtmyhQ4cOWCyWCp2flZVFXFwcb731FqNHj75s/6KiIhISEhg+fDgvvfRSmX0KCgooKCiwP87JySE2NtYl17k5n9Vq5Zb3V7EhOZMHesXz7I2tjC5JRESkwq5knZsrmnNz8803O30+KyvrSl7uIsHBwTRv3py9e8t3G7OHhwft27d32t/LywsvL6+rqqs2MplMjL2mKffOWMdna1J4pG9TQvw8jS5LRESkyl3RZanzL++UdcTFxTFy5MgKF5Obm8u+ffuIjo4uV3+LxcLWrVvL3b+u6ds8nNb1AzldaGHGigNGlyMiIlItrmjkZsaMGZX65k899RSDBw8mLi6O1NRUnn/+edzc3Bg+fDgAI0eOpH79+kyaNAmAF198kW7dutG0aVOysrJ44403SE5O5v7776/UulyFyWRiTN+mPPzZRmasPMj9vRsT6O1hdFkiIiJVqsK3gleGw4cPM3z4cE6cOEF4eDh/+MMfWL16NeHh4QCkpKRgNp8bXMrMzOSBBx4gPT2dkJAQOnbsyMqVK2nVSvNJLmVAYhRNI/zZm5HLf1cl2ycai4iIuKpKnVBcG7jyxpmX8u2mwzz+xRZC/Tz59el++HoammlFRESuWJVvnCm1y+A2MTQM9eVkXiGfrz1kdDkiIiJVSuGmDnB3M/Nw3yYATF+2j4Liit2qLyIiUhso3NQRN3eoT1SgN0dzCvhmwxGjyxEREakyCjd1hJe7G3/u0xiAaUv3UmwpMbgiERGRqqFwU4fc0bkhYX6eHDp5hrlbUo0uR0REpEoo3NQhPp5ujO4VD8C7S/ZSUlKnbpQTEZE6QuGmjrm7WxyB3u7sO5bHj7+nG12OiIhIpVO4qWMCvD24p6dt9Gbqz3upY8sciYhIHaBwUwfd26MRvp5ubE/LYcmuDKPLERERqVQKN3VQiJ8nd3eLAzR6IyIirkfhpo4a3SseT3czG1OyWLX/hNHliIiIVBqFmzoqIsCbOzrHArbRGxEREVehcFOH/blPE9zNJlbuO8HGlEyjyxEREakUCjd1WP1gH27uUB+AdzV6IyIiLkLhpo57uG9TzCZYvDOD31OzjS5HRETkqinc1HHx9fz4Y5sYAN5bss/gakRERK6ewo0wpl9TAH7YlsbejFyDqxEREbk6CjdCi6gArmsVidUK7/2iuTciIlK7KdwIAGNLR2++25zKoZOnDa5GRESk4hRuBIC2scH0alYPS4mV95dq7o2IiNReCjdid3b05qv1h0nPzje4GhERkYpRuBG7ro3D6NIolEJLiUZvRESk1lK4EQdjrrGN3sxceZCxszaScUojOCIiUrso3IiD3s3qMbafbWG/739L49rJS/lsTTIlJdo5XEREageFG3FgMpl4akAL5o79A0n1gziVX8yz327j1g9WsSv9lNHliYiIXJbCjZSpdf0g5ozpyfODW+Hn6caG5ExufHs5byzYSX6RxejyRERELknhRi7JzWzi3p7xLHyiD9e1iqS4xMq7S/YxYMoyft1z3OjyREREyqRwI5cVE+zDhyM78cHdHYkK9Cb5xGnu+mgNj3+xmeO5BUaXJyIi4kDhRsptQGIUC5/ozT09GmEywbebjtD/raV8ue4QVqsmHIuISM2gcCNXJMDbg4l/SmTOIz1pFR1I1uki/vrNb9w+fbU23RQRkRpB4UYqpG1sMHPH9uTZGxLw8XBj7YGTDPrXMt5auFsTjkVExFAKN1Jh7m5mHujdmJ8e702/FuEUWay8vXgPN/xrOSv3acKxiIgYQ+FGrlpsqC8f39OZd+/sQHiAF/uP53Hnh2t46qstZOYVGl2eiIjUMQo3UilMJhM3tolm8ZN9uKtbQ0wm+HrDYa59aynfbDisCcciIlJtFG6kUgV6e/DykCS+fqgHLSIDOJlXyJNfbeGuj9Zw4Hie0eWJiEgdoHAjVaJjXAjfP/oH/jqwBV7uZlbsPcGAKct4Z/EeCotLjC5PRERcmMKNVBkPNzOP9G3Kwsf70KtZPQqLS5i8cDc3vL2cdQdPGl2eiIi4KIUbqXINw3z55L4u/OuOdtTz92RvRi63vr+KZ775jezTRUaXJyIiLkbhRqqFyWTipnb1WfREH+7oHAvA7HWHuPatX/hu8xFNOBYRkUqjcCPVKtjXk9eGteHLP3enaYQ/x3MLGT97M6NmrCPlxGmjyxMRERdgaLiZOHEiJpPJ4WjZsqXTc7766itatmyJt7c3SUlJ/PDDD9VUrVSmLvGh/PBoL568rjme7maW7T7G9VOWMu2XfRRZNOFYREQqzvCRm8TERNLS0uzHr7/+esm+K1euZPjw4YwePZpNmzYxZMgQhgwZwrZt26qxYqksnu5mxl3bjB/H96JHkzDyi0p4/cedDH7nVzamZBpdnoiI1FImq4GTHSZOnMicOXPYvHlzufrffvvt5OXl8f3339vbunXrRrt27Xj//ffL9Ro5OTkEBQWRnZ1NYGBgRcqWKmC1WvnfxiO8PG87maeLMJlgRNeG/HVgSwK9PYwuT0REDHYlP78NH7nZs2cPMTExNG7cmBEjRpCSknLJvqtWraJ///4ObQMGDGDVqlWXPKegoICcnByHQ2oek8nEsI4NWPxkX27p2ACrFT5dnUL/yUv5YWuaJhyLiEi5GRpuunbtysyZM/nxxx+ZNm0aBw4coFevXpw6darM/unp6URGRjq0RUZGkp6efsn3mDRpEkFBQfYjNja2Uj+DVK5QP0/evLUtsx7oSnw9PzJOFfDIZxsZ/Z/1HM7UhGMREbk8Q8PNoEGDuPXWW2nTpg0DBgzghx9+ICsriy+//LLS3mPChAlkZ2fbj0OHDlXaa0vV6dGkHvPH9+LRa5vh4Wbi550ZXPfWMj5ctp9iTTgWEREnDL8sdb7g4GCaN2/O3r17y3w+KiqKo0ePOrQdPXqUqKioS76ml5cXgYGBDofUDt4ebjxxXXPmj+9Fl0ahnCmy8MoPO/jT1BVsOZRldHkiIlJD1ahwk5uby759+4iOji7z+e7du7N48WKHtoULF9K9e/fqKE8M0jQigNkPduP1YUkE+XiwPS2Hoe+tYOLc38ktKDa6PBERqWEMDTdPPfUUS5cu5eDBg6xcuZKhQ4fi5ubG8OHDARg5ciQTJkyw9x8/fjw//vgjkydPZufOnUycOJH169czduxYoz6CVBOz2cTtnRuy+Mk+DGkXQ4kVZq48SP/JS1nw+6XnXImISN1jaLg5fPgww4cPp0WLFtx2222EhYWxevVqwsPDAUhJSSEtLc3ev0ePHsyaNYvp06fTtm1bvv76a+bMmUPr1q2N+ghSzer5ezHljvb8d3QX4sJ8Sc/J58//3cCDn6wnNeuM0eWJiEgNYOg6N0bQOjeuI7/Iwjs/7+GDpfspLrHi5+nGk9e3YFSPRriZTUaXJyIilahWrXMjUlHeHm78ZUBL5j3ai45xIeQVWnjx++0MfW8F245kG12eiIgYROFGar0WUQF89efuvDK0NQHe7vx2OJs/Tf2Vl7/fTp4mHIuI1Dm6LCUuJSMnnxe+386832xzter5ezG8SyzDuzQkJtjH4OpERKSiruTnt8KNuKQlOzN47rttHM60TTI2m+CalpHc1a0hvZuFY9acHBGRWkXhxgmFm7qjsLiEn7an8+nqZFbvP2lvjwvz5c4uDbm1Uyyhfp4GVigiIuWlcOOEwk3dtDfjFJ+uTuGbDYc5VToPx9PdzI1J0dzVrSEdGoZgMmk0R0SkplK4cULhpm47XVjM3M2pfLommW1Hzu0QnxAdyF3dGjKkXX38vNwNrFBERMqicOOEwo0AWK1WthzO5tPVyfzfllQKim2bcfp7uTO0fX3u6hZHi6gAg6sUEZGzFG6cULiRC2WdLuTrDYf5bE0KB47n2du7NAplRLeGDGwdhZe7m4EVioiIwo0TCjdyKSUlVlbuO8Gnq5NZuOMolhLbX40wP09u6xzLnV0aEhvqa3CVIiJ1k8KNEwo3Uh7p2fnMXpfC52tTOJpTAIDJBH2bh3NXtzj6tojQFg8iItVI4cYJhRu5EkWWEhbvOMqnq1P4de9xe3v9YB/u7NqQ2zvHUs/fy8AKRUTqBoUbJxRupKL2H8tl1poUvtpwmOwzRQB4uJkY2Dqau7o2pEt8qG4nFxGpIgo3TijcyNXKL7Lwf1tS+XRNClsOZdnbm0f6c1e3OIa2r0+At4dxBYqIuCCFGycUbqQybTtiu538u82pnCmyAODr6cZN7epzV7eGJMYEGVyhiIhrULhxQuFGqkL2mSK+3XiYT9eksDcj197evmEwd3eL44akaLw9dDu5iEhFKdw4oXAjVclqtbJ6/0k+XZPMgm3pFJfeTh7i68GtnWIZ0bUhcWF+BlcpIlL7KNw4oXAj1SXjVD5frjvErDUppGbn29t7NavH3d3iuKZlBO5uZgMrFBGpPRRunFC4kepmKbHy884MPl2dzLI9xzj7Ny46yJvhXRpyR+dYIgK9jS1SRKSGU7hxQuFGjJRy4jSfrU3mq/WHOZlXCIC72cT1iZHc1TWO7k3CdDu5iEgZFG6cULiRmiC/yML8bWl8ujqFDcmZ9vbG4X7c1TWOYR0bEOSj28lFRM5SuHFC4UZqmh1pOXy6Opk5m46QV2i7ndzbw8yf2sZwV7c42jQINrZAEZEaQOHGCYUbqalO5RcxZ3Mqn61OZmf6KXt7mwZB3NnFtjt5sK+ngRWKiBhH4cYJhRup6axWKxuSM/nv6mTmb02n0FIC2ObmdG8Sxo1J0VyfGEWon4KOiNQdCjdOKNxIbXIit4Av1x/mu81HHEZz3MwmujcOY1BSFAMSo7R5p4i4PIUbJxRupLbafyyX+dvS+WFrGr+n5tjbzSboGh/GDW2iGZAYSUSAbisXEdejcOOEwo24goPH8+xBZ+uRbHu7yQRdGoVyQ1I0A1tHEan1c0TERSjcOKFwI67m0MnT/LA1jR+2pTvsUm4yQae4EAa1jmZQUhTRQT7GFSkicpUUbpxQuBFXdjjzND9uS2fe1jQ2pWQ5PNehYTA3JEUzKCma+sEKOiJSuyjcOKFwI3VFatYZ5m9LZ/7WNNaft1AgQLvYYG5IimJQ62hiQ30NqlBEpPwUbpxQuJG6KD07nx+32S5drTt4kvP/1rdpEMQNSdHc0DqahmEKOiJSMyncOKFwI3VdRk4+C363Xbpae+AkJef9C9C6fiCDWkdzY1I0jer5GVekiMgFFG6cULgROefYqQIW/J7O/G1prNp3wiHoJEQHcmNSFIOSomkS7m9ckSIiKNw4pXAjUrYTuQX8tP0oP2xNY+W+E1jOSzotIgNsl66SomgWGWBglSJSVyncOKFwI3J5mXmF/LQ9nR+2prNi73GKzws6zSL8GZRku3TVPNIfk8lkYKUiUlco3DihcCNyZbJOF7KwdETn173HKbKc+yejcbgfNyZFM6h1NAnRAQo6IlJlFG6cULgRqbjsM0Us3mELOst2H7dv6gkQX8+PQa2juCEpmsSYQAUdEalUCjdOKNyIVI5T+UUs3pHBD1vT+GX3MQqLzwWdhqG+DEqK4sakaJLqBynoiMhVU7hxQuFGpPLlFhTz884MfvgtjSW7Mig4L+g0CPGxrYzcOop2scEKOiJSIQo3TijciFStvIJiluzKYP7WdH7emcGZIov9ueggb/o0D6d383B6Nq1HkI+HgZWKSG1SK8PNa6+9xoQJExg/fjxTpkwps8/MmTO59957Hdq8vLzIz88v9/so3IhUnzOFFn7ZlcEP29JZvOMopwvPBR03s4l2scH0bhZO7+b1aNMgGDezRnVEpGxX8vPbvZpqcmrdunV88MEHtGnT5rJ9AwMD2bVrl/2xhrhFai4fTzcGlW7WmV9kYdX+EyzbfYxlu4+x71geG5Iz2ZCcyT8X7SbY14M/NK1H7+bh9GkeTmSgt9Hli0gtZXi4yc3NZcSIEXz44Ye8/PLLl+1vMpmIioqqhspEpDJ5e7jRr0UE/VpEALYdzJftPs6y3cdYsfc4WaeL+P63NL7/LQ2AllEB9G4eTu9m4XSOD8HL3c3I8kWkFjE83IwZM4Ybb7yR/v37lyvc5ObmEhcXR0lJCR06dODVV18lMTHxkv0LCgooKCiwP87JyamUukXk6jQI8eXOrg25s2tDiiwlbD6UZR/V+e1INjvTT7Ez/RTTl+3Hx8ONbo1DbWGneTiN6/lp1FZELsnQcDN79mw2btzIunXrytW/RYsWfPzxx7Rp04bs7GzefPNNevTowe+//06DBg3KPGfSpEm88MILlVm2iFQyDzcznRuF0rlRKE9e34KTeYUs33PMNrKz5xjHThWwZNcxluw6BtjuwDo7qtOjaRiB3pqYLCLnGDah+NChQ3Tq1ImFCxfa59r07duXdu3aXXJC8YWKiopISEhg+PDhvPTSS2X2KWvkJjY2VhOKRWoJq9XKzvRTLC0d1Vl/MNNh8UA3s4mODUPo3dw2X6d1TBBmTUwWcTm14m6pOXPmMHToUNzczl1Ht1gsmEwmzGYzBQUFDs9dyq233oq7uzuff/55ud5Xd0uJ1G6nC4tZvf8ES3cdY9me4xw4nufwfKifJ72a1aN3s3B6Na9HRIAmJou4glpxt9S1117L1q1bHdruvfdeWrZsydNPP12uYGOxWNi6dSs33HBDVZUpIjWMr6c717SM5JqWkQAcOnnaPqqzct8JTuYV8t3mVL7bnApAQnRg6do69egUF4qnu9nI8kWkGtSYdW7g4stSI0eOpH79+kyaNAmAF198kW7dutG0aVOysrJ44403mDNnDhs2bKBVq1bleg+N3Ii4riJLCRuTM1m25xhLdx9j2xHHGwh8Pd3o3jiMPi1s83Ua1fMzqFIRuVK1YuSmPFJSUjCbz/0vKzMzkwceeID09HRCQkLo2LEjK1euLHewERHX5uFmpmvjMLo2DuMvA1pyPLeAX/fYbjdftucYx3MLWbwzg8U7MwDbHli9m9crnZhcD3+vGv1PooiUU40auakOGrkRqZtKSqxsT8th2Z5zE5OLS8798+duNtExLsS+iGCr6EBNTBapQWrFhGKjKNyICNg2+1y174R9VCf5xGmH5+v5e9KrdGuIXs3CqefvZVClIgIKN04p3IhIWQ4ez7OP6qzcd8JhHyyA1vUDS/fBCqdjXAgebpqYLFKdFG6cULgRkcspLC5hQ3Km/S6s7WmOE5P9PN3o2CiUrvGhdGscSlL9YN2FJVLFFG6cULgRkSuVcSqfX/ccZ+nuYyzfc5yTeYUOz3t7mOkYF0LX+DC6xofSNjYYbw/thSVSmRRunFC4EZGrUVJiZUd6Dmv2n2TNgROsPXCSzNNFDn083c20jw223bkVH0qHhiH4eCrsiFwNhRsnFG5EpDKVlFjZeyyXNftPsPrASdbsP8nx3AKHPh5uJto0CKZrfChdG4fRKS4EP912LnJFFG6cULgRkapktVrZfzzPPrKzZv9J0nPyHfq4mU20rh9Et/hQujYOpVOjUG3+KXIZCjdOKNyISHWyWq2knDzNmv0nWV0ado5knXHoYzZBq5hA+5ydLvGhBPt6GlSxSM2kcOOEwo2IGO1wpi3srD1gG905eMEaOwAtowLsl7G6xIdqnR2p8xRunFC4EZGaJj0733YJ68BJ1uw/wb5jeRf1aRrhbw873eJDiQjUbudStyjcOKFwIyI13bFTBfZRnTX7T7Lr6KmL+sTX8ysNO6F0jQ8jJtjHgEpFqo/CjRMKNyJS25zMK3QIOzvSc7jwX+4GIT62OTuNQ+kWH0ZsqA8mk/bGEtehcOOEwo2I1HbZp4tYd/Akaw/aLmNtS83BUuL4T3l0kLf9MlbX+FDi6/kp7EitpnDjhMKNiLia3IJi1h88aZ+z89vhbIcdzwHCA7wc5uw0jfBX2JFaReHGCYUbEXF1pwuL2ZicZb+MtflQFoWWEoc+YX6edG4USse4EDrEBZMYE6QtI6RGU7hxQuFGROqa/CILm1LOhZ2NKZkUFDuGHQ83E61igujQMJgODUNo3zCY+sGatyM1h8KNEwo3IlLXFRRb2Ho4m7UHT7IxOYtNKZmcuGAzUICIAC/al4adDnEhJNXX6I4YR+HGCYUbERFHVquVQyfPsDElk00pmWxMyWJ72sWTlN3NJlrFBNpHdjo0DKFBiEZ3pHoo3DihcCMicnlnCi1sPZLNxpRMNibbAs+FG4IC1PM/N7rTvmEwbRoE4eupTUGl8incOKFwIyJy5axWK4czz7DpUBYbk20jPL+n5lx0V5ab2URCdADtY20TlTs0DKFhqK9Gd+SqKdw4oXAjIlI58ossbCsd3dmUksXGlEyO5lw8uhPm50n7hsG0Lx3dadsgGD8vje7IlVG4cULhRkSkalitVtKy80svZWWx6VAmvx/Jueg2dLMJWkQFOtyZpUUG5XIUbpxQuBERqT4FxRZ+T80pvZRluzMrNTv/on4hvh62kZ3YYDrEhdCmQRAB3h4GVCw1lcKNEwo3IiLGSi8d3Tl7Z9bWI9kUXrDujskELSID7JeyOjQMoXE9P8xmje7UVQo3TijciIjULIXFJWxPKx3dKZ2wfCTrzEX9gnw8aBd77lJWu4bBBGp0p85QuHFC4UZEpObLyMlnY+llrE0pWWw5nHXRqsomEzSL8Kd9bAhJDYJIqh9Ey+gAvNy10KArUrhxQuFGRKT2KbKUsCMtx35X1saUTA6dvHh0x91sonlkAEn1g2h9NvBEBWhlZRegcOOEwo2IiGs4dqqATSmZbD5km7ez7Ug2maeLLurnbjbRLDKApPqBJNUPIrF+EK2iAxV4ahmFGycUbkREXJPVauVI1hm2Hclm65Fsth7JYduRbE6WsW+Wm9lEswh/Wte3je60Lg08Pp4KPDWVwo0TCjciInWH1WolNTufrYez+T012z7Cczz34sBjNkGziABa1w+idekoT6uYQG0nUUMo3DihcCMiUrdZrVbSc2yB5/xRnrL2zjKboEm4v310J6mBbYRHKyxXP4UbJxRuRETkQlarlaM5BfaRnbOhJ+PUxYHHVBp4WscE2i9rJdYPwl+Bp0op3DihcCMiIuWVkZNfOrJzLvCUtX+WyQTx9fxIOm8OT2JMoFZZrkQKN04o3IiIyNXIOJXP70dyHEJPWhlbSgA0rudHYv0gkuoHls7lCdLCgxWkcOOEwo2IiFS247mll7QOnws8Ze2hBdAozNd+OevsJa0gHwWey1G4cULhRkREqsOJ3AK2pdpuR99aGnrK2lYCIC7Ml9YxQSTWD6RVdCCJMUGEB3hVc8U1m8KNEwo3IiJilJN5hfa5O2d/PZxZduAJD/AiMeZc2GkVE0hcqG+d3TxU4cYJhRsREalJMvMK+T3VNofn99RstqflcOB4HmX9dPbzdCMhOpDEmHOBp1mkf53YT0vhxgmFGxERqenyCorZmX6K7aVh5/fUHHamn6Lwgs1Dwba9RNMIf3vYSYwJJCE60OXm8SjcOKFwIyIitVGxpYR9x/LYnpbN70dy7KEn+8zF+2kBxIb6nLukFR1IYv1AogK9MZlq52WtWhluXnvtNSZMmMD48eOZMmXKJft99dVXPPfccxw8eJBmzZrx+uuvc8MNN5T7fRRuRETEVZzdXuL3I+dGeLan5lxy4nKonyetogPtIzytogNpHO6PWy2Yx3MlP79rxHKK69at44MPPqBNmzZO+61cuZLhw4czadIk/vjHPzJr1iyGDBnCxo0bad26dTVVKyIiUjOYTCbqB/tQP9iH6xOj7O1ZpwvZnmYLOttTbaFn77FcTuYV8uve4/y697i9r7eHmRZRgedNXg6kZVTt3kTU8JGb3NxcOnTowHvvvcfLL79Mu3btLjlyc/vtt5OXl8f3339vb+vWrRvt2rXj/fffL9f7aeRGRETqovwiC7uPnrKHne1pOexIy+F0oeWivmYTNA73t4edVqUTmEP9PA2o3KZWjdyMGTOGG2+8kf79+/Pyyy877btq1SqeeOIJh7YBAwYwZ86cS55TUFBAQcG5pbJzcnKuql4REZHayNvDjTYNgmnTINjeZimxknwizx52bJe1bLum783IZW9GLnO3pNr7RwV6nxd2AmkVHURsqE+Nm8djaLiZPXs2GzduZN26deXqn56eTmRkpENbZGQk6enplzxn0qRJvPDCC1dVp4iIiCtyM5toHO5P43B/BreNsbdn5OTzu8NlrWwOnjhNek4+6Tn5LN6ZYe8b4O3ueHt6tO32dA83sxEfCTAw3Bw6dIjx48ezcOFCvL29q+x9JkyY4DDak5OTQ2xsbJW9n4iISG0XEehNRKA3/VpE2NtyC4rZkXYu7GxPy2F3ei6n8otZe+Akaw+ctPeNr+fHkqf6GlC5jWHhZsOGDWRkZNChQwd7m8ViYdmyZUydOpWCggLc3BwnM0VFRXH06FGHtqNHjxIVFcWleHl54eWlJaxFRESuhr+XO50bhdK5Uai9rbC4hH3Hcu13aZ0NPc0i/A2s1MBwc+2117J161aHtnvvvZeWLVvy9NNPXxRsALp3787ixYt57LHH7G0LFy6ke/fuVV2uiIiIXMDT3UxCtG3RQDra2qxWK3llTFKuToaFm4CAgItu3/bz8yMsLMzePnLkSOrXr8+kSZMAGD9+PH369GHy5MnceOONzJ49m/Xr1zN9+vRqr19EREQuZjKZ8Pcy9n4l42b7lENKSgppaWn2xz169GDWrFlMnz6dtm3b8vXXXzNnzhytcSMiIiJ2hq9zU920zo2IiEjtcyU/v2v0yI2IiIjIlVK4EREREZeicCMiIiIuReFGREREXIrCjYiIiLgUhRsRERFxKQo3IiIi4lIUbkRERMSlKNyIiIiIS1G4EREREZeicCMiIiIuxdhtOw1wdiutnJwcgysRERGR8jr7c7s8W2LWuXBz6tQpAGJjYw2uRERERK7UqVOnCAoKctqnzu0KXlJSQmpqKgEBAZhMpkp97ZycHGJjYzl06JB2HK8B9P2oWfT9qFn0/ah59D1xzmq1curUKWJiYjCbnc+qqXMjN2azmQYNGlTpewQGBuoPZg2i70fNou9HzaLvR82j78mlXW7E5ixNKBYRERGXonAjIiIiLkXhphJ5eXnx/PPP4+XlZXQpgr4fNY2+HzWLvh81j74nlafOTSgWERER16aRGxEREXEpCjciIiLiUhRuRERExKUo3IiIiIhLUbipJO+++y6NGjXC29ubrl27snbtWqNLqrMmTZpE586dCQgIICIigiFDhrBr1y6jy5JSr732GiaTiccee8zoUuqsI0eOcNdddxEWFoaPjw9JSUmsX7/e6LLqJIvFwnPPPUd8fDw+Pj40adKEl156qVz7J8mlKdxUgi+++IInnniC559/no0bN9K2bVsGDBhARkaG0aXVSUuXLmXMmDGsXr2ahQsXUlRUxPXXX09eXp7RpdV569at44MPPqBNmzZGl1JnZWZm0rNnTzw8PJg/fz7bt29n8uTJhISEGF1anfT6668zbdo0pk6dyo4dO3j99df5xz/+wTvvvGN0abWabgWvBF27dqVz585MnToVsO1fFRsby7hx43jmmWcMrk6OHTtGREQES5cupXfv3kaXU2fl5ubSoUMH3nvvPV5++WXatWvHlClTjC6rznnmmWdYsWIFy5cvN7oUAf74xz8SGRnJRx99ZG8bNmwYPj4+fPrppwZWVrtp5OYqFRYWsmHDBvr3729vM5vN9O/fn1WrVhlYmZyVnZ0NQGhoqMGV1G1jxozhxhtvdPi7ItVv7ty5dOrUiVtvvZWIiAjat2/Phx9+aHRZdVaPHj1YvHgxu3fvBmDLli38+uuvDBo0yODKarc6t3FmZTt+/DgWi4XIyEiH9sjISHbu3GlQVXJWSUkJjz32GD179qR169ZGl1NnzZ49m40bN7Ju3TqjS6nz9u/fz7Rp03jiiSf4f//v/7Fu3ToeffRRPD09GTVqlNHl1TnPPPMMOTk5tGzZEjc3NywWC6+88gojRowwurRaTeFGXNqYMWPYtm0bv/76q9Gl1FmHDh1i/PjxLFy4EG9vb6PLqfNKSkro1KkTr776KgDt27dn27ZtvP/++wo3Bvjyyy/57LPPmDVrFomJiWzevJnHHnuMmJgYfT+ugsLNVapXrx5ubm4cPXrUof3o0aNERUUZVJUAjB07lu+//55ly5bRoEEDo8upszZs2EBGRgYdOnSwt1ksFpYtW8bUqVMpKCjAzc3NwArrlujoaFq1auXQlpCQwDfffGNQRXXbX/7yF5555hnuuOMOAJKSkkhOTmbSpEkKN1dBc26ukqenJx07dmTx4sX2tpKSEhYvXkz37t0NrKzuslqtjB07lm+//Zaff/6Z+Ph4o0uq06699lq2bt3K5s2b7UenTp0YMWIEmzdvVrCpZj179rxoaYTdu3cTFxdnUEV12+nTpzGbHX8Uu7m5UVJSYlBFrkEjN5XgiSeeYNSoUXTq1IkuXbowZcoU8vLyuPfee40urU4aM2YMs2bN4rvvviMgIID09HQAgoKC8PHxMbi6uicgIOCi+U5+fn6EhYVpHpQBHn/8cXr06MGrr77Kbbfdxtq1a5k+fTrTp083urQ6afDgwbzyyis0bNiQxMRENm3axFtvvcV9991ndGm1mm4FryRTp07ljTfeID09nXbt2vH222/TtWtXo8uqk0wmU5ntM2bM4J577qneYqRMffv21a3gBvr++++ZMGECe/bsIT4+nieeeIIHHnjA6LLqpFOnTvHcc8/x7bffkpGRQUxMDMOHD+fvf/87np6eRpdXaynciIiIiEvRnBsRERFxKQo3IiIi4lIUbkRERMSlKNyIiIiIS1G4EREREZeicCMiIiIuReFGREREXIrCjYiIiLgUhRsRqfNMJhNz5swxugwRqSQKNyJiqHvuuQeTyXTRMXDgQKNLE5FaShtniojhBg4cyIwZMxzavLy8DKpGRGo7jdyIiOG8vLyIiopyOEJCQgDbJaNp06YxaNAgfHx8aNy4MV9//bXD+Vu3buWaa67Bx8eHsLAwHnzwQXJzcx36fPzxxyQmJuLl5UV0dDRjx451eP748eMMHToUX19fmjVrxty5c6v2Q4tIlVG4EZEa77nnnmPYsGFs2bKFESNGcMcdd7Bjxw4A8vLyGDBgACEhIaxbt46vvvqKRYsWOYSXadOmMWbMGB588EG2bt3K3Llzadq0qcN7vPDCC9x222389ttv3HDDDYwYMYKTJ09W6+cUkUpiFREx0KhRo6xubm5WPz8/h+OVV16xWq1WK2B96KGHHM7p2rWr9eGHH7ZarVbr9OnTrSEhIdbc3Fz78/PmzbOazWZrenq61Wq1WmNiYqzPPvvsJWsArH/729/sj3Nzc62Adf78+ZX2OUWk+mjOjYgYrl+/fkybNs2hLTQ01P519+7dHZ7r3r07mzdvBmDHjh20bdsWPz8/+/M9e/akpKSEXbt2YTKZSE1N5dprr3VaQ5s2bexf+/n5ERgYSEZGRkU/kogYSOFGRAzn5+d30WWiyuLj41Oufh4eHg6PTSYTJSUlVVGSiFQxzbkRkRpv9erVFz1OSEgAICEhgS1btpCXl2d/fsWKFZjNZlq0aEFAQACNGjVi8eLF1VqziBhHIzciYriCggLS09Md2tzd3alXrx4AX331FZ06deIPf/gDn332GWvXruWjjz4CYMSIETz//POMGjWKiRMncuzYMcaNG8fdd99NZGQkABMnTuShhx4iIiKCQYMGcerUKVasWMG4ceOq94OKSLVQuBERw/34449ER0c7tLVo0YKdO3cCtjuZZs+ezSOPPEJ0dDSff/45rVq1AsDX15cFCxYwfvx4OnfujK+vL8OGDeOtt96yv9aoUaPIz8/nn//8J0899RT16tXjlltuqb4PKCLVymS1Wq1GFyEicikmk4lvv/2WIUOGGF2KiNQSmnMjIiIiLkXhRkRERFyK5tyISI2mK+cicqU0ciMiIiIuReFGREREXIrCjYiIiLgUhRsRERFxKQo3IiIi4lIUbkRERMSlKNyIiIiIS1G4EREREZfy/wE540hql/uOUgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(training_loss, label='Training Loss')\n",
    "plt.plot(validation_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')\n",
    "torch.save(model.state_dict(), 'q2a_transformer_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Validation Loss: 6.578901571386001\n",
      "| Test Loss: 6.708190045458205\n"
     ]
    }
   ],
   "source": [
    "model_loaded = TransformerModel(src_vocab_size=SRC_VOCAB_SIZE, tgt_vocab_size=TGT_VOCAB_SIZE, \n",
    "            emb_dim=EMB_DIM, nhead=N_HEAD, num_encoder_layers=NUM_ENCODER_LAYERS, \n",
    "            num_decoder_layers=NUM_DECODER_LAYERS, dropout=DROPOUT)\n",
    "model_loaded.load_state_dict(torch.load('q2a_transformer_model.pth'))\n",
    "\n",
    "val_loss = evaluate(model_loaded, val_loader, criterion)\n",
    "print(f'| Validation Loss: {val_loss}')\n",
    "test_loss = evaluate(model_loaded, test_loader, criterion)\n",
    "print(f'| Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two wanted to talk about the implementation of the international agreement and about Teheran's destabilising activities in the Middle East.\n",
      " of the two proposals on the basis of the reform of the two - year programme , the Portuguese Presidency\n"
     ]
    }
   ],
   "source": [
    "def translate_sentence(model, sentence, token_transform, vocab_transform, device, max_length):\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    sentence_token = token_transform[SRC_LANGUAGE](sentence)\n",
    "    sentence_vocab = torch.tensor([vocab_transform[SRC_LANGUAGE][token] for token in sentence_token], dtype=torch.long)\n",
    "    sentence_vocab = sentence_vocab.unsqueeze(dim=0)\n",
    "    sentence_vocab = sentence_vocab.to(device)\n",
    "    src_mask = torch.zeros((sentence_vocab.shape[1], sentence_vocab.shape[1]),device=device).type(torch.bool)\n",
    "    memory = model.encode(sentence_vocab, src_mask)\n",
    "    translation = torch.tensor([vocab_transform[TGT_LANGUAGE]['<bos>']], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        tgt_mask = generate_square_subsequent_mask(translation.shape[1]).to(device)\n",
    "        out = model.decode(translation, memory, tgt_mask)\n",
    "        \n",
    "        out = model.linear(out)\n",
    "        out = out.softmax(dim=-1)\n",
    "        out = torch.argmax(out, dim=-1)\n",
    "        translation = torch.cat((translation, out[:, -1].unsqueeze(0)), dim=1)\n",
    "        if out[:, -1].item() == vocab_transform[TGT_LANGUAGE]['<eos>']:\n",
    "            break\n",
    "    translation = translation.squeeze(0)\n",
    "    translation = translation.cpu().numpy()\n",
    "    translation = [vocab_transform[TGT_LANGUAGE].lookup_token(token) for token in translation]\n",
    "    return ' '.join(translation).replace('<bos>', '').replace('<eos>', '')\n",
    "\n",
    "print(test_dataset[2]['translation']['en'])\n",
    "print(translate_sentence(model, test_dataset[2]['translation']['de'], token_transform, vocab_transform, device, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The crash came amid high winds and rain just days before millions arrive in the kingdom for the pilgrimage, which is required at least once in the life of every able-bodied Muslim.\n",
      " of the Erika , the United Nations Group has been able to take a report on the basis of a total of the euro , and a number of people who are in favour of the euro , and in\n"
     ]
    }
   ],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(device)\n",
    "    src_mask = src_mask.to(device)\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(device)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(1))\n",
    "                    .type(torch.bool)).to(device)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.linear(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word[-1].item()\n",
    "        ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = token_transform[SRC_LANGUAGE](src_sentence)\n",
    "    src = torch.tensor([[vocab_transform[SRC_LANGUAGE][token] for token in src]], dtype=torch.long)\n",
    "    num_tokens = src.shape[1]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n",
    "\n",
    "ind = 660\n",
    "print(test_dataset[ind]['translation']['en'])\n",
    "print(translate(model, test_dataset[ind]['translation']['de']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /mnt/disk1/sumdev/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /mnt/disk1/sumdev/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "from nltk.translate import meteor_score\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from bert_score import score\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "def calculate_bleu(reference_corpus, predicted_corpus):\n",
    "    return sacrebleu.corpus_bleu(predicted_corpus, [reference_corpus])\n",
    "\n",
    "def calculate_meteor(reference_corpus, predicted_corpus):\n",
    "    m_score = 0\n",
    "    for line in zip(reference_corpus, predicted_corpus):\n",
    "        ref = word_tokenize(line[0])\n",
    "        hypo = word_tokenize(line[1])\n",
    "        # m_score += meteor_score.meteor_score([ref], hypo)\n",
    "        m_score += meteor_score.single_meteor_score(ref, hypo)\n",
    "    return m_score / len(reference_corpus)\n",
    "\n",
    "def calculate_bert_score(reference_corpus, predicted_corpus):\n",
    "    _, _, bert_scores = score(predicted_corpus, reference_corpus, lang=\"en\", rescale_with_baseline=True)\n",
    "    return bert_scores.mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Scores on the Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_german_val, sentence_english_val, sentence_english_translated_val = [], [], []\n",
    "\n",
    "for i in range(len(validation_dataset)):\n",
    "    sentence_german_val.append(validation_dataset[i]['translation']['de'])\n",
    "    sentence_english_val.append(validation_dataset[i]['translation']['en'])\n",
    "    sentence_english_translated_val.append(translate(model, validation_dataset[i]['translation']['de']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.9478835493638972\n",
      "BLEU-1 Score: 23.710785263656526\n",
      "BLEU-2 Score: 3.0627456294890907\n",
      "BLEU-3 Score: 0.3182368727289999\n",
      "BLEU-4 Score: 0.060082613593691325\n",
      "METEOR Score: 0.12734655510735712\n",
      "BERT Score: -0.04137616232037544\n"
     ]
    }
   ],
   "source": [
    "bleu_score_val = calculate_bleu(sentence_english_translated_val, sentence_english_val)\n",
    "meteor_score_val = calculate_meteor(sentence_english_translated_val, sentence_english_val)\n",
    "bert_score_val = calculate_bert_score(sentence_english_translated_val, sentence_english_val)\n",
    "\n",
    "print(f'BLEU Score: {bleu_score_val.score}')\n",
    "print(f'BLEU-1 Score: {bleu_score_val.precisions[0]}')\n",
    "print(f'BLEU-2 Score: {bleu_score_val.precisions[1]}')\n",
    "print(f'BLEU-3 Score: {bleu_score_val.precisions[2]}')\n",
    "print(f'BLEU-4 Score: {bleu_score_val.precisions[3]}')\n",
    "print(f'METEOR Score: {meteor_score_val}')\n",
    "print(f'BERT Score: {bert_score_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Sentence 1\n",
      "German: Die Premierminister Indiens und Japans trafen sich in Tokio.\n",
      "English: India and Japan prime ministers meet in Tokyo\n",
      "Translated:  and foremost , the situation in Europe is being made . It is also\n",
      "==> Sentence 2\n",
      "German: Indiens neuer Premierminister Narendra Modi trifft bei seinem ersten wichtigen Auslandsbesuch seit seinem Wahlsieg im Mai seinen japanischen Amtskollegen Shinzo Abe in Toko, um wirtschaftliche und sicherheitspolitische Beziehungen zu besprechen.\n",
      "English: India's new prime minister, Narendra Modi, is meeting his Japanese counterpart, Shinzo Abe, in Tokyo to discuss economic and security ties, on his first major foreign visit since winning May's election.\n",
      "Translated:  - year , the Portuguese Presidency has had a great deal of progress in the past , and in particular , to the end of the United Kingdom , in the last few weeks , in\n",
      "==> Sentence 3\n",
      "German: Herr Modi befindet sich auf einer fnftgigen Reise nach Japan, um die wirtschaftlichen Beziehungen mit der drittgrten Wirtschaftsnation der Welt zu festigen.\n",
      "English: Mr Modi is on a five-day trip to Japan to strengthen economic ties with the third largest economy in the world.\n",
      "Translated:  of the world , we are talking about the situation of the world , and the same thing , is that we are talking about the situation of\n",
      "==> Sentence 4\n",
      "German: Plne fr eine strkere kerntechnische Zusammenarbeit stehen ganz oben auf der Tagesordnung.\n",
      "English: High on the agenda are plans for greater nuclear co-operation.\n",
      "Translated:  - General for the Council , we should be able to take a clear position on the\n",
      "==> Sentence 5\n",
      "German: Berichten zufolge hofft Indien darber hinaus auf einen Vertrag zur Verteidigungszusammenarbeit zwischen den beiden Nationen.\n",
      "English: India is also reportedly hoping for a deal on defence collaboration between the two nations.\n",
      "Translated:  of the two amendments have been made by the two rapporteurs . This is a very good thing . This\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('==> Sentence', i+1)\n",
    "    print(f'German: {sentence_german_val[i]}')\n",
    "    print(f'English: {sentence_english_val[i]}')\n",
    "    print(f'Translated: {sentence_english_translated_val[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Scores on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 1.004693931335485\n",
      "BLEU-1 Score: 23.599868993590043\n",
      "BLEU-2 Score: 2.9466623036649215\n",
      "BLEU-3 Score: 0.3475507991947833\n",
      "BLEU-4 Score: 0.0798214901220906\n",
      "METEOR Score: 0.12672719694687268\n",
      "BERT Score: -0.054380256682634354\n"
     ]
    }
   ],
   "source": [
    "sentence_german_test, sentence_english_test, sentence_english_translated_test = [], [], []\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    sentence_german_test.append(test_dataset[i]['translation']['de'])\n",
    "    sentence_english_test.append(test_dataset[i]['translation']['en'])\n",
    "    sentence_english_translated_test.append(translate(model, test_dataset[i]['translation']['de']))\n",
    "\n",
    "bleu_score_test = calculate_bleu(sentence_english_translated_test, sentence_english_test)\n",
    "meteor_score_test = calculate_meteor(sentence_english_translated_test, sentence_english_test)\n",
    "bert_score_test = calculate_bert_score(sentence_english_translated_test, sentence_english_test)\n",
    "\n",
    "print(f'BLEU Score: {bleu_score_test.score}')\n",
    "print(f'BLEU-1 Score: {bleu_score_test.precisions[0]}')\n",
    "print(f'BLEU-2 Score: {bleu_score_test.precisions[1]}')\n",
    "print(f'BLEU-3 Score: {bleu_score_test.precisions[2]}')\n",
    "print(f'BLEU-4 Score: {bleu_score_test.precisions[3]}')\n",
    "print(f'METEOR Score: {meteor_score_test}')\n",
    "print(f'BERT Score: {bert_score_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Sentence 1\n",
      "German: Obama empfngt Netanyahu\n",
      "English: Obama receives Netanyahu\n",
      "Translated:  of the cost of the cost of\n",
      "==> Sentence 2\n",
      "German: Das Verhltnis zwischen Obama und Netanyahu ist nicht gerade freundschaftlich.\n",
      "English: The relationship between Obama and Netanyahu is not exactly friendly.\n",
      "Translated:  and a number of things are not being made by a majority of the United\n",
      "==> Sentence 3\n",
      "German: Die beiden wollten ber die Umsetzung der internationalen Vereinbarung sowie ber Teherans destabilisierende Manahmen im Nahen Osten sprechen.\n",
      "English: The two wanted to talk about the implementation of the international agreement and about Teheran's destabilising activities in the Middle East.\n",
      "Translated:  of the two proposals on the basis of the reform of the two - year programme , the Portuguese Presidency and the Portuguese\n",
      "==> Sentence 4\n",
      "German: Bei der Begegnung soll es aber auch um den Konflikt mit den Palstinensern und die diskutierte Zwei-Staaten-Lsung gehen.\n",
      "English: The meeting was also planned to cover the conflict with the Palestinians and the disputed two state solution.\n",
      "Translated:  - and this is also the case of the proposed amendment , but also the possibility of the principle of the Treaty .\n",
      "==> Sentence 5\n",
      "German: Das Verhltnis zwischen Obama und Netanyahu ist seit Jahren gespannt.\n",
      "English: Relations between Obama and Netanyahu have been strained for years.\n",
      "Translated:  and a number of years ago , the European Parliament is still a long time\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('==> Sentence', i+1)\n",
    "    print(f'German: {sentence_german_test[i]}')\n",
    "    print(f'English: {sentence_english_test[i]}')\n",
    "    print(f'Translated: {sentence_english_translated_test[i]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
