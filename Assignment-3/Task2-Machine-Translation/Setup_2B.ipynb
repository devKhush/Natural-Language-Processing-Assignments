{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/sumdev/CourseWork/a3_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset and Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training dataset, only the first 50,000 examples\n",
    "train_dataset = load_dataset(\"wmt16\", \"de-en\", split=\"train[:50000]\")\n",
    "\n",
    "# Load validation and test datasets\n",
    "validation_dataset = load_dataset(\"wmt16\", \"de-en\", split=\"validation\")\n",
    "test_dataset = load_dataset(\"wmt16\", \"de-en\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2169, 2999)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(validation_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup- 2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Das Haus ist wunderbar.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google-t5/t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google-t5/t5-small\")\n",
    "\n",
    "prefix = \"translate English to German: \"\n",
    "input_ids = tokenizer(\"translate English to German: The house is wonderful.\", return_tensors=\"pt\").input_ids\n",
    "\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 54.54 87.5/66.7/50.0/50.0 (BP = 0.882 ratio = 0.889 hyp_len = 8 ref_len = 9)\n",
      "[87.5, 66.66666666666667, 50.0, 50.0]\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "\n",
    "hypotheses = [\"hello there general kenobi\",\"foo bar foo bar\"]\n",
    "references = [\n",
    "    \"hello there is general hello\",\n",
    "    \"foo bar foo bar\"\n",
    "]\n",
    "ret = sacrebleu.corpus_bleu(hypotheses, [references])\n",
    "print(ret)\n",
    "# Extract the BLEU-1, BLEU-2, BLEU-3, and BLEU-4 scores\n",
    "print(ret.precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /mnt/disk1/sumdev/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /mnt/disk1/sumdev/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "from nltk.translate import meteor_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from bert_score import score\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def calculate_bleu(predicted_corpus, reference_corpus):\n",
    "    return sacrebleu.corpus_bleu(predicted_corpus, [[i] for i in reference_corpus])\n",
    "\n",
    "def calculate_meteor(predicted_corpus, reference_corpus):\n",
    "    m_score = 0\n",
    "    for line in zip(predicted_corpus, reference_corpus):\n",
    "        hypo = word_tokenize(line[0])\n",
    "        ref = word_tokenize(line[1])\n",
    "        # m_score += meteor_score.meteor_score([ref], hypo)\n",
    "        m_score += meteor_score.single_meteor_score(ref, hypo)\n",
    "    return m_score / len(reference_corpus)\n",
    "\n",
    "def calculate_bert_score(predicted_corpus, reference_corpus):\n",
    "    p, r, f1 = score(predicted_corpus, reference_corpus, lang=\"de\")\n",
    "    return p.mean().item(), r.mean().item(), f1.mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate Engligh to German Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Translate English to German\n",
    "def translate_engligh_to_german(dataset):\n",
    "    reference_corpus = []\n",
    "    predicted_corpus = []\n",
    "\n",
    "    for example in dataset:\n",
    "        input_text = prefix + example[\"translation\"][\"en\"]\n",
    "        input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "        outputs = model.generate(input_ids)\n",
    "        predicted_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        reference_corpus.append(example[\"translation\"][\"de\"])\n",
    "        predicted_corpus.append(predicted_text)\n",
    "    return reference_corpus, predicted_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation score of T5-model on the Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 39.281465090051306\n",
      "BLEU-1: 100.0\n",
      "BLEU-2: 50.0\n",
      "BLEU-3: 28.571428571428573\n",
      "BLEU-4: 16.666666666666668\n",
      "METEOR Score: 0.3697782590377402\n",
      "BERT Scores:\n",
      "Precision in BERT Score: 0.8268641829490662\n",
      "Recall in BERT Score: 0.7662411332130432\n",
      "F1 Score in BERT Score: 0.7942118644714355\n"
     ]
    }
   ],
   "source": [
    "reference_corpus_val, predicted_corpus_val = translate_engligh_to_german(validation_dataset)\n",
    "\n",
    "bleu_score_ = calculate_bleu(predicted_corpus_val, reference_corpus_val)\n",
    "meteor_score_ = calculate_meteor(predicted_corpus_val, reference_corpus_val)\n",
    "bert_score_ = calculate_bert_score(predicted_corpus_val, reference_corpus_val)\n",
    "\n",
    "print(f'BLEU Score: {bleu_score_.score}')\n",
    "print(f'BLEU-1: {bleu_score_.precisions[0]}')\n",
    "print(f'BLEU-2: {bleu_score_.precisions[1]}')\n",
    "print(f'BLEU-3: {bleu_score_.precisions[2]}')\n",
    "print(f'BLEU-4: {bleu_score_.precisions[3]}')\n",
    "print(f'METEOR Score: {meteor_score_}')\n",
    "print(f'BERT Scores:')\n",
    "print(f'Precision in BERT Score: {bert_score_[0]}')\n",
    "print(f'Recall in BERT Score: {bert_score_[1]}')\n",
    "print(f'F1 Score in BERT Score: {bert_score_[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1\n",
      "Original: Die Premierminister Indiens und Japans trafen sich in Tokio.\n",
      "Translated: In Tokio treffen sich die Premierminister Indiens und Japans\n",
      "Example 2\n",
      "Original: Indiens neuer Premierminister Narendra Modi trifft bei seinem ersten wichtigen Auslandsbesuch seit seinem Wahlsieg im Mai seinen japanischen Amtskollegen Shinzo Abe in Toko, um wirtschaftliche und sicherheitspolitische Beziehungen zu besprechen.\n",
      "Translated: Der neue indische Premierminister Narendra Modi trifft sein japanisches Am\n",
      "Example 3\n",
      "Original: Herr Modi befindet sich auf einer fünftägigen Reise nach Japan, um die wirtschaftlichen Beziehungen mit der drittgrößten Wirtschaftsnation der Welt zu festigen.\n",
      "Translated: Herr Modi ist auf einer fünftägigen Reise nach Japan, um die wirtschaftliche\n",
      "Example 4\n",
      "Original: Pläne für eine stärkere kerntechnische Zusammenarbeit stehen ganz oben auf der Tagesordnung.\n",
      "Translated: Auf der Tagesordnung stehen Pläne für eine verstärkte nukleare Zusammenarbeit.\n",
      "Example 5\n",
      "Original: Berichten zufolge hofft Indien darüber hinaus auf einen Vertrag zur Verteidigungszusammenarbeit zwischen den beiden Nationen.\n",
      "Translated: Indien hofft ebenfalls auf eine Vereinbarung über die Zusammenarbeit im Verteidigungs\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f\"Example {i+1}\")\n",
    "    print(f\"Original: {reference_corpus_val[i]}\")\n",
    "    print(f\"Translated: {predicted_corpus_val[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation score of T5-model on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.0\n",
      "BLEU-1: 66.66666666666667\n",
      "BLEU-2: 25.0\n",
      "BLEU-3: 25.0\n",
      "BLEU-4: 0.0\n",
      "METEOR Score: 0.3889479564070389\n",
      "BERT Scores:\n",
      "Precision in BERT Score: 0.8345420956611633\n",
      "Recall in BERT Score: 0.7703850269317627\n",
      "F1 Score in BERT Score: 0.8000087141990662\n"
     ]
    }
   ],
   "source": [
    "reference_corpus_test, predicted_corpus_test = translate_engligh_to_german(test_dataset)\n",
    "\n",
    "bleu_score_ = calculate_bleu(predicted_corpus_test, reference_corpus_test)\n",
    "meteor_score_ = calculate_meteor(predicted_corpus_test, reference_corpus_test)\n",
    "bert_score_ = calculate_bert_score(predicted_corpus_test, reference_corpus_test)\n",
    "\n",
    "print(f'BLEU Score: {bleu_score_.score}')\n",
    "print(f'BLEU-1: {bleu_score_.precisions[0]}')\n",
    "print(f'BLEU-2: {bleu_score_.precisions[1]}')\n",
    "print(f'BLEU-3: {bleu_score_.precisions[2]}')\n",
    "print(f'BLEU-4: {bleu_score_.precisions[3]}')\n",
    "print(f'METEOR Score: {meteor_score_}')\n",
    "print(f'BERT Scores:')\n",
    "print(f'Precision in BERT Score: {bert_score_[0]}')\n",
    "print(f'Recall in BERT Score: {bert_score_[1]}')\n",
    "print(f'F1 Score in BERT Score: {bert_score_[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1\n",
      "Original: Obama empfängt Netanyahu\n",
      "Translated: Obama erhält Netanjahu\n",
      "Example 2\n",
      "Original: Das Verhältnis zwischen Obama und Netanyahu ist nicht gerade freundschaftlich.\n",
      "Translated: Die Beziehung zwischen Obama und Netanjahu ist nicht gerade freundlich.\n",
      "Example 3\n",
      "Original: Die beiden wollten über die Umsetzung der internationalen Vereinbarung sowie über Teherans destabilisierende Maßnahmen im Nahen Osten sprechen.\n",
      "Translated: Die beiden wollten über die Umsetzung des internationalen Abkommens und über Teherans\n",
      "Example 4\n",
      "Original: Bei der Begegnung soll es aber auch um den Konflikt mit den Palästinensern und die diskutierte Zwei-Staaten-Lösung gehen.\n",
      "Translated: Das Treffen sollte auch den Konflikt mit den Palästinensern und die ums\n",
      "Example 5\n",
      "Original: Das Verhältnis zwischen Obama und Netanyahu ist seit Jahren gespannt.\n",
      "Translated: Die Beziehungen zwischen Obama und Netanjahu sind seit Jahren angespannt.\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f\"Example {i+1}\")\n",
    "    print(f\"Original: {reference_corpus_test[i]}\")\n",
    "    print(f\"Translated: {predicted_corpus_test[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
