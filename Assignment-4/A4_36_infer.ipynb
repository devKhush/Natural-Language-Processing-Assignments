{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: ERC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 6740\n",
      "Length of val dataset: 843\n"
     ]
    }
   ],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, json_file, model_name='all-MiniLM-L6-v2'):\n",
    "        self.data = []\n",
    "        self.speaker_encoder = LabelEncoder()\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.emotion_class_to_idx = {'neutral': 0, 'joy': 1, 'sadness': 2, 'anger': 3, 'fear': 4, 'disgust': 5, 'surprise': 6}\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            for entry in data:\n",
    "                self.data.append(entry)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.data[idx]\n",
    "        speakers = torch.tensor(self.speaker_encoder.fit_transform(entry[\"speakers\"]), dtype=torch.long)\n",
    "        emotions = torch.tensor([self.emotion_class_to_idx[emotion] for emotion in entry[\"emotions\"]], dtype=torch.long)\n",
    "        utterance_embeddings = torch.tensor(self.model.encode(entry[\"utterances\"]), dtype=torch.float)\n",
    "        return torch.tensor(len(entry[\"speakers\"])), speakers, utterance_embeddings, emotions\n",
    "\n",
    "\n",
    "# Initialize the dataset and dataloader\n",
    "train_dataset = EmotionDataset(\"./Data/train_file.json\")\n",
    "val_dataset = EmotionDataset(\"./Data/val_file.json\")\n",
    "print('Length of train dataset:', len(train_dataset))\n",
    "print('Length of val dataset:', len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train_loader: 211\n",
      "Length of val_loader: 27\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def collate_fn(batch):\n",
    "    length, speakers, utterance_embeddings, emotions = zip(*batch)\n",
    "    length = torch.tensor(length, dtype=torch.long)\n",
    "    speakers = nn.utils.rnn.pad_sequence(speakers, batch_first=True)\n",
    "    utterance_embeddings = nn.utils.rnn.pad_sequence(utterance_embeddings, batch_first=True)        \n",
    "    emotions = nn.utils.rnn.pad_sequence(emotions, batch_first=True)\n",
    "    return length, speakers, utterance_embeddings, emotions\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "print('Length of train_loader:', len(train_loader))\n",
    "print('Length of val_loader:', len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples: 6740\n",
      "Val Samples: 843\n"
     ]
    }
   ],
   "source": [
    "with open(\"./Data/train_file.json\", 'r') as f:\n",
    "    train_json = json.load(f)\n",
    "with open(\"./Data/val_file.json\", 'r') as f:\n",
    "    val_json = json.load(f)\n",
    "print('Train Samples:', len(train_json))\n",
    "print('Val Samples:', len(val_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GRUClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(GRUClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(2*hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(2, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "sentence_emb_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "emotion_class_to_idx = {'neutral': 0, 'joy': 1, 'sadness': 2, 'anger': 3, 'fear': 4, 'disgust': 5, 'surprise': 6}\n",
    "emotion_idx_to_class = {v: k for k, v in emotion_class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_EPOCH = 10\n",
    "INPUT_SIZE = 384\n",
    "HIDDEN_SIZE = 128\n",
    "OUTPUT_SIZE = 7\n",
    "\n",
    "trained_model = GRUClassifier(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE).to(DEVICE)\n",
    "trained_model.load_state_dict(torch.load(\"M1.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True emotions: ['anger', 'joy', 'neutral', 'joy', 'joy']\n",
      "Predicted emotions: ['joy', 'surprise', 'joy', 'joy', 'joy']\n",
      "Accuracy of Prediction: 0.4\n",
      "F1 Score of Prediction: 0.14285714285714288\n",
      "\n",
      "---------------------------------\n",
      "Detecting Speaker Emotion Flips\n",
      "speakers in conversation:\n",
      "['Phoebe', 'Monica', 'Phoebe', 'Monica', 'Phoebe']\n",
      "Predicted Emotions:\n",
      "['joy', 'surprise', 'joy', 'joy', 'joy']\n",
      "\n",
      "Monica changed emotion from surprise to joy\n"
     ]
    }
   ],
   "source": [
    "def conversation_inference_m1(model:GRUClassifier, conversation:dict):\n",
    "    model.eval()\n",
    "    utterances = conversation[\"utterances\"]\n",
    "    true_emotions = conversation[\"emotions\"]\n",
    "    speakers = conversation[\"speakers\"]\n",
    "    \n",
    "    # Obtain the utterance embeddings and predict the emotions of all the utterances\n",
    "    utterance_embeddings = torch.tensor(sentence_emb_model.encode(utterances), dtype=torch.float)\n",
    "    utterance_embeddings = utterance_embeddings.unsqueeze(0).to(DEVICE)\n",
    "    predicted_emotions = model(utterance_embeddings)\n",
    "    _, predicted_emotions = torch.max(predicted_emotions, 2)\n",
    "    predicted_emotions = predicted_emotions.squeeze(0)\n",
    "    predicted_emotions = [emotion_idx_to_class[emotion.item()] for emotion in predicted_emotions]\n",
    "\n",
    "    # Show the Accuracy and F1 Score of the prediction\n",
    "    accuracy = accuracy_score(true_emotions, predicted_emotions)\n",
    "    f1 = f1_score(true_emotions, predicted_emotions, average='macro')\n",
    "    print('True emotions:', true_emotions)\n",
    "    print('Predicted emotions:', predicted_emotions)\n",
    "    print('Accuracy of Prediction:', accuracy)\n",
    "    print('F1 Score of Prediction:', f1)\n",
    "    \n",
    "    # Predicting the Emotion Flips\n",
    "    print('\\n---------------------------------')\n",
    "    print('Detecting Speaker Emotion Flips')\n",
    "    print('speakers in conversation:')\n",
    "    print(speakers)\n",
    "    print('Predicted Emotions:')\n",
    "    print(predicted_emotions)\n",
    "    print()\n",
    "    speakers_prev_emotion = {speaker:None for speaker in speakers}\n",
    "    for i, (speaker, true_emotion, predicted_emotion) in enumerate(zip(speakers, true_emotions, predicted_emotions)):\n",
    "        if speakers_prev_emotion[speaker] is None:\n",
    "            speakers_prev_emotion[speaker] = predicted_emotion\n",
    "        else:\n",
    "            if speakers_prev_emotion[speaker] != predicted_emotion:\n",
    "                print(f'{speaker} changed emotion from {speakers_prev_emotion[speaker]} to {predicted_emotion}')\n",
    "                speakers_prev_emotion[speaker] = predicted_emotion\n",
    "    return    \n",
    "\n",
    "ind = 200\n",
    "conversation = val_json[ind]\n",
    "conversation_inference_m1(trained_model, conversation)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9578074507651972\n",
      "Validation Macro-F1 Score: 0.876162606551148\n",
      "Validation Weighted-F1 Score: 0.9572777261377494\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for _, _, utterance_embeddings, emotions in val_loader:\n",
    "    emotions = emotions.to(DEVICE)\n",
    "    utterance_embeddings = utterance_embeddings.to(DEVICE)\n",
    "    trained_model = trained_model.to(DEVICE)\n",
    "    outputs = trained_model(utterance_embeddings)\n",
    "    loss = criterion(outputs.view(-1, outputs.size(-1)), emotions.view(-1))\n",
    "    _, preds = torch.max(outputs, 2)\n",
    "    target_expanded = emotions.view(-1).cpu().numpy()\n",
    "    preds_expanded = preds.view(-1).cpu().numpy()\n",
    "    y_true.extend(target_expanded)\n",
    "    y_pred.extend(preds_expanded)\n",
    "print('Validation Accuracy:', accuracy_score(y_true, y_pred))\n",
    "print('Validation Macro-F1 Score:', f1_score(y_true, y_pred, average='macro'))\n",
    "print('Validation Weighted-F1 Score:', f1_score(y_true, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TransformerGRUClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_dim):\n",
    "        super(TransformerGRUClassifier, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_dim = output_dim\n",
    "        self.tranformer_encoder_layer = nn.TransformerEncoderLayer(d_model=input_size, nhead=input_size//4)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.tranformer_encoder_layer, num_layers=2)\n",
    "        self.GRU = nn.GRU(input_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        transform_out = self.transformer_encoder(x) + x\n",
    "        h0 = torch.zeros(2, x.size(0), self.hidden_size).to(x.device)\n",
    "        gru_out, _ = self.GRU(transform_out, h0)\n",
    "        gru_out = self.fc(gru_out)\n",
    "        return gru_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "sentence_emb_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "emotion_class_to_idx = {'neutral': 0, 'joy': 1, 'sadness': 2, 'anger': 3, 'fear': 4, 'disgust': 5, 'surprise': 6}\n",
    "emotion_idx_to_class = {v: k for k, v in emotion_class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_EPOCH = 10\n",
    "INPUT_SIZE = 384\n",
    "HIDDEN_SIZE = 128\n",
    "OUTPUT_SIZE = 7\n",
    "\n",
    "trained_model = TransformerGRUClassifier(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE).to(DEVICE)\n",
    "trained_model.load_state_dict(torch.load(\"M2.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True emotions: ['anger', 'joy', 'neutral', 'joy', 'joy']\n",
      "Predicted emotions: ['anger', 'joy', 'neutral', 'joy', 'anger']\n",
      "Accuracy of Prediction: 0.8\n",
      "F1 Score of Prediction: 0.8222222222222223\n",
      "\n",
      "---------------------------------\n",
      "Detecting Speaker Emotion Flips\n",
      "speakers in conversation:\n",
      "['Phoebe', 'Monica', 'Phoebe', 'Monica', 'Phoebe']\n",
      "Predicted Emotions:\n",
      "['anger', 'joy', 'neutral', 'joy', 'anger']\n",
      "\n",
      "Phoebe changed emotion from anger to neutral\n",
      "Phoebe changed emotion from neutral to anger\n"
     ]
    }
   ],
   "source": [
    "def conversation_inference_m2(model:TransformerGRUClassifier, conversation:dict):\n",
    "    model.eval()\n",
    "    utterances = conversation[\"utterances\"]\n",
    "    true_emotions = conversation[\"emotions\"]\n",
    "    speakers = conversation[\"speakers\"]\n",
    "    \n",
    "    # Obtain the utterance embeddings and predict the emotions of all the utterances\n",
    "    utterance_embeddings = torch.tensor(sentence_emb_model.encode(utterances), dtype=torch.float)\n",
    "    utterance_embeddings = utterance_embeddings.unsqueeze(0).to(DEVICE)\n",
    "    predicted_emotions = model(utterance_embeddings)\n",
    "    _, predicted_emotions = torch.max(predicted_emotions, 2)\n",
    "    predicted_emotions = predicted_emotions.squeeze(0)\n",
    "    predicted_emotions = [emotion_idx_to_class[emotion.item()] for emotion in predicted_emotions]\n",
    "\n",
    "    # Show the Accuracy and F1 Score of the prediction\n",
    "    accuracy = accuracy_score(true_emotions, predicted_emotions)\n",
    "    f1 = f1_score(true_emotions, predicted_emotions, average='macro')\n",
    "    print('True emotions:', true_emotions)\n",
    "    print('Predicted emotions:', predicted_emotions)\n",
    "    print('Accuracy of Prediction:', accuracy)\n",
    "    print('F1 Score of Prediction:', f1)\n",
    "    \n",
    "    # Predicting the Emotion Flips\n",
    "    print('\\n---------------------------------')\n",
    "    print('Detecting Speaker Emotion Flips')\n",
    "    print('speakers in conversation:')\n",
    "    print(speakers)\n",
    "    print('Predicted Emotions:')\n",
    "    print(predicted_emotions)\n",
    "    print()\n",
    "    speakers_prev_emotion = {speaker:None for speaker in speakers}\n",
    "    for i, (speaker, true_emotion, predicted_emotion) in enumerate(zip(speakers, true_emotions, predicted_emotions)):\n",
    "        if speakers_prev_emotion[speaker] is None:\n",
    "            speakers_prev_emotion[speaker] = predicted_emotion\n",
    "        else:\n",
    "            if speakers_prev_emotion[speaker] != predicted_emotion:\n",
    "                print(f'{speaker} changed emotion from {speakers_prev_emotion[speaker]} to {predicted_emotion}')\n",
    "                speakers_prev_emotion[speaker] = predicted_emotion\n",
    "    return    \n",
    "\n",
    "ind = 200\n",
    "conversation = val_json[ind]\n",
    "conversation_inference_m2(trained_model, conversation)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9964026583744894\n",
      "Validation F1 Score: 0.98930110022866\n",
      "Validation Weighted-F1 Score: 0.9963929671576677\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for _, _, utterance_embeddings, emotions in val_loader:\n",
    "    emotions = emotions.to(DEVICE)\n",
    "    utterance_embeddings = utterance_embeddings.to(DEVICE)\n",
    "    trained_model = trained_model.to(DEVICE)\n",
    "    outputs = trained_model(utterance_embeddings)\n",
    "    loss = criterion(outputs.view(-1, outputs.size(-1)), emotions.view(-1))\n",
    "    _, preds = torch.max(outputs, 2)\n",
    "    target_expanded = emotions.view(-1).cpu().numpy()\n",
    "    preds_expanded = preds.view(-1).cpu().numpy()\n",
    "    y_true.extend(target_expanded)\n",
    "    y_pred.extend(preds_expanded)\n",
    "print('Validation Accuracy:', accuracy_score(y_true, y_pred))\n",
    "print('Validation F1 Score:', f1_score(y_true, y_pred, average='macro'))\n",
    "print('Validation Weighted-F1 Score:', f1_score(y_true, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2:  ERF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples: 6740\n",
      "Val Samples: 843\n"
     ]
    }
   ],
   "source": [
    "with open(\"./Data/train_file.json\", 'r') as f:\n",
    "    train_json = json.load(f)\n",
    "with open(\"./Data/val_file.json\", 'r') as f:\n",
    "    val_json = json.load(f)\n",
    "print('Train Samples:', len(train_json))\n",
    "print('Val Samples:', len(val_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 6740\n",
      "Length of val dataset: 843\n"
     ]
    }
   ],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, json_file, model_name=\"all-MiniLM-L6-v2\"):\n",
    "        self.data = []\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.speaker_encoder = LabelEncoder()\n",
    "        self.emotion_class_to_idx = {'neutral': 0, 'joy': 1, 'sadness': 2, 'anger': 3, 'fear': 4, 'disgust': 5, 'surprise': 6}\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            for entry in data:\n",
    "                self.data.append(entry)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.data[idx]\n",
    "        context_size = 5\n",
    "        speakers = torch.tensor(self.speaker_encoder.fit_transform(entry[\"speakers\"]), dtype=torch.long)[-(context_size):]\n",
    "        emotions = torch.tensor([self.emotion_class_to_idx[emotion] for emotion in entry[\"emotions\"]], dtype=torch.long)[-(context_size):]\n",
    "        utterance_embeddings = torch.tensor(self.model.encode(entry[\"utterances\"]), dtype=torch.float)[-(context_size):]\n",
    "        utterance_embeddings = utterance_embeddings + utterance_embeddings[-1]\n",
    "        triggers = [a if a != None else 0.0 for a in entry['triggers']]\n",
    "        triggers = torch.tensor(triggers, dtype=torch.long)[-(context_size):]\n",
    "        return torch.tensor(len(entry[\"speakers\"])), speakers, emotions, utterance_embeddings, triggers\n",
    "\n",
    "\n",
    "# Initialize the dataset and dataloader\n",
    "model_name = 'all-MiniLM-L6-v2' # all-mpnet-base-v2\n",
    "train_dataset = EmotionDataset(\"./Data/train_file.json\", model_name=model_name)\n",
    "val_dataset = EmotionDataset(\"./Data/val_file.json\", model_name=model_name)\n",
    "print('Length of train dataset:', len(train_dataset))\n",
    "print('Length of val dataset:', len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train_loader: 211\n",
      "Length of val_loader: 27\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def collate_fn(batch):\n",
    "    length, speakers, emotions, utterance_embeddings, triggers = zip(*batch)\n",
    "    length = torch.tensor(length, dtype=torch.long)\n",
    "    speakers = nn.utils.rnn.pad_sequence(speakers, batch_first=True)\n",
    "    emotions = nn.utils.rnn.pad_sequence(emotions, batch_first=True)\n",
    "    triggers = nn.utils.rnn.pad_sequence(triggers, batch_first=True)\n",
    "    utterance_embeddings = nn.utils.rnn.pad_sequence(utterance_embeddings, batch_first=True)        \n",
    "    return length, speakers, emotions, utterance_embeddings, triggers\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "print('Length of train_loader:', len(train_loader))\n",
    "print('Length of val_loader:', len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_dim):\n",
    "        super(CustomClassifier, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_dim = output_dim\n",
    "        self.input_layer = nn.Linear(input_size, input_size)\n",
    "        self.tranformer_encoder_layer = nn.TransformerEncoderLayer(d_model=input_size, nhead=input_size//8)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.tranformer_encoder_layer, num_layers=2)\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.transformer_encoder(x) + x\n",
    "        h0 = torch.zeros(2, x.size(0), self.hidden_size).to(x.device)\n",
    "        x, _ = self.gru(x, h0)\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "sentence_emb_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_EPOCH = 10\n",
    "INPUT_SIZE = 384\n",
    "HIDDEN_SIZE = 128\n",
    "OUTPUT_SIZE = 2\n",
    "\n",
    "trained_model = CustomClassifier(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE).to(DEVICE)\n",
    "trained_model.load_state_dict(torch.load(\"M3.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speakers: ['Joey', 'Chandler', 'Joey', 'Chandler', 'Joey']\n",
      "Utterances: [\"Oh God. Uh, okay, here's the thing, this is the thing, okay, the thing is...\", 'What is the thing?', \"Okay. I went down to the \\x91Mattress King' showroom and, and I saw Janice, kissing her ex-husband.\", 'What?', 'They were in his office.']\n",
      "Emotions: ['neutral', 'sadness', 'sadness', 'surprise', 'neutral']\n",
      "\n",
      "True triggers: tensor([0, 0, 0, 1, 0])\n",
      "Predicted triggers: tensor([0, 0, 1, 0, 0])\n",
      "Accuracy of Prediction: 0.6\n",
      "F1 Score of Prediction: 0.375\n"
     ]
    }
   ],
   "source": [
    "def emotion_flip_inference_m3(model:CustomClassifier, conversation:dict):\n",
    "    model.eval()\n",
    "    utterances = conversation[\"utterances\"]\n",
    "    true_emotions = conversation[\"emotions\"]\n",
    "    speakers = conversation[\"speakers\"]\n",
    "    triggers = conversation[\"triggers\"]\n",
    "    context_size = 5\n",
    "    \n",
    "    # Obtain the utterance embeddings and predict the emotion flip reason of last utterance for context size 5\n",
    "    utterance_embeddings = torch.tensor(sentence_emb_model.encode(utterances), dtype=torch.float)[-(context_size):]\n",
    "    utterance_embeddings = utterance_embeddings + utterance_embeddings[-1]\n",
    "    triggers_true_label = [a if a != None else 0.0 for a in triggers]\n",
    "    triggers_true_label = torch.tensor(triggers_true_label, dtype=torch.long)[-(context_size):]\n",
    "    \n",
    "    # Obtain the predicted triggers\n",
    "    utterance_embeddings = utterance_embeddings.unsqueeze(0).to(DEVICE)\n",
    "    triggers_predictions = model(utterance_embeddings)\n",
    "    _, triggers_predictions = torch.max(triggers_predictions, 2)\n",
    "    triggers_predictions = triggers_predictions.view(-1).cpu()\n",
    "\n",
    "    print('Speakers:', speakers[-context_size:])\n",
    "    print('Utterances:', utterances[-context_size:])\n",
    "    print('Emotions:', true_emotions[-context_size:])\n",
    "    print()\n",
    "    print('True triggers:', triggers_true_label)\n",
    "    print('Predicted triggers:', triggers_predictions)\n",
    "\n",
    "    # Show the Accuracy and F1 Score of the prediction\n",
    "    accuracy = accuracy_score(triggers_true_label.cpu().numpy(), triggers_predictions.numpy())\n",
    "    f1 = f1_score(triggers_true_label.cpu().numpy(), triggers_predictions.numpy(), average='macro')\n",
    "    print('Accuracy of Prediction:', accuracy)\n",
    "    print('F1 Score of Prediction:', f1)\n",
    "    \n",
    "\n",
    "ind = 0\n",
    "conversation = val_json[ind]\n",
    "emotion_flip_inference_m3(trained_model, conversation)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.829655990510083\n",
      "Validation Macro-F1 Score: 0.7525376103387056\n",
      "Validation Weighted-F1 Score: 0.8226422491770297\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "for _, speakers, emotions, utterance_embeddings, targets in val_loader:\n",
    "    utterance_embeddings = utterance_embeddings.to(DEVICE)\n",
    "    targets = targets.to(DEVICE)\n",
    "    trained_model = trained_model.to(DEVICE)\n",
    "    outputs = trained_model(utterance_embeddings)\n",
    "    _, preds = torch.max(outputs, 2)\n",
    "    target_expanded = targets.view(-1).cpu().numpy()\n",
    "    preds_expanded = preds.view(-1).cpu().numpy()\n",
    "    y_true.extend(target_expanded)\n",
    "    y_pred.extend(preds_expanded)\n",
    "print('Validation Accuracy:', accuracy_score(y_true, y_pred))\n",
    "print('Validation Macro-F1 Score:', f1_score(y_true, y_pred, average='macro'))\n",
    "print('Validation Weighted-F1 Score:', f1_score(y_true, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218196a1729b42828b25aeb9b7147f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "316df6bdf1b541c2bb5876aa40b1261e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b34f9389cd7454886831892bc27784b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "210ff4cdd2884e75998349a8b242190a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3b024141d64c5e8647edea59712100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b6ea249778462d98e0b8eb7301822b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6628c4624e74cc4bf874087aec92374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b52401c05bb4e35992eda67123e89b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d871add8544cd8a51b5b7dc1b6eb99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f9504b84b5469fb0eb62ea13010cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab12e509d9d4a35b4d1cfa210345e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 6740\n",
      "Length of val dataset: 843\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, json_file, model_name=\"all-MiniLM-L6-v2\"):\n",
    "        self.data = []\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.speaker_encoder = LabelEncoder()\n",
    "        self.emotion_class_to_idx = {'neutral': 0, 'joy': 1, 'sadness': 2, 'anger': 3, 'fear': 4, 'disgust': 5, 'surprise': 6}\n",
    "\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            for entry in data:\n",
    "                self.data.append(entry)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.data[idx]\n",
    "        speakers = torch.tensor(self.speaker_encoder.fit_transform(entry[\"speakers\"]), dtype=torch.long)\n",
    "        emotions = torch.tensor([self.emotion_class_to_idx[emotion] for emotion in entry[\"emotions\"]], dtype=torch.long)\n",
    "        utterance_embeddings = torch.tensor(self.model.encode(entry[\"utterances\"]), dtype=torch.float)\n",
    "        triggers = np.array(entry[\"triggers\"], dtype=float)\n",
    "        np.nan_to_num(triggers, copy=False)\n",
    "        triggers = torch.tensor(triggers, dtype=torch.int64)\n",
    "        return torch.tensor(len(entry[\"speakers\"])), speakers, emotions, utterance_embeddings, triggers\n",
    "\n",
    "\n",
    "# Initialize the dataset and dataloader\n",
    "model_name = 'all-mpnet-base-v2' # all-MiniLM-L6-v2\n",
    "train_dataset = EmotionDataset(\"./Data/train_file.json\", model_name=model_name)\n",
    "val_dataset = EmotionDataset(\"./Data/val_file.json\", model_name=model_name)\n",
    "print('Length of train dataset:', len(train_dataset))\n",
    "print('Length of val dataset:', len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train_loader: 211\n",
      "Length of val_loader: 27\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "def collate_fn(batch):\n",
    "    length, speakers, emotions, utterance_embeddings, triggers = zip(*batch)\n",
    "    length = torch.tensor(length, dtype=torch.long)\n",
    "    speakers = nn.utils.rnn.pad_sequence(speakers, batch_first=True)\n",
    "    emotions = nn.utils.rnn.pad_sequence(emotions, batch_first=True)\n",
    "    triggers = nn.utils.rnn.pad_sequence(triggers, batch_first=True)\n",
    "    utterance_embeddings = nn.utils.rnn.pad_sequence(utterance_embeddings, batch_first=True)\n",
    "    return length, speakers, emotions, utterance_embeddings, triggers   \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "print('Length of train_loader:', len(train_loader))\n",
    "print('Length of val_loader:', len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.fc(lstm_out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "sentence_emb_model = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_EPOCH = 10\n",
    "INPUT_SIZE = 768\n",
    "HIDDEN_SIZE = 256\n",
    "OUTPUT_SIZE = 2\n",
    "\n",
    "trained_model = BiLSTMClassifier(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE).to(DEVICE)\n",
    "trained_model.load_state_dict(torch.load(\"M4.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speakers: ['Joey', 'Chandler', 'Joey', 'Chandler', 'Joey']\n",
      "Utterances: [\"Oh God. Uh, okay, here's the thing, this is the thing, okay, the thing is...\", 'What is the thing?', \"Okay. I went down to the \\x91Mattress King' showroom and, and I saw Janice, kissing her ex-husband.\", 'What?', 'They were in his office.']\n",
      "Emotions: ['neutral', 'sadness', 'sadness', 'surprise', 'neutral']\n",
      "\n",
      "True triggers: tensor([0, 0, 0, 1, 0])\n",
      "Predicted triggers: tensor([0, 0, 0, 1, 1])\n",
      "Accuracy of Prediction: 0.8\n",
      "F1 Score of Prediction: 0.7619047619047619\n"
     ]
    }
   ],
   "source": [
    "def emotion_flip_inference_m4(model:BiLSTMClassifier, conversation:dict):\n",
    "    model.eval()\n",
    "    utterances = conversation[\"utterances\"]\n",
    "    true_emotions = conversation[\"emotions\"]\n",
    "    speakers = conversation[\"speakers\"]\n",
    "    triggers = conversation[\"triggers\"]\n",
    "    context_size = 5\n",
    "    \n",
    "    # Obtain the utterance embeddings and predict the emotion flip reason of last utterance for context size 5\n",
    "    utterance_embeddings = torch.tensor(sentence_emb_model.encode(utterances), dtype=torch.float)[-(context_size):]\n",
    "    utterance_embeddings = utterance_embeddings + utterance_embeddings[-1]\n",
    "    triggers_true_label = [a if a != None else 0.0 for a in triggers]\n",
    "    triggers_true_label = torch.tensor(triggers_true_label, dtype=torch.long)[-(context_size):]\n",
    "    \n",
    "    # Obtain the predicted triggers\n",
    "    utterance_embeddings = utterance_embeddings.unsqueeze(0).to(DEVICE)\n",
    "    triggers_predictions = model(utterance_embeddings)\n",
    "    _, triggers_predictions = torch.max(triggers_predictions, 2)\n",
    "    triggers_predictions = triggers_predictions.view(-1).cpu()\n",
    "\n",
    "    print('Speakers:', speakers[-context_size:])\n",
    "    print('Utterances:', utterances[-context_size:])\n",
    "    print('Emotions:', true_emotions[-context_size:])\n",
    "    print()\n",
    "    print('True triggers:', triggers_true_label)\n",
    "    print('Predicted triggers:', triggers_predictions)\n",
    "\n",
    "    # Show the Accuracy and F1 Score of the prediction\n",
    "    accuracy = accuracy_score(triggers_true_label.cpu().numpy(), triggers_predictions.numpy())\n",
    "    f1 = f1_score(triggers_true_label.cpu().numpy(), triggers_predictions.numpy(), average='macro')\n",
    "    print('Accuracy of Prediction:', accuracy)\n",
    "    print('F1 Score of Prediction:', f1)\n",
    "    \n",
    "\n",
    "ind = 0\n",
    "conversation = val_json[ind]\n",
    "emotion_flip_inference_m4(trained_model, conversation)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.961038961038961\n",
      "Validation Macro-F1 Score: 0.83866663167085\n",
      "Validation Weighted-F1 Score: 0.9602079532016111\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "for _, speakers, emotions, utterance_embeddings, targets in val_loader:\n",
    "    utterance_embeddings = utterance_embeddings.to(DEVICE)\n",
    "    targets = targets.to(DEVICE)\n",
    "    trained_model = trained_model.to(DEVICE)\n",
    "    outputs = trained_model(utterance_embeddings)\n",
    "    _, preds = torch.max(outputs, 2)\n",
    "    target_expanded = targets.view(-1).cpu().numpy()\n",
    "    preds_expanded = preds.view(-1).cpu().numpy()\n",
    "    y_true.extend(target_expanded)\n",
    "    y_pred.extend(preds_expanded)\n",
    "print('Validation Accuracy:', accuracy_score(y_true, y_pred))\n",
    "print('Validation Macro-F1 Score:', f1_score(y_true, y_pred, average='macro'))\n",
    "print('Validation Weighted-F1 Score:', f1_score(y_true, y_pred, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a3_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
