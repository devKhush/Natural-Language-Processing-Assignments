{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: ERC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a6af93a77143d999f28fcde28ee676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0543556902443529d8ba5708da11940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f5508f432f4a0f9321349ca7781ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c33508574846ee88a05f8ffc45114c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c884ed75174740aa16a5c02671586f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50df7684a339497299c408a2e5d9d935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f4cb6ee24804cf982397d7e258466f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ee8435c25947d19a6d0f87d203bf86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd34ba277b14ae39f3319c8525cc083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9abf699a7684d7486d5d9ee6fb88072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ce8f10ffd94374afb48bebbb6c31f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Data/train_file.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 24\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mlen\u001b[39m(entry[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeakers\u001b[39m\u001b[38;5;124m\"\u001b[39m])), speakers, utterance_embeddings, emotions\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Initialize the dataset and dataloader\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mEmotionDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../Data/train_file.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m EmotionDataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../Data/val_file.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLength of train dataset:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(train_dataset))\n",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m, in \u001b[0;36mEmotionDataset.__init__\u001b[1;34m(self, json_file, model_name)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m SentenceTransformer(model_name)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotion_class_to_idx \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjoy\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msadness\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manger\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfear\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m4\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisgust\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m5\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurprise\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m6\u001b[39m}\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      8\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Data/train_file.json'"
     ]
    }
   ],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, json_file, model_name='all-MiniLM-L6-v2'):\n",
    "        self.data = []\n",
    "        self.speaker_encoder = LabelEncoder()\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.emotion_class_to_idx = {'neutral': 0, 'joy': 1, 'sadness': 2, 'anger': 3, 'fear': 4, 'disgust': 5, 'surprise': 6}\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            for entry in data:\n",
    "                self.data.append(entry)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.data[idx]\n",
    "        speakers = torch.tensor(self.speaker_encoder.fit_transform(entry[\"speakers\"]), dtype=torch.long)\n",
    "        emotions = torch.tensor([self.emotion_class_to_idx[emotion] for emotion in entry[\"emotions\"]], dtype=torch.long)\n",
    "        utterance_embeddings = torch.tensor(self.model.encode(entry[\"utterances\"]), dtype=torch.float)\n",
    "        return torch.tensor(len(entry[\"speakers\"])), speakers, utterance_embeddings, emotions\n",
    "\n",
    "\n",
    "# Initialize the dataset and dataloader\n",
    "train_dataset = EmotionDataset(\"../Data/train_file.json\")\n",
    "val_dataset = EmotionDataset(\"../Data/val_file.json\")\n",
    "print('Length of train dataset:', len(train_dataset))\n",
    "print('Length of val dataset:', len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train_loader: 211\n",
      "Length of val_loader: 27\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def collate_fn(batch):\n",
    "    length, speakers, utterance_embeddings, emotions = zip(*batch)\n",
    "    length = torch.tensor(length, dtype=torch.long)\n",
    "    speakers = nn.utils.rnn.pad_sequence(speakers, batch_first=True)\n",
    "    utterance_embeddings = nn.utils.rnn.pad_sequence(utterance_embeddings, batch_first=True)        \n",
    "    emotions = nn.utils.rnn.pad_sequence(emotions, batch_first=True)\n",
    "    return length, speakers, utterance_embeddings, emotions\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "print('Length of train_loader:', len(train_loader))\n",
    "print('Length of val_loader:', len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples: 6740\n",
      "Val Samples: 843\n"
     ]
    }
   ],
   "source": [
    "with open(\"../Data/train_file.json\", 'r') as f:\n",
    "    train_json = json.load(f)\n",
    "with open(\"../Data/val_file.json\", 'r') as f:\n",
    "    val_json = json.load(f)\n",
    "print('Train Samples:', len(train_json))\n",
    "print('Val Samples:', len(val_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GRUClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(GRUClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(2*hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(2, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "sentence_emb_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "emotion_class_to_idx = {'neutral': 0, 'joy': 1, 'sadness': 2, 'anger': 3, 'fear': 4, 'disgust': 5, 'surprise': 6}\n",
    "emotion_idx_to_class = {v: k for k, v in emotion_class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_EPOCH = 10\n",
    "INPUT_SIZE = 384\n",
    "HIDDEN_SIZE = 128\n",
    "OUTPUT_SIZE = 7\n",
    "\n",
    "trained_model = GRUClassifier(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE).to(DEVICE)\n",
    "trained_model.load_state_dict(torch.load(\"M1.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True emotions: ['anger', 'joy', 'neutral', 'joy', 'joy']\n",
      "Predicted emotions: ['joy', 'surprise', 'joy', 'joy', 'joy']\n",
      "Accuracy of Prediction: 0.4\n",
      "F1 Score of Prediction: 0.14285714285714285\n",
      "\n",
      "---------------------------------\n",
      "Detecting Speaker Emotion Flips\n",
      "speakers in conversation:\n",
      "['Phoebe', 'Monica', 'Phoebe', 'Monica', 'Phoebe']\n",
      "Predicted Emotions:\n",
      "['joy', 'surprise', 'joy', 'joy', 'joy']\n",
      "\n",
      "Monica changed emotion from surprise to joy\n"
     ]
    }
   ],
   "source": [
    "def conversation_inference_m1(model:GRUClassifier, conversation:dict):\n",
    "    model.eval()\n",
    "    utterances = conversation[\"utterances\"]\n",
    "    true_emotions = conversation[\"emotions\"]\n",
    "    speakers = conversation[\"speakers\"]\n",
    "    \n",
    "    # Obtain the utterance embeddings and predict the emotions of all the utterances\n",
    "    utterance_embeddings = torch.tensor(sentence_emb_model.encode(utterances), dtype=torch.float)\n",
    "    utterance_embeddings = utterance_embeddings.unsqueeze(0).to(DEVICE)\n",
    "    predicted_emotions = model(utterance_embeddings)\n",
    "    _, predicted_emotions = torch.max(predicted_emotions, 2)\n",
    "    predicted_emotions = predicted_emotions.squeeze(0)\n",
    "    predicted_emotions = [emotion_idx_to_class[emotion.item()] for emotion in predicted_emotions]\n",
    "\n",
    "    # Show the Accuracy and F1 Score of the prediction\n",
    "    accuracy = accuracy_score(true_emotions, predicted_emotions)\n",
    "    f1 = f1_score(true_emotions, predicted_emotions, average='macro')\n",
    "    print('True emotions:', true_emotions)\n",
    "    print('Predicted emotions:', predicted_emotions)\n",
    "    print('Accuracy of Prediction:', accuracy)\n",
    "    print('F1 Score of Prediction:', f1)\n",
    "    \n",
    "    # Predicting the Emotion Flips\n",
    "    print('\\n---------------------------------')\n",
    "    print('Detecting Speaker Emotion Flips')\n",
    "    print('speakers in conversation:')\n",
    "    print(speakers)\n",
    "    print('Predicted Emotions:')\n",
    "    print(predicted_emotions)\n",
    "    print()\n",
    "    speakers_prev_emotion = {speaker:None for speaker in speakers}\n",
    "    for i, (speaker, true_emotion, predicted_emotion) in enumerate(zip(speakers, true_emotions, predicted_emotions)):\n",
    "        if speakers_prev_emotion[speaker] is None:\n",
    "            speakers_prev_emotion[speaker] = predicted_emotion\n",
    "        else:\n",
    "            if speakers_prev_emotion[speaker] != predicted_emotion:\n",
    "                print(f'{speaker} changed emotion from {speakers_prev_emotion[speaker]} to {predicted_emotion}')\n",
    "                speakers_prev_emotion[speaker] = predicted_emotion\n",
    "    return    \n",
    "\n",
    "ind = 200\n",
    "conversation = val_json[ind]\n",
    "conversation_inference_m1(trained_model, conversation)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9578074507651972\n",
      "Validation Macro-F1 Score: 0.876162606551148\n",
      "Validation Weighted-F1 Score: 0.9572777261377494\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for _, _, utterance_embeddings, emotions in val_loader:\n",
    "    emotions = emotions.to(DEVICE)\n",
    "    utterance_embeddings = utterance_embeddings.to(DEVICE)\n",
    "    trained_model = trained_model.to(DEVICE)\n",
    "    outputs = trained_model(utterance_embeddings)\n",
    "    loss = criterion(outputs.view(-1, outputs.size(-1)), emotions.view(-1))\n",
    "    _, preds = torch.max(outputs, 2)\n",
    "    target_expanded = emotions.view(-1).cpu().numpy()\n",
    "    preds_expanded = preds.view(-1).cpu().numpy()\n",
    "    y_true.extend(target_expanded)\n",
    "    y_pred.extend(preds_expanded)\n",
    "print('Validation Accuracy:', accuracy_score(y_true, y_pred))\n",
    "print('Validation Macro-F1 Score:', f1_score(y_true, y_pred, average='macro'))\n",
    "print('Validation Weighted-F1 Score:', f1_score(y_true, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TransformerGRUClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_dim):\n",
    "        super(TransformerGRUClassifier, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_dim = output_dim\n",
    "        self.tranformer_encoder_layer = nn.TransformerEncoderLayer(d_model=input_size, nhead=input_size//4)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.tranformer_encoder_layer, num_layers=2)\n",
    "        self.GRU = nn.GRU(input_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        transform_out = self.transformer_encoder(x) + x\n",
    "        h0 = torch.zeros(2, x.size(0), self.hidden_size).to(x.device)\n",
    "        gru_out, _ = self.GRU(transform_out, h0)\n",
    "        gru_out = self.fc(gru_out)\n",
    "        return gru_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "sentence_emb_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "emotion_class_to_idx = {'neutral': 0, 'joy': 1, 'sadness': 2, 'anger': 3, 'fear': 4, 'disgust': 5, 'surprise': 6}\n",
    "emotion_idx_to_class = {v: k for k, v in emotion_class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_EPOCH = 10\n",
    "INPUT_SIZE = 384\n",
    "HIDDEN_SIZE = 128\n",
    "OUTPUT_SIZE = 7\n",
    "\n",
    "trained_model = TransformerGRUClassifier(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE).to(DEVICE)\n",
    "trained_model.load_state_dict(torch.load(\"M2.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True emotions: ['anger', 'joy', 'neutral', 'joy', 'joy']\n",
      "Predicted emotions: ['anger', 'joy', 'neutral', 'joy', 'anger']\n",
      "Accuracy of Prediction: 0.8\n",
      "F1 Score of Prediction: 0.8222222222222223\n",
      "\n",
      "---------------------------------\n",
      "Detecting Speaker Emotion Flips\n",
      "speakers in conversation:\n",
      "['Phoebe', 'Monica', 'Phoebe', 'Monica', 'Phoebe']\n",
      "Predicted Emotions:\n",
      "['anger', 'joy', 'neutral', 'joy', 'anger']\n",
      "\n",
      "Phoebe changed emotion from anger to neutral\n",
      "Phoebe changed emotion from neutral to anger\n"
     ]
    }
   ],
   "source": [
    "def conversation_inference_m2(model:TransformerGRUClassifier, conversation:dict):\n",
    "    model.eval()\n",
    "    utterances = conversation[\"utterances\"]\n",
    "    true_emotions = conversation[\"emotions\"]\n",
    "    speakers = conversation[\"speakers\"]\n",
    "    \n",
    "    # Obtain the utterance embeddings and predict the emotions of all the utterances\n",
    "    utterance_embeddings = torch.tensor(sentence_emb_model.encode(utterances), dtype=torch.float)\n",
    "    utterance_embeddings = utterance_embeddings.unsqueeze(0).to(DEVICE)\n",
    "    predicted_emotions = model(utterance_embeddings)\n",
    "    _, predicted_emotions = torch.max(predicted_emotions, 2)\n",
    "    predicted_emotions = predicted_emotions.squeeze(0)\n",
    "    predicted_emotions = [emotion_idx_to_class[emotion.item()] for emotion in predicted_emotions]\n",
    "\n",
    "    # Show the Accuracy and F1 Score of the prediction\n",
    "    accuracy = accuracy_score(true_emotions, predicted_emotions)\n",
    "    f1 = f1_score(true_emotions, predicted_emotions, average='macro')\n",
    "    print('True emotions:', true_emotions)\n",
    "    print('Predicted emotions:', predicted_emotions)\n",
    "    print('Accuracy of Prediction:', accuracy)\n",
    "    print('F1 Score of Prediction:', f1)\n",
    "    \n",
    "    # Predicting the Emotion Flips\n",
    "    print('\\n---------------------------------')\n",
    "    print('Detecting Speaker Emotion Flips')\n",
    "    print('speakers in conversation:')\n",
    "    print(speakers)\n",
    "    print('Predicted Emotions:')\n",
    "    print(predicted_emotions)\n",
    "    print()\n",
    "    speakers_prev_emotion = {speaker:None for speaker in speakers}\n",
    "    for i, (speaker, true_emotion, predicted_emotion) in enumerate(zip(speakers, true_emotions, predicted_emotions)):\n",
    "        if speakers_prev_emotion[speaker] is None:\n",
    "            speakers_prev_emotion[speaker] = predicted_emotion\n",
    "        else:\n",
    "            if speakers_prev_emotion[speaker] != predicted_emotion:\n",
    "                print(f'{speaker} changed emotion from {speakers_prev_emotion[speaker]} to {predicted_emotion}')\n",
    "                speakers_prev_emotion[speaker] = predicted_emotion\n",
    "    return    \n",
    "\n",
    "ind = 200\n",
    "conversation = val_json[ind]\n",
    "conversation_inference_m2(trained_model, conversation)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9964026583744894\n",
      "Validation F1 Score: 0.98930110022866\n",
      "Validation Weighted-F1 Score: 0.9963929671576677\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for _, _, utterance_embeddings, emotions in val_loader:\n",
    "    emotions = emotions.to(DEVICE)\n",
    "    utterance_embeddings = utterance_embeddings.to(DEVICE)\n",
    "    trained_model = trained_model.to(DEVICE)\n",
    "    outputs = trained_model(utterance_embeddings)\n",
    "    loss = criterion(outputs.view(-1, outputs.size(-1)), emotions.view(-1))\n",
    "    _, preds = torch.max(outputs, 2)\n",
    "    target_expanded = emotions.view(-1).cpu().numpy()\n",
    "    preds_expanded = preds.view(-1).cpu().numpy()\n",
    "    y_true.extend(target_expanded)\n",
    "    y_pred.extend(preds_expanded)\n",
    "print('Validation Accuracy:', accuracy_score(y_true, y_pred))\n",
    "print('Validation F1 Score:', f1_score(y_true, y_pred, average='macro'))\n",
    "print('Validation Weighted-F1 Score:', f1_score(y_true, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2:  ERF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/sumdev/CourseWork/a3_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples: 6740\n",
      "Val Samples: 843\n"
     ]
    }
   ],
   "source": [
    "with open(\"../Data/train_file.json\", 'r') as f:\n",
    "    train_json = json.load(f)\n",
    "with open(\"../Data/val_file.json\", 'r') as f:\n",
    "    val_json = json.load(f)\n",
    "print('Train Samples:', len(train_json))\n",
    "print('Val Samples:', len(val_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 6740\n",
      "Length of val dataset: 843\n"
     ]
    }
   ],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, json_file, model_name=\"all-MiniLM-L6-v2\"):\n",
    "        self.data = []\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.speaker_encoder = LabelEncoder()\n",
    "        self.emotion_class_to_idx = {'neutral': 0, 'joy': 1, 'sadness': 2, 'anger': 3, 'fear': 4, 'disgust': 5, 'surprise': 6}\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            for entry in data:\n",
    "                self.data.append(entry)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.data[idx]\n",
    "        context_size = 5\n",
    "        speakers = torch.tensor(self.speaker_encoder.fit_transform(entry[\"speakers\"]), dtype=torch.long)[-(context_size):]\n",
    "        emotions = torch.tensor([self.emotion_class_to_idx[emotion] for emotion in entry[\"emotions\"]], dtype=torch.long)[-(context_size):]\n",
    "        utterance_embeddings = torch.tensor(self.model.encode(entry[\"utterances\"]), dtype=torch.float)[-(context_size):]\n",
    "        utterance_embeddings = utterance_embeddings + utterance_embeddings[-1]\n",
    "        triggers = [a if a != None else 0.0 for a in entry['triggers']]\n",
    "        triggers = torch.tensor(triggers, dtype=torch.long)[-(context_size):]\n",
    "        return torch.tensor(len(entry[\"speakers\"])), speakers, emotions, utterance_embeddings, triggers\n",
    "\n",
    "\n",
    "# Initialize the dataset and dataloader\n",
    "model_name = 'all-MiniLM-L6-v2' # all-mpnet-base-v2\n",
    "train_dataset = EmotionDataset(\"../Data/train_file.json\", model_name=model_name)\n",
    "val_dataset = EmotionDataset(\"../Data/val_file.json\", model_name=model_name)\n",
    "print('Length of train dataset:', len(train_dataset))\n",
    "print('Length of val dataset:', len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train_loader: 211\n",
      "Length of val_loader: 27\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def collate_fn(batch):\n",
    "    length, speakers, emotions, utterance_embeddings, triggers = zip(*batch)\n",
    "    length = torch.tensor(length, dtype=torch.long)\n",
    "    speakers = nn.utils.rnn.pad_sequence(speakers, batch_first=True)\n",
    "    emotions = nn.utils.rnn.pad_sequence(emotions, batch_first=True)\n",
    "    triggers = nn.utils.rnn.pad_sequence(triggers, batch_first=True)\n",
    "    utterance_embeddings = nn.utils.rnn.pad_sequence(utterance_embeddings, batch_first=True)        \n",
    "    return length, speakers, emotions, utterance_embeddings, triggers\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "print('Length of train_loader:', len(train_loader))\n",
    "print('Length of val_loader:', len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_dim):\n",
    "        super(CustomClassifier, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_dim = output_dim\n",
    "        self.input_layer = nn.Linear(input_size, input_size)\n",
    "        self.tranformer_encoder_layer = nn.TransformerEncoderLayer(d_model=input_size, nhead=input_size//8)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.tranformer_encoder_layer, num_layers=2)\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.transformer_encoder(x) + x\n",
    "        h0 = torch.zeros(2, x.size(0), self.hidden_size).to(x.device)\n",
    "        x, _ = self.gru(x, h0)\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "sentence_emb_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_EPOCH = 10\n",
    "INPUT_SIZE = 384\n",
    "HIDDEN_SIZE = 128\n",
    "OUTPUT_SIZE = 2\n",
    "\n",
    "trained_model = CustomClassifier(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE).to(DEVICE)\n",
    "trained_model.load_state_dict(torch.load(\"M3.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speakers: ['Joey', 'Chandler', 'Joey', 'Chandler', 'Joey']\n",
      "Utterances: [\"Oh God. Uh, okay, here's the thing, this is the thing, okay, the thing is...\", 'What is the thing?', \"Okay. I went down to the \\x91Mattress King' showroom and, and I saw Janice, kissing her ex-husband.\", 'What?', 'They were in his office.']\n",
      "Emotions: ['neutral', 'sadness', 'sadness', 'surprise', 'neutral']\n",
      "\n",
      "True triggers: tensor([0, 0, 0, 1, 0])\n",
      "Predicted triggers: tensor([0, 0, 1, 0, 0])\n",
      "Accuracy of Prediction: 0.6\n",
      "F1 Score of Prediction: 0.375\n"
     ]
    }
   ],
   "source": [
    "def emotion_flip_inference_m3(model:CustomClassifier, conversation:dict):\n",
    "    model.eval()\n",
    "    utterances = conversation[\"utterances\"]\n",
    "    true_emotions = conversation[\"emotions\"]\n",
    "    speakers = conversation[\"speakers\"]\n",
    "    triggers = conversation[\"triggers\"]\n",
    "    context_size = 5\n",
    "    \n",
    "    # Obtain the utterance embeddings and predict the emotion flip reason of last utterance for context size 5\n",
    "    utterance_embeddings = torch.tensor(sentence_emb_model.encode(utterances), dtype=torch.float)[-(context_size):]\n",
    "    utterance_embeddings = utterance_embeddings + utterance_embeddings[-1]\n",
    "    triggers_true_label = [a if a != None else 0.0 for a in triggers]\n",
    "    triggers_true_label = torch.tensor(triggers_true_label, dtype=torch.long)[-(context_size):]\n",
    "    \n",
    "    # Obtain the predicted triggers\n",
    "    utterance_embeddings = utterance_embeddings.unsqueeze(0).to(DEVICE)\n",
    "    triggers_predictions = model(utterance_embeddings)\n",
    "    _, triggers_predictions = torch.max(triggers_predictions, 2)\n",
    "    triggers_predictions = triggers_predictions.view(-1).cpu()\n",
    "\n",
    "    print('Speakers:', speakers[-context_size:])\n",
    "    print('Utterances:', utterances[-context_size:])\n",
    "    print('Emotions:', true_emotions[-context_size:])\n",
    "    print()\n",
    "    print('True triggers:', triggers_true_label)\n",
    "    print('Predicted triggers:', triggers_predictions)\n",
    "\n",
    "    # Show the Accuracy and F1 Score of the prediction\n",
    "    accuracy = accuracy_score(triggers_true_label.cpu().numpy(), triggers_predictions.numpy())\n",
    "    f1 = f1_score(triggers_true_label.cpu().numpy(), triggers_predictions.numpy(), average='macro')\n",
    "    print('Accuracy of Prediction:', accuracy)\n",
    "    print('F1 Score of Prediction:', f1)\n",
    "    \n",
    "\n",
    "ind = 0\n",
    "conversation = val_json[ind]\n",
    "emotion_flip_inference_m3(trained_model, conversation)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.829655990510083\n",
      "Validation Macro-F1 Score: 0.7525376103387056\n",
      "Validation Weighted-F1 Score: 0.8226422491770297\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "for _, speakers, emotions, utterance_embeddings, targets in val_loader:\n",
    "    utterance_embeddings = utterance_embeddings.to(DEVICE)\n",
    "    targets = targets.to(DEVICE)\n",
    "    trained_model = trained_model.to(DEVICE)\n",
    "    outputs = trained_model(utterance_embeddings)\n",
    "    _, preds = torch.max(outputs, 2)\n",
    "    target_expanded = targets.view(-1).cpu().numpy()\n",
    "    preds_expanded = preds.view(-1).cpu().numpy()\n",
    "    y_true.extend(target_expanded)\n",
    "    y_pred.extend(preds_expanded)\n",
    "print('Validation Accuracy:', accuracy_score(y_true, y_pred))\n",
    "print('Validation Macro-F1 Score:', f1_score(y_true, y_pred, average='macro'))\n",
    "print('Validation Weighted-F1 Score:', f1_score(y_true, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 6740\n",
      "Length of val dataset: 843\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, json_file, model_name=\"all-MiniLM-L6-v2\"):\n",
    "        self.data = []\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.speaker_encoder = LabelEncoder()\n",
    "        self.emotion_class_to_idx = {'neutral': 0, 'joy': 1, 'sadness': 2, 'anger': 3, 'fear': 4, 'disgust': 5, 'surprise': 6}\n",
    "\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            for entry in data:\n",
    "                self.data.append(entry)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.data[idx]\n",
    "        speakers = torch.tensor(self.speaker_encoder.fit_transform(entry[\"speakers\"]), dtype=torch.long)\n",
    "        emotions = torch.tensor([self.emotion_class_to_idx[emotion] for emotion in entry[\"emotions\"]], dtype=torch.long)\n",
    "        utterance_embeddings = torch.tensor(self.model.encode(entry[\"utterances\"]), dtype=torch.float)\n",
    "        triggers = np.array(entry[\"triggers\"], dtype=float)\n",
    "        np.nan_to_num(triggers, copy=False)\n",
    "        triggers = torch.tensor(triggers, dtype=torch.int64)\n",
    "        return torch.tensor(len(entry[\"speakers\"])), speakers, emotions, utterance_embeddings, triggers\n",
    "\n",
    "\n",
    "# Initialize the dataset and dataloader\n",
    "model_name = 'all-mpnet-base-v2' # all-MiniLM-L6-v2\n",
    "train_dataset = EmotionDataset(\"../Data/train_file.json\", model_name=model_name)\n",
    "val_dataset = EmotionDataset(\"../Data/val_file.json\", model_name=model_name)\n",
    "print('Length of train dataset:', len(train_dataset))\n",
    "print('Length of val dataset:', len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train_loader: 211\n",
      "Length of val_loader: 27\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "def collate_fn(batch):\n",
    "    length, speakers, emotions, utterance_embeddings, triggers = zip(*batch)\n",
    "    length = torch.tensor(length, dtype=torch.long)\n",
    "    speakers = nn.utils.rnn.pad_sequence(speakers, batch_first=True)\n",
    "    emotions = nn.utils.rnn.pad_sequence(emotions, batch_first=True)\n",
    "    triggers = nn.utils.rnn.pad_sequence(triggers, batch_first=True)\n",
    "    utterance_embeddings = nn.utils.rnn.pad_sequence(utterance_embeddings, batch_first=True)\n",
    "    return length, speakers, emotions, utterance_embeddings, triggers   \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "print('Length of train_loader:', len(train_loader))\n",
    "print('Length of val_loader:', len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.fc(lstm_out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "sentence_emb_model = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_EPOCH = 10\n",
    "INPUT_SIZE = 768\n",
    "HIDDEN_SIZE = 256\n",
    "OUTPUT_SIZE = 2\n",
    "\n",
    "trained_model = BiLSTMClassifier(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE).to(DEVICE)\n",
    "trained_model.load_state_dict(torch.load(\"M4.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speakers: ['Joey', 'Chandler', 'Joey', 'Chandler', 'Joey']\n",
      "Utterances: [\"Oh God. Uh, okay, here's the thing, this is the thing, okay, the thing is...\", 'What is the thing?', \"Okay. I went down to the \\x91Mattress King' showroom and, and I saw Janice, kissing her ex-husband.\", 'What?', 'They were in his office.']\n",
      "Emotions: ['neutral', 'sadness', 'sadness', 'surprise', 'neutral']\n",
      "\n",
      "True triggers: tensor([0, 0, 0, 1, 0])\n",
      "Predicted triggers: tensor([0, 0, 0, 1, 1])\n",
      "Accuracy of Prediction: 0.8\n",
      "F1 Score of Prediction: 0.7619047619047619\n"
     ]
    }
   ],
   "source": [
    "def emotion_flip_inference_m4(model:BiLSTMClassifier, conversation:dict):\n",
    "    model.eval()\n",
    "    utterances = conversation[\"utterances\"]\n",
    "    true_emotions = conversation[\"emotions\"]\n",
    "    speakers = conversation[\"speakers\"]\n",
    "    triggers = conversation[\"triggers\"]\n",
    "    context_size = 5\n",
    "    \n",
    "    # Obtain the utterance embeddings and predict the emotion flip reason of last utterance for context size 5\n",
    "    utterance_embeddings = torch.tensor(sentence_emb_model.encode(utterances), dtype=torch.float)[-(context_size):]\n",
    "    utterance_embeddings = utterance_embeddings + utterance_embeddings[-1]\n",
    "    triggers_true_label = [a if a != None else 0.0 for a in triggers]\n",
    "    triggers_true_label = torch.tensor(triggers_true_label, dtype=torch.long)[-(context_size):]\n",
    "    \n",
    "    # Obtain the predicted triggers\n",
    "    utterance_embeddings = utterance_embeddings.unsqueeze(0).to(DEVICE)\n",
    "    triggers_predictions = model(utterance_embeddings)\n",
    "    _, triggers_predictions = torch.max(triggers_predictions, 2)\n",
    "    triggers_predictions = triggers_predictions.view(-1).cpu()\n",
    "\n",
    "    print('Speakers:', speakers[-context_size:])\n",
    "    print('Utterances:', utterances[-context_size:])\n",
    "    print('Emotions:', true_emotions[-context_size:])\n",
    "    print()\n",
    "    print('True triggers:', triggers_true_label)\n",
    "    print('Predicted triggers:', triggers_predictions)\n",
    "\n",
    "    # Show the Accuracy and F1 Score of the prediction\n",
    "    accuracy = accuracy_score(triggers_true_label.cpu().numpy(), triggers_predictions.numpy())\n",
    "    f1 = f1_score(triggers_true_label.cpu().numpy(), triggers_predictions.numpy(), average='macro')\n",
    "    print('Accuracy of Prediction:', accuracy)\n",
    "    print('F1 Score of Prediction:', f1)\n",
    "    \n",
    "\n",
    "ind = 0\n",
    "conversation = val_json[ind]\n",
    "emotion_flip_inference_m4(trained_model, conversation)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.961038961038961\n",
      "Validation Macro-F1 Score: 0.8386666316708499\n",
      "Validation Weighted-F1 Score: 0.960207953201611\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "for _, speakers, emotions, utterance_embeddings, targets in val_loader:\n",
    "    utterance_embeddings = utterance_embeddings.to(DEVICE)\n",
    "    targets = targets.to(DEVICE)\n",
    "    trained_model = trained_model.to(DEVICE)\n",
    "    outputs = trained_model(utterance_embeddings)\n",
    "    _, preds = torch.max(outputs, 2)\n",
    "    target_expanded = targets.view(-1).cpu().numpy()\n",
    "    preds_expanded = preds.view(-1).cpu().numpy()\n",
    "    y_true.extend(target_expanded)\n",
    "    y_pred.extend(preds_expanded)\n",
    "print('Validation Accuracy:', accuracy_score(y_true, y_pred))\n",
    "print('Validation Macro-F1 Score:', f1_score(y_true, y_pred, average='macro'))\n",
    "print('Validation Weighted-F1 Score:', f1_score(y_true, y_pred, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a3_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
