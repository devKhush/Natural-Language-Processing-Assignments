{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztH7pzZ7_t5l"
      },
      "source": [
        "#Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ0ppXxY_Puw"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bIViOWkAClt"
      },
      "source": [
        "#Tokenize text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28xNHkNnyk3N"
      },
      "source": [
        "*italicised text*## Regex Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSsTlWwqyk3R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcd792e0-52ca-4450-edcf-affc54394ec4"
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer = RegexpTokenizer('\\w+')\n",
        "filterdText=tokenizer.tokenize('Hello NLTK, You have build a very good site and I love visiting your site.')\n",
        "print(filterdText)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'NLTK', 'You', 'have', 'build', 'a', 'very', 'good', 'site', 'and', 'I', 'love', 'visiting', 'your', 'site']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JcqnL9wyk3U"
      },
      "source": [
        "## Tokenization of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDrTqtNIBQK_",
        "outputId": "0ddbf6e7-880e-4bad-f82f-4b4aa266d680"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1Fj-qSAyk3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "995d8a51-3dce-4ec7-98ce-2f4cf7dc2d77"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "text = \"India has recorded the biggest single-day spike of 66,999 COVID-19 cases, taking the total number of infections to 23,96,637. However, the recovery rate has gone up to 70.76 per cent, with 16,95,982 people recovering in the country from the highly-contagious disease, government data this morning showed. With the death of 942 patients in the last 24 hours, the county's fatality count rose 47,033, the Union Health Ministry said. India is the third worst-hit country by the pandemic after the United States and Brazil.\"\n",
        "print(word_tokenize(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['India', 'has', 'recorded', 'the', 'biggest', 'single-day', 'spike', 'of', '66,999', 'COVID-19', 'cases', ',', 'taking', 'the', 'total', 'number', 'of', 'infections', 'to', '23,96,637', '.', 'However', ',', 'the', 'recovery', 'rate', 'has', 'gone', 'up', 'to', '70.76', 'per', 'cent', ',', 'with', '16,95,982', 'people', 'recovering', 'in', 'the', 'country', 'from', 'the', 'highly-contagious', 'disease', ',', 'government', 'data', 'this', 'morning', 'showed', '.', 'With', 'the', 'death', 'of', '942', 'patients', 'in', 'the', 'last', '24', 'hours', ',', 'the', 'county', \"'s\", 'fatality', 'count', 'rose', '47,033', ',', 'the', 'Union', 'Health', 'Ministry', 'said', '.', 'India', 'is', 'the', 'third', 'worst-hit', 'country', 'by', 'the', 'pandemic', 'after', 'the', 'United', 'States', 'and', 'Brazil', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtbSn0skyk3V"
      },
      "source": [
        "## Tokenization of Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrwHrItmyk3W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbb7f6dd-e278-4b46-ed8f-b0669064f100"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "# text = \"God is Great! I won a lottery.\"\n",
        "print(sent_tokenize(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['India has recorded the biggest single-day spike of 66,999 COVID-19 cases, taking the total number of infections to 23,96,637.', 'However, the recovery rate has gone up to 70.76 per cent, with 16,95,982 people recovering in the country from the highly-contagious disease, government data this morning showed.', \"With the death of 942 patients in the last 24 hours, the county's fatality count rose 47,033, the Union Health Ministry said.\", 'India is the third worst-hit country by the pandemic after the United States and Brazil.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZxhqNAjyk3W"
      },
      "source": [
        "# Text Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iepAVlZnBsfX"
      },
      "source": [
        "#Case Folding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5ZMDCyhyk3X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc347fe3-17c5-45af-b08f-d3fa7a9676dd"
      },
      "source": [
        "input_str = \"The 5 biggest countries by population in 2017 are China, India, United States, Indonesia, and Brazil.\"\n",
        "input_str = input_str.lower()\n",
        "print(input_str)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 5 biggest countries by population in 2017 are china, india, united states, indonesia, and brazil.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW6qzOMEyk3c"
      },
      "source": [
        "## Remove whitespaces at beginning and end"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Udw7ewhRyk3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b655e71e-fa5d-432b-fbc0-d762f2bf2e06"
      },
      "source": [
        "input_str = \"  a string example  \"\n",
        "input_str = input_str.strip()\n",
        "print(input_str)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a string example\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8Jhhx6eyk3d"
      },
      "source": [
        "## Remove stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kn7UzfDzGppJ",
        "outputId": "cf2cd477-6d6b-4eec-955c-5f854698bbbc"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q-ri-Jgyk3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc432a72-d593-46d7-9400-9ee20d75be8c"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "print(stop_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ve', \"wouldn't\", 'how', 'my', 'is', 'yourself', 'same', 't', 'both', 'didn', 'with', 'did', 'his', \"should've\", 'other', 'we', \"doesn't\", 'such', 'than', 'm', 'yours', 'at', 'when', 'don', 'while', 'into', 'then', 'on', 'has', 'which', 'themselves', 'an', 'but', 'that', 'under', \"haven't\", 'having', 'why', 'each', 'are', 'itself', 'herself', 'of', 'more', 'a', 'too', 'haven', 'will', 'where', 'these', \"won't\", 'or', 're', \"weren't\", 'by', 'hasn', 'hers', 'their', \"you'd\", 'them', 'couldn', 'and', \"shouldn't\", 'over', 'weren', 'there', 'him', \"aren't\", 'in', \"mustn't\", 'o', 'own', 'not', 'through', 'wouldn', 'yourselves', 'being', 'whom', 'down', \"isn't\", 'hadn', \"hadn't\", 'theirs', \"mightn't\", 'was', 'does', 'i', 'had', 'the', \"couldn't\", 'were', 'won', 'she', 'very', 'after', 'for', 'some', 's', 'what', 'mightn', 'any', 'out', 'it', 'have', 'your', 'here', 'few', \"don't\", 'about', 'he', 'up', 'needn', 'no', \"shan't\", 'shouldn', 'from', 'am', 'me', \"that'll\", 'you', \"wasn't\", 'just', 'shan', 'been', \"didn't\", \"you've\", 'between', 'its', 'so', 'mustn', 'as', 'ourselves', 'ain', \"it's\", 'further', 'because', 'against', 'all', 'above', 'ma', \"you're\", 'her', 'during', 'most', 'until', 'again', \"you'll\", 'to', 'they', 'only', 'before', 'below', 'aren', 'wasn', 'myself', 'those', 'nor', 'be', 'this', 'can', 'himself', 'doesn', 'once', \"hasn't\", 'isn', 'd', 'y', 'do', 'll', 'now', \"needn't\", 'our', 'ours', 'who', 'if', \"she's\", 'off', 'doing', 'should'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuJkNsdbyk3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "740d62e7-101b-43f9-8819-508380357f79"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "# input_str = \"NLTK is a leading platform for building Python programs to work with human language data.\"\n",
        "tokens = word_tokenize(text)\n",
        "result = [i for i in tokens if i not in stop_words]\n",
        "print (result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['India', 'recorded', 'biggest', 'single-day', 'spike', '66,999', 'COVID-19', 'cases', ',', 'taking', 'total', 'number', 'infections', '23,96,637', '.', 'However', ',', 'recovery', 'rate', 'gone', '70.76', 'per', 'cent', ',', '16,95,982', 'people', 'recovering', 'country', 'highly-contagious', 'disease', ',', 'government', 'data', 'morning', 'showed', '.', 'With', 'death', '942', 'patients', 'last', '24', 'hours', ',', 'county', \"'s\", 'fatality', 'count', 'rose', '47,033', ',', 'Union', 'Health', 'Ministry', 'said', '.', 'India', 'third', 'worst-hit', 'country', 'pandemic', 'United', 'States', 'Brazil', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHvhwbbjyk3e"
      },
      "source": [
        "## Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGWy-C0Jyk3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52a7eb3f-a365-4030-f325-9f49bdcb85cf"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "stemmer= PorterStemmer()\n",
        "# input_str=\"There are several types of stemming algorithms.\"\n",
        "#input_str = \"happening happen\"\n",
        "# input_str=\"been had done languages cities mice was\"\n",
        "input_str=word_tokenize(text)\n",
        "for word in input_str:\n",
        "    print(stemmer.stem(word))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "india\n",
            "ha\n",
            "record\n",
            "the\n",
            "biggest\n",
            "single-day\n",
            "spike\n",
            "of\n",
            "66,999\n",
            "covid-19\n",
            "case\n",
            ",\n",
            "take\n",
            "the\n",
            "total\n",
            "number\n",
            "of\n",
            "infect\n",
            "to\n",
            "23,96,637\n",
            ".\n",
            "howev\n",
            ",\n",
            "the\n",
            "recoveri\n",
            "rate\n",
            "ha\n",
            "gone\n",
            "up\n",
            "to\n",
            "70.76\n",
            "per\n",
            "cent\n",
            ",\n",
            "with\n",
            "16,95,982\n",
            "peopl\n",
            "recov\n",
            "in\n",
            "the\n",
            "countri\n",
            "from\n",
            "the\n",
            "highly-contagi\n",
            "diseas\n",
            ",\n",
            "govern\n",
            "data\n",
            "thi\n",
            "morn\n",
            "show\n",
            ".\n",
            "with\n",
            "the\n",
            "death\n",
            "of\n",
            "942\n",
            "patient\n",
            "in\n",
            "the\n",
            "last\n",
            "24\n",
            "hour\n",
            ",\n",
            "the\n",
            "counti\n",
            "'s\n",
            "fatal\n",
            "count\n",
            "rose\n",
            "47,033\n",
            ",\n",
            "the\n",
            "union\n",
            "health\n",
            "ministri\n",
            "said\n",
            ".\n",
            "india\n",
            "is\n",
            "the\n",
            "third\n",
            "worst-hit\n",
            "countri\n",
            "by\n",
            "the\n",
            "pandem\n",
            "after\n",
            "the\n",
            "unit\n",
            "state\n",
            "and\n",
            "brazil\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RprIl3kyk3f"
      },
      "source": [
        "## Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d01acJwrHWtR",
        "outputId": "1460378e-c23e-465e-b6f8-9e80c167eeaf"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvM2-ahqyk3g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83dcca07-625b-44da-a71f-378aa924f931"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "# input_str=\"been had done languages cities mice was is\"\n",
        "input_str=word_tokenize(text)\n",
        "for word in input_str:\n",
        "    print(lemmatizer.lemmatize(word))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "India\n",
            "ha\n",
            "recorded\n",
            "the\n",
            "biggest\n",
            "single-day\n",
            "spike\n",
            "of\n",
            "66,999\n",
            "COVID-19\n",
            "case\n",
            ",\n",
            "taking\n",
            "the\n",
            "total\n",
            "number\n",
            "of\n",
            "infection\n",
            "to\n",
            "23,96,637\n",
            ".\n",
            "However\n",
            ",\n",
            "the\n",
            "recovery\n",
            "rate\n",
            "ha\n",
            "gone\n",
            "up\n",
            "to\n",
            "70.76\n",
            "per\n",
            "cent\n",
            ",\n",
            "with\n",
            "16,95,982\n",
            "people\n",
            "recovering\n",
            "in\n",
            "the\n",
            "country\n",
            "from\n",
            "the\n",
            "highly-contagious\n",
            "disease\n",
            ",\n",
            "government\n",
            "data\n",
            "this\n",
            "morning\n",
            "showed\n",
            ".\n",
            "With\n",
            "the\n",
            "death\n",
            "of\n",
            "942\n",
            "patient\n",
            "in\n",
            "the\n",
            "last\n",
            "24\n",
            "hour\n",
            ",\n",
            "the\n",
            "county\n",
            "'s\n",
            "fatality\n",
            "count\n",
            "rose\n",
            "47,033\n",
            ",\n",
            "the\n",
            "Union\n",
            "Health\n",
            "Ministry\n",
            "said\n",
            ".\n",
            "India\n",
            "is\n",
            "the\n",
            "third\n",
            "worst-hit\n",
            "country\n",
            "by\n",
            "the\n",
            "pandemic\n",
            "after\n",
            "the\n",
            "United\n",
            "States\n",
            "and\n",
            "Brazil\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VccAsOpmyk3g"
      },
      "source": [
        "## Part-of-speech tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFHRrFO1H_eU",
        "outputId": "402f15ba-b402-4a05-9212-f96dccc59267"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NMAIVKtyk3g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e93b4807-8ad4-4a4a-926a-692162c35141"
      },
      "source": [
        "text = \"Hello nltk, You have to build a very good site, and I love visiting your\"\n",
        "sentence = nltk.sent_tokenize(text)\n",
        "for sent in sentence:\n",
        "    print(nltk.pos_tag(nltk.word_tokenize(sent)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Hello', 'NNP'), ('nltk', 'NN'), (',', ','), ('You', 'PRP'), ('have', 'VBP'), ('to', 'TO'), ('build', 'VB'), ('a', 'DT'), ('very', 'RB'), ('good', 'JJ'), ('site', 'NN'), (',', ','), ('and', 'CC'), ('I', 'PRP'), ('love', 'VBP'), ('visiting', 'VBG'), ('your', 'PRP$')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9i_dzoVLx35"
      },
      "source": [
        "#Lemmatization with POS tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol14UTdpOIOB"
      },
      "source": [
        "from nltk.corpus import wordnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpOddbxvLaY4"
      },
      "source": [
        "def pos_tagger(nltk_tag):\n",
        "    if nltk_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif nltk_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif nltk_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif nltk_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xbKjI6fM_cX",
        "outputId": "9ce1fbfc-ed25-4578-b927-3ed80af686ec"
      },
      "source": [
        "# text = 'the cat is sitting with the bats on the striped mat under many badly flying geese'\n",
        "#text = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n",
        "text = \"been had done languages cities mice was is\"\n",
        "print(\"{0:20}{1:20}\".format(\"Without POS\",\"With POS\"))\n",
        "sentence = nltk.sent_tokenize(text)\n",
        "for sent in sentence:\n",
        "    tok = nltk.pos_tag(nltk.word_tokenize(sent))\n",
        "    for word in tok:\n",
        "      pos = pos_tagger(word[1])\n",
        "      if pos:\n",
        "        print(\"{0:20}{1:20}\".format(lemmatizer.lemmatize(word[0]), lemmatizer.lemmatize(word[0], pos)))\n",
        "      else:\n",
        "        print(\"{0:20}{1:20}\".format(lemmatizer.lemmatize(word[0]), lemmatizer.lemmatize(word[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without POS         With POS            \n",
            "been                be                  \n",
            "had                 have                \n",
            "done                do                  \n",
            "language            language            \n",
            "city                city                \n",
            "mouse               mouse               \n",
            "wa                  be                  \n",
            "is                  be                  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec\n",
        "\n"
      ],
      "metadata": {
        "id": "Z6K2cOfnObYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import gensim.downloader as api\n",
        "\n",
        "# model = api.load('word2vec-google-news-300') # Download and Load the pre-trained model\n",
        "\n",
        "# !wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
        "# model = gensim.models.KeyedVectors.load_word2vec_format(r'/root/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz', binary=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9neHPcPFNcNw",
        "outputId": "4794fda7-bc11-4020-9d54-b556727e96d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=================================================-] 100.0% 1662.5/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hhXWaWfyutQ",
        "outputId": "ce136ffd-0f02-4b62-ca4a-9865e6f16679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(model.index_to_key))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pBdvxV0UeEO",
        "outputId": "739285ce-027d-42ab-b5d6-6292043eba07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model['king'])"
      ],
      "metadata": {
        "id": "oGPHzO6XUWdq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8824a1b2-259b-49da-c734-31f5e0f43e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.25976562e-01  2.97851562e-02  8.60595703e-03  1.39648438e-01\n",
            " -2.56347656e-02 -3.61328125e-02  1.11816406e-01 -1.98242188e-01\n",
            "  5.12695312e-02  3.63281250e-01 -2.42187500e-01 -3.02734375e-01\n",
            " -1.77734375e-01 -2.49023438e-02 -1.67968750e-01 -1.69921875e-01\n",
            "  3.46679688e-02  5.21850586e-03  4.63867188e-02  1.28906250e-01\n",
            "  1.36718750e-01  1.12792969e-01  5.95703125e-02  1.36718750e-01\n",
            "  1.01074219e-01 -1.76757812e-01 -2.51953125e-01  5.98144531e-02\n",
            "  3.41796875e-01 -3.11279297e-02  1.04492188e-01  6.17675781e-02\n",
            "  1.24511719e-01  4.00390625e-01 -3.22265625e-01  8.39843750e-02\n",
            "  3.90625000e-02  5.85937500e-03  7.03125000e-02  1.72851562e-01\n",
            "  1.38671875e-01 -2.31445312e-01  2.83203125e-01  1.42578125e-01\n",
            "  3.41796875e-01 -2.39257812e-02 -1.09863281e-01  3.32031250e-02\n",
            " -5.46875000e-02  1.53198242e-02 -1.62109375e-01  1.58203125e-01\n",
            " -2.59765625e-01  2.01416016e-02 -1.63085938e-01  1.35803223e-03\n",
            " -1.44531250e-01 -5.68847656e-02  4.29687500e-02 -2.46582031e-02\n",
            "  1.85546875e-01  4.47265625e-01  9.58251953e-03  1.31835938e-01\n",
            "  9.86328125e-02 -1.85546875e-01 -1.00097656e-01 -1.33789062e-01\n",
            " -1.25000000e-01  2.83203125e-01  1.23046875e-01  5.32226562e-02\n",
            " -1.77734375e-01  8.59375000e-02 -2.18505859e-02  2.05078125e-02\n",
            " -1.39648438e-01  2.51464844e-02  1.38671875e-01 -1.05468750e-01\n",
            "  1.38671875e-01  8.88671875e-02 -7.51953125e-02 -2.13623047e-02\n",
            "  1.72851562e-01  4.63867188e-02 -2.65625000e-01  8.91113281e-03\n",
            "  1.49414062e-01  3.78417969e-02  2.38281250e-01 -1.24511719e-01\n",
            " -2.17773438e-01 -1.81640625e-01  2.97851562e-02  5.71289062e-02\n",
            " -2.89306641e-02  1.24511719e-02  9.66796875e-02 -2.31445312e-01\n",
            "  5.81054688e-02  6.68945312e-02  7.08007812e-02 -3.08593750e-01\n",
            " -2.14843750e-01  1.45507812e-01 -4.27734375e-01 -9.39941406e-03\n",
            "  1.54296875e-01 -7.66601562e-02  2.89062500e-01  2.77343750e-01\n",
            " -4.86373901e-04 -1.36718750e-01  3.24218750e-01 -2.46093750e-01\n",
            " -3.03649902e-03 -2.11914062e-01  1.25000000e-01  2.69531250e-01\n",
            "  2.04101562e-01  8.25195312e-02 -2.01171875e-01 -1.60156250e-01\n",
            " -3.78417969e-02 -1.20117188e-01  1.15234375e-01 -4.10156250e-02\n",
            " -3.95507812e-02 -8.98437500e-02  6.34765625e-03  2.03125000e-01\n",
            "  1.86523438e-01  2.73437500e-01  6.29882812e-02  1.41601562e-01\n",
            " -9.81445312e-02  1.38671875e-01  1.82617188e-01  1.73828125e-01\n",
            "  1.73828125e-01 -2.37304688e-01  1.78710938e-01  6.34765625e-02\n",
            "  2.36328125e-01 -2.08984375e-01  8.74023438e-02 -1.66015625e-01\n",
            " -7.91015625e-02  2.43164062e-01 -8.88671875e-02  1.26953125e-01\n",
            " -2.16796875e-01 -1.73828125e-01 -3.59375000e-01 -8.25195312e-02\n",
            " -6.49414062e-02  5.07812500e-02  1.35742188e-01 -7.47070312e-02\n",
            " -1.64062500e-01  1.15356445e-02  4.45312500e-01 -2.15820312e-01\n",
            " -1.11328125e-01 -1.92382812e-01  1.70898438e-01 -1.25000000e-01\n",
            "  2.65502930e-03  1.92382812e-01 -1.74804688e-01  1.39648438e-01\n",
            "  2.92968750e-01  1.13281250e-01  5.95703125e-02 -6.39648438e-02\n",
            "  9.96093750e-02 -2.72216797e-02  1.96533203e-02  4.27246094e-02\n",
            " -2.46093750e-01  6.39648438e-02 -2.25585938e-01 -1.68945312e-01\n",
            "  2.89916992e-03  8.20312500e-02  3.41796875e-01  4.32128906e-02\n",
            "  1.32812500e-01  1.42578125e-01  7.61718750e-02  5.98144531e-02\n",
            " -1.19140625e-01  2.74658203e-03 -6.29882812e-02 -2.72216797e-02\n",
            " -4.82177734e-03 -8.20312500e-02 -2.49023438e-02 -4.00390625e-01\n",
            " -1.06933594e-01  4.24804688e-02  7.76367188e-02 -1.16699219e-01\n",
            "  7.37304688e-02 -9.22851562e-02  1.07910156e-01  1.58203125e-01\n",
            "  4.24804688e-02  1.26953125e-01  3.61328125e-02  2.67578125e-01\n",
            " -1.01074219e-01 -3.02734375e-01 -5.76171875e-02  5.05371094e-02\n",
            "  5.26428223e-04 -2.07031250e-01 -1.38671875e-01 -8.97216797e-03\n",
            " -2.78320312e-02 -1.41601562e-01  2.07031250e-01 -1.58203125e-01\n",
            "  1.27929688e-01  1.49414062e-01 -2.24609375e-02 -8.44726562e-02\n",
            "  1.22558594e-01  2.15820312e-01 -2.13867188e-01 -3.12500000e-01\n",
            " -3.73046875e-01  4.08935547e-03  1.07421875e-01  1.06933594e-01\n",
            "  7.32421875e-02  8.97216797e-03 -3.88183594e-02 -1.29882812e-01\n",
            "  1.49414062e-01 -2.14843750e-01 -1.83868408e-03  9.91210938e-02\n",
            "  1.57226562e-01 -1.14257812e-01 -2.05078125e-01  9.91210938e-02\n",
            "  3.69140625e-01 -1.97265625e-01  3.54003906e-02  1.09375000e-01\n",
            "  1.31835938e-01  1.66992188e-01  2.35351562e-01  1.04980469e-01\n",
            " -4.96093750e-01 -1.64062500e-01 -1.56250000e-01 -5.22460938e-02\n",
            "  1.03027344e-01  2.43164062e-01 -1.88476562e-01  5.07812500e-02\n",
            " -9.37500000e-02 -6.68945312e-02  2.27050781e-02  7.61718750e-02\n",
            "  2.89062500e-01  3.10546875e-01 -5.37109375e-02  2.28515625e-01\n",
            "  2.51464844e-02  6.78710938e-02 -1.21093750e-01 -2.15820312e-01\n",
            " -2.73437500e-01 -3.07617188e-02 -3.37890625e-01  1.53320312e-01\n",
            "  2.33398438e-01 -2.08007812e-01  3.73046875e-01  8.20312500e-02\n",
            "  2.51953125e-01 -7.61718750e-02 -4.66308594e-02 -2.23388672e-02\n",
            "  2.99072266e-02 -5.93261719e-02 -4.66918945e-03 -2.44140625e-01\n",
            " -2.09960938e-01 -2.87109375e-01 -4.54101562e-02 -1.77734375e-01\n",
            " -2.79296875e-01 -8.59375000e-02  9.13085938e-02  2.51953125e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.index_to_key[0:10])"
      ],
      "metadata": {
        "id": "srXi-fjWNgvy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2104bb9-5a8a-4b53-bfd5-56d1ac15b9ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['</s>', 'in', 'for', 'that', 'is', 'on', '##', 'The', 'with', 'said']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    print (model['akhtar'])\n",
        "except KeyError:\n",
        "    print(\"The word 'akhtar' does not appear in this model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiH_JJ1GNhmS",
        "outputId": "e018609b-0db2-4c56-edf8-35a2a516f756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The word 'akhtar' does not appear in this model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.most_similar('india')) # default 10 words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR0upm_rUEF5",
        "outputId": "754788ee-0b45-48c7-ec1e-c6a6e8b52409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('indian', 0.6967039704322815), ('usa', 0.6836211085319519), ('pakistan', 0.681516706943512), ('chennai', 0.6675503253936768), ('america', 0.6589399576187134), ('sri_lanka', 0.64982008934021), ('canada', 0.6490967869758606), ('australia', 0.6368584036827087), ('mexico', 0.6239137649536133), ('uk', 0.6221641898155212)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.most_similar(['india', 'usa'], topn=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xTQUwJmNtr3",
        "outputId": "85c909b2-ef13-442f-afc1-89ccd8e4bbb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('canada', 0.7426208257675171), ('america', 0.7194116711616516), ('uk', 0.7084315419197083), ('mexico', 0.7043545246124268), ('australia', 0.6988037824630737)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.most_similar(['india', 'delhi'], topn=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g14PWYzIU4iE",
        "outputId": "408d2ef9-f289-40de-c8f3-8848dbc518bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('chennai', 0.7414294481277466), ('mumbai', 0.7143338918685913), ('pakistan', 0.6966208815574646), ('kerala', 0.6920104026794434), ('indian', 0.6869001388549805)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "iA_sckGfVEWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.word2vec import Word2Vec\n",
        "corpus = api.load('text8')    # Download and load some text-based corpus."
      ],
      "metadata": {
        "id": "aKiQPm8KN_9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not model:\n",
        "  model = Word2Vec(corpus)\n",
        "# print(model.wv.most_similar('tree'))\n",
        "print(model.most_similar('tree'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VDyqYlvVi3s",
        "outputId": "c9376ab9-38e4-46d8-fc6a-793e6712c7ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('trees', 0.829312264919281), ('pine_tree', 0.7622087001800537), ('oak_tree', 0.731893002986908), ('evergreen_tree', 0.6926872730255127), ('fir_tree', 0.6917218565940857), ('willow_tree', 0.6845874786376953), ('pine_trees', 0.6824266910552979), ('maple_tree', 0.6803498864173889), ('sycamore_tree', 0.6681811809539795), ('tress', 0.6547872424125671)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.similarity('delhi', 'mumbai'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hyom5JF6Noox",
        "outputId": "f3da9be8-135d-4b01-f86e-9059b5cc0a97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6771246\n"
          ]
        }
      ]
    }
  ]
}